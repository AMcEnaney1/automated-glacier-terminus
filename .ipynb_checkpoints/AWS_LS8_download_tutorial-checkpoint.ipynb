{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to bulk download LS8 images using Amazon Web Services (aws)\n",
    "\n",
    "This tutorial goes through how to bulk download Landsat-8 images stored on the Amazon Web Services cloud (s3 bucket) over a region of interest. You can access each band and the metadata file for each LS8 scene separately! Read more about the Landsat-8 data availability on the AWS cloud here: https://registry.opendata.aws/landsat-8/. You will need to install AWS and have a shapefile over your region of interest. Make sure to also have the Geospatial Data Abstraction Library (GDAL) downloaded so you can run commands like __ogr2ogr__ and __gdalwarp__ from your command terminal.\n",
    "\n",
    "_by Jukes Liu. Last modified 10-04-2019._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Set-up\n",
    "#### Install AWS command line interface using pip or pip3\n",
    "\n",
    "This download workflow requires you to have the Amazon Web Services command line interface installed on your terminal. Follow instructions at https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html to get aws commands onto your shell terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy.ma as ma\n",
    "\n",
    "#geospatial packages\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point\n",
    "import shapely\n",
    "\n",
    "# Enable fiona KML file reading driver\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some these packages cannot be imported, you may not have those modules installed on your machine or the path is different from the one accessed by Jupyter notebook. Either way, run the following cell to install the package that is giving you an error and try importing them after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install fiona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace os with whichever package you want to install."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set working paths and create a new folder for your LS8 downloads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists already\n"
     ]
    }
   ],
   "source": [
    "#Set a basepath for your input files (shapefiles, WRS world bound kml file, etc.) here:\n",
    "basepath = '/home/jukes/Documents/Sample_glaciers/'\n",
    "\n",
    "#Set an output path for your downloaded images here:\n",
    "outputpath = '/media/jukes/jukes1/'\n",
    "\n",
    "#create a new folder to hold your new downloads in your output path:\n",
    "newfoldername = 'LS8aws'\n",
    "\n",
    "if os.path.exists(outputpath+newfoldername)==True:\n",
    "    print(\"Path exists already\")\n",
    "else:\n",
    "    os.mkdir(outputpath+newfoldername)\n",
    "    print(\"LS8aws directory made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Find all LS Path Row combinations over the shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the path to your shapefile over the region of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "shpname_no_ext = \"Box001\"\n",
    "pathtoshp = basepath+\"Box001/\"+shpname_no_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your shapefile is not in the WRS projection (ESPG: 4326), reproject it into WRS84 coordinates using GDAL command __ogr2ogr__:\n",
    "\n",
    "    ogr2ogr -f \"ESRI Shapefile\" -t_srs EPSG:NEW_EPSG_NUMBER -s_srs EPSG:OLD_EPSG_NUMBER output.shp input.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ogr2ogr -f \"ESRI Shapefile\" -t_srs EPSG:4326 -s_srs EPSG:3413 /home/jukes/Documents/Sample_glaciers/Box001/Box001_WRS.shp /home/jukes/Documents/Sample_glaciers/Box001/Box001.shp\n"
     ]
    }
   ],
   "source": [
    "rp_command = 'ogr2ogr -f \"ESRI Shapefile\" -t_srs EPSG:4326 -s_srs EPSG:3413 '+pathtoshp+'_WRS.shp '+pathtoshp+'.shp'\n",
    "#print the command to check syntax:\n",
    "print(rp_command)\n",
    "#Then uncomment the following line and run it:\n",
    "# subprocess.call(rp_command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we read in the shapefile as a fiona vector feature and grab its vertex coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: [(-69.95445523105522, 77.23057991382787), (-69.95269043891739, 77.24074644306974), (-69.92754635068265, 77.24053201366061), (-69.92933129107398, 77.23036566058502), (-69.95445523105522, 77.23057991382787)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jukes/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FionaDeprecationWarning: Collection.__next__() is buggy and will be removed in Fiona 2.0. Switch to `next(iter(collection))`.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#new path to the reprojected shapefile and open it using fiona\n",
    "WRS84_shp = pathtoshp+'_WRS.shp'\n",
    "shp = fiona.open(WRS84_shp)\n",
    "\n",
    "shp_feature = shp.next()\n",
    "shp_geom= shp_feature.get('geometry')\n",
    "shp_coords = shp_geom.get('coordinates')[0]\n",
    "print(\"Coordinates:\", shp_coords)\n",
    "#if it's a shapefile with n vertices, there should be n+1 coordinate pairs with the 1st and last being the same\n",
    "\n",
    "#Grab the vertex points and turn them into shapely geometries stored in a list\n",
    "points = []\n",
    "\n",
    "#loops through all of the coordinate pairs from above:\n",
    "for coord_pair in shp_coords:\n",
    "    lat = coord_pair[0]\n",
    "    lon = coord_pair[1]\n",
    "    \n",
    "    #create shapely points and append to points list\n",
    "    point = shapely.geometry.Point(lat, lon)\n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the LS8 Path Row footprint .kml file and find which Path Row combinations overlay your shapefile!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the kml file with the pathrow bounds as WRS\n",
    "WRS = fiona.open(basepath+'WRS-2_bound_world.kml', driver='KML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loops through all the Path Row (features) combinations and stores those that contain ALL of your shapefile vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>035</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>034</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>033</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>032</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>031</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>037</td>\n",
       "      <td>004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>036</td>\n",
       "      <td>004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Path  Row\n",
       "0  035  005\n",
       "1  034  005\n",
       "2  033  005\n",
       "3  032  005\n",
       "4  031  005\n",
       "5  037  004\n",
       "6  036  004"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create lists to hold the paths and rows\n",
    "paths = []\n",
    "rows = []\n",
    "\n",
    "#loop through all features in the WRS .kml:\n",
    "for feature in WRS:\n",
    "    #create shapely polygons with the path row bounds\n",
    "    coordinates = feature['geometry']['coordinates'][0]\n",
    "    coords = [xy[0:2] for xy in coordinates]\n",
    "    pathrow_poly = Polygon(coords)\n",
    "    \n",
    "    #grab the path and row from the metadata\n",
    "    pathrowname = feature['properties']['Name']  \n",
    "    path = pathrowname.split('_')[0]\n",
    "    row = pathrowname.split('_')[1]\n",
    "    \n",
    "    #create a counter for the number of shapefile vertices found in the path row footpring\n",
    "    points_in = 0\n",
    "    \n",
    "    #for each path row, loop through each of the box_points\n",
    "    for point in points:\n",
    "        #if the pathrow shape contains the point\n",
    "        if point.within(pathrow_poly):\n",
    "            #append the counter\n",
    "            points_in = points_in+1\n",
    "        \n",
    "    #If the number of vertices found in the Path Row footprint is equal to the total number (all of them)\n",
    "    if points_in == len(points):\n",
    "        #append the path and row to the lists (3 digit formatting)\n",
    "        paths.append('%03d' % int(path))\n",
    "        rows.append('%03d' % int(row))\n",
    "\n",
    "#Store in a dataframe:\n",
    "pr_df = pd.DataFrame(list(zip(paths, rows)), columns=['Path', 'Row'])\n",
    "pr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: write the path row combinations found to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #write the data frame to csv file\n",
    "# pr_df.to_csv(path_or_buf = basepath+'LS_pathrows_'+shpname_no_ext+'.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Download metadata (MTL.txt) files for all available images over the shapefile region\n",
    "\n",
    "It's good practice to keep the metadata file around for any images that you're using, so let's go ahead and download all of them for the available image over your region. This is the first instance where we're using the AWS command line interface. We'll use this syntax:\n",
    "\n",
    "     aws --no-sign-request s3 cp s3://landsat-pds/L8/path/row/LC8pathrowyear001LGN00/LC8pathrowyear001LGN00_MTL.txt /path_to/output/\n",
    "\n",
    "Access https://docs.opendata.aws/landsat-pds/readme.html to learn more.\n",
    "\n",
    "#### To keep things organized, let's create folders corresponding to the Path_Row IDs and download the MTL.txt files into them.\n",
    "\n",
    "#### Download the metadatafiles into these path row folders using the following syntax:\n",
    "\n",
    "    aws --no-sign-request s3 cp s3://landsat-pds/L8/031/005/ Output/path/LS8aws/Path031_Row005/ --recursive --exclude \"*\" --include \"*.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path035_Row005  EXISTS ALREADY. SKIP.\n",
      "aws --no-sign-request s3 cp s3://landsat-pds/L8/035/005/ /media/jukes/jukes1/LS8aws/Path035_Row005/ --recursive --exclude \"*\" --include \"*.txt\"\n",
      "Path034_Row005  EXISTS ALREADY. SKIP.\n",
      "aws --no-sign-request s3 cp s3://landsat-pds/L8/034/005/ /media/jukes/jukes1/LS8aws/Path034_Row005/ --recursive --exclude \"*\" --include \"*.txt\"\n",
      "Path033_Row005  EXISTS ALREADY. SKIP.\n",
      "aws --no-sign-request s3 cp s3://landsat-pds/L8/033/005/ /media/jukes/jukes1/LS8aws/Path033_Row005/ --recursive --exclude \"*\" --include \"*.txt\"\n",
      "Path032_Row005  EXISTS ALREADY. SKIP.\n",
      "aws --no-sign-request s3 cp s3://landsat-pds/L8/032/005/ /media/jukes/jukes1/LS8aws/Path032_Row005/ --recursive --exclude \"*\" --include \"*.txt\"\n",
      "Path031_Row005  EXISTS ALREADY. SKIP.\n",
      "aws --no-sign-request s3 cp s3://landsat-pds/L8/031/005/ /media/jukes/jukes1/LS8aws/Path031_Row005/ --recursive --exclude \"*\" --include \"*.txt\"\n",
      "Path037_Row004  EXISTS ALREADY. SKIP.\n",
      "aws --no-sign-request s3 cp s3://landsat-pds/L8/037/004/ /media/jukes/jukes1/LS8aws/Path037_Row004/ --recursive --exclude \"*\" --include \"*.txt\"\n",
      "Path036_Row004  EXISTS ALREADY. SKIP.\n",
      "aws --no-sign-request s3 cp s3://landsat-pds/L8/036/004/ /media/jukes/jukes1/LS8aws/Path036_Row004/ --recursive --exclude \"*\" --include \"*.txt\"\n"
     ]
    }
   ],
   "source": [
    "#Loop through the dataframe with your path row combinations:\n",
    "for index, row in pr_df.iterrows():\n",
    "    #grab the path row names and set the folder name\n",
    "    path = row['Path']\n",
    "    row = row['Row']\n",
    "    folder_name = 'Path'+path+'_Row'+row\n",
    "\n",
    "    #set basepath to access the image on the amazon cloud\n",
    "    bp_in = 's3://landsat-pds/L8/'\n",
    "    totalp_in = bp_in+path+'/'+row+'/'\n",
    "    print(totalp_in)\n",
    "\n",
    "    #set output path for the downloaded files:\n",
    "    bp_out = outputpath+newfoldername+'/'+folder_name+'/'\n",
    "    print(bp_out)\n",
    "    \n",
    "    #create Path_Row folders if they don't exist already\n",
    "    if os.path.exists(bp_out):\n",
    "        print(folder_name, \" EXISTS ALREADY. SKIP.\")\n",
    "    else:\n",
    "        os.mkdir(bp_out)\n",
    "        print(folder_name+\" directory made\")\n",
    "        \n",
    "    #Check download command syntax:\n",
    "    command = 'aws --no-sign-request s3 cp '+totalp_in+' '+bp_out+' --recursive --exclude \"*\" --include \"*.txt\"'\n",
    "    print(command)\n",
    "    \n",
    "    #When you've checked everything, uncomment the following to run:\n",
    "#     #call the command line that downloads the metadata files using aws\n",
    "#     subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
