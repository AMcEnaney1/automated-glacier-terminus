{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to download LS8 images for Greenland peripheral glaciers using Amazon Web Services (aws) \n",
    "\n",
    "### Jukes Liu\n",
    "\n",
    "The following code automatically downloads Landsat 8 scenes available through Amazon Web Services that have less than a threshold % of cloud cover. The Landsat 8 scenes over each glacier are identified using their pre-determined path and row, stored in a .csv file. The scenes are filtered for cloud cover using their metadata files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Set up:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install AWS using pip or pip3\n",
    "\n",
    "Must have Amazon Web Services installed on your terminal. Follow instructions at https://docs.aws.amazon.com/cli/latest/userguide/install-linux-al2017.html to get aws commands onto your shell terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in LS path and row for each peripheral glacier by BoxID into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LS Path and Row information for each peripheral glacier is stored in a .csv file. \n",
    "\n",
    "Note: Many glaciers exist in the same Landsat scene, so some Paths and Rows are repeated. Therefore, the subsequent code will not repeat download for a path and row combination that already exists in the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Row</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoxID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001</th>\n",
       "      <td>034</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002</th>\n",
       "      <td>031</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004</th>\n",
       "      <td>031</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>033</th>\n",
       "      <td>008</td>\n",
       "      <td>014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>232</td>\n",
       "      <td>017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Path  Row\n",
       "BoxID          \n",
       "001    034  005\n",
       "002    031  005\n",
       "004    031  005\n",
       "033    008  014\n",
       "120    232  017"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set basepath\n",
    "basepath = '/home/jukes/Documents/Sample_glaciers/'\n",
    "#basepath = '/home/automated-glacier-terminus/'\n",
    "outputpath = '/media/jukes/jukes1/'\n",
    "\n",
    "#read the path row csv file into a dataframe\n",
    "pathrows_df = pd.read_csv(basepath+'LS_pathrows.csv', sep=',', usecols =[0,1,2], dtype=str, nrows =10)\n",
    "pathrows_df = pathrows_df.set_index('BoxID')\n",
    "pathrows_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the df dimensions\n",
    "pathrows_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create output directory: LS8aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists already\n"
     ]
    }
   ],
   "source": [
    "#create LS8aws folder\n",
    "if os.path.exists(outputpath+'LS8aws')==True:\n",
    "    print(\"Path exists already\")\n",
    "else:\n",
    "    os.mkdir(outputpath+'LS8aws')\n",
    "    print(\"LS8aws directory made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Download B8 (panchromatic band) and MTL.txt (metadata) files for all available images over the path/row of the glaciers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Landsat8 scenes stored in AWS can be accessed using the landsat-pds bucket and the path and row information. Each of the bands and a metadata file can be accessed separately. \n",
    "\n",
    "We are interested in the panchromatic band (B8.TIF) and the metadata file to filter for cloud cover (MTL.txt). The download commands will use the following syntax:\n",
    "\n",
    "\n",
    "    aws --no-sign-request s3 cp s3://landsat-pds/L8/path/row/LC8pathrowyear001LGN00/LC8pathrowyear001LGN00_MTL.txt /path_to/output/\n",
    "\n",
    "    aws --no-sign-request s3 cp s3://landsat-pds/L8/path/row/LC8pathrowyear001LGN00/LC8pathrowyear001LGN00_B8.TIF /path_to/output/\n",
    "\n",
    "Access https://docs.opendata.aws/landsat-pds/readme.html to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A) Option 1: For one BoxID (one glacier) at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxID  002 path 031 row 005\n",
      "Path031_Row005\n",
      "s3://landsat-pds/L8/031/005/\n",
      "/media/jukes/jukes1/LS8aws/Path031_Row005/\n"
     ]
    }
   ],
   "source": [
    "#choose a glacier: Box002\n",
    "boxid = pathrows_df.index[1]\n",
    "path = pathrows_df['Path'][1]\n",
    "row = pathrows_df['Row'][1] \n",
    "print('BoxID ', boxid, 'path', path, 'row', row)\n",
    "\n",
    "#set path row folder name\n",
    "folder_name = 'Path'+path+'_Row'+row\n",
    "print(folder_name)\n",
    "\n",
    "#set input path\n",
    "bp_in = 's3://landsat-pds/L8/'\n",
    "totalp_in = bp_in+path+'/'+row+'/'\n",
    "print(totalp_in)\n",
    "\n",
    "#set output path\n",
    "bp_out = outputpath+'LS8aws/'+folder_name+'/'\n",
    "print(bp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Path_Row folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path031_Row005 directory made\n"
     ]
    }
   ],
   "source": [
    "#create Path_row folder and write path names to txt files\n",
    "if os.path.exists(bp_out):\n",
    "    print(folder_name, \" EXISTS ALREADY. SKIP.\")\n",
    "else:\n",
    "    os.mkdir(bp_out)\n",
    "    print(folder_name+\" directory made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download all the metadata text files using os.system aws commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following syntax:\n",
    "\n",
    "    aws --no-sign-request s3 cp s3://landsat-pds/L8/031/005/ Output/path/LS8aws/Path031_Row005/ --recursive --exclude \"*\" --include \"*.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws --no-sign-request s3 cp s3://landsat-pds/L8/031/005/ /media/jukes/jukes1/LS8aws/Path031_Row005/ --recursive --exclude \"*\" --include \"*.txt\"\n"
     ]
    }
   ],
   "source": [
    "#Check command syntax:\n",
    "command = 'aws --no-sign-request s3 cp '+totalp_in+' '+bp_out+' --recursive --exclude \"*\" --include \"*.txt\"'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the command line that downloads the metadata files using aws\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter for cloud cover\n",
    "\n",
    "If the metadata files indicate land cloud cover is less than the threshold, then download the B8, otherwise, delete the folder. Not all metadata files contain the land cloud cover, some only contain the overall cloud cover. If land cloud cover is not found, use the cloud cover value to determine whether the image should be downloaded .Use the following metadata attributes:\n",
    "\n",
    "  GROUP = IMAGE_ATTRIBUTES\n",
    "  \n",
    "    CLOUD_COVER = 23.58\n",
    "    CLOUD_COVER_LAND = 20.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set cloud cover % thresholds\n",
    "ccland_thresh = 30.0\n",
    "cc_thresh = 50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC80310052014146LGN00\n",
      "LC80310052014146LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052017074LGN00\n",
      "LC80310052017074LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052016168LGN00\n",
      "LC80310052016168LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052016232LGN00\n",
      "83.21  >  30.0 ,  LC80310052016232LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052016120LGN00\n",
      "58.87  >  30.0 ,  LC80310052016120LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052016184LGN00\n",
      "51.23  >  30.0 ,  LC80310052016184LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052016280LGN00\n",
      "LC80310052016280LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052015277LGN00\n",
      "LC80310052015277LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052015149LGN00\n",
      "LC80310052015149LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052014098LGN00\n",
      "LC80310052014098LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052015165LGN00\n",
      "LC80310052015165LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052013271LGN00\n",
      "LC80310052013271LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052015101LGN00\n",
      "CCL detected =  False\n",
      "CCL not detected, use CC.\n",
      "LC80310052015101LGN00 B8 downloaded -cc\n",
      "LC80310052017090LGN00\n",
      "LC80310052017090LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052015069LGN00\n",
      "LC80310052015069LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052013239LGN00\n",
      "LC80310052013239LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052014178LGN00\n",
      "32.79  >  30.0 ,  LC80310052014178LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052015197LGN00\n",
      "LC80310052015197LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052015085LGN00\n",
      "CCL detected =  False\n",
      "CCL not detected, use CC.\n",
      "LC80310052015085LGN00 B8 downloaded -cc\n",
      "LC80310052015229LGN00\n",
      "LC80310052015229LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052013143LGN01\n",
      "LC80310052013143LGN01 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052016152LGN00\n",
      "52.28  >  30.0 ,  LC80310052016152LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052016216LGN00\n",
      "86.56  >  30.0 ,  LC80310052016216LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052015117LGN00\n",
      "LC80310052015117LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052015181LGN00\n",
      "LC80310052015181LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052016248LGN00\n",
      "56.57  >  30.0 ,  LC80310052016248LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052016088LGN00\n",
      "LC80310052016088LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052013255LGN00\n",
      "79.45  >  30.0 ,  LC80310052013255LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052014258LGN00\n",
      "CCL detected =  False\n",
      "CCL not detected, use CC.\n",
      "LC80310052014258LGN00 B8 downloaded -cc\n",
      "LC80310052015245LGN00\n",
      "LC80310052015245LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052015133LGN00\n",
      "32.44  >  30.0 ,  LC80310052015133LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052016072LGN00\n",
      "LC80310052016072LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052015213LGN00\n",
      "LC80310052015213LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052016104LGN00\n",
      "55.35  >  30.0 ,  LC80310052016104LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052016200LGN00\n",
      "52.64  >  30.0 ,  LC80310052016200LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052014082LGN00\n",
      "LC80310052014082LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052015261LGN00\n",
      "LC80310052015261LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052016136LGN00\n",
      "31.14  >  30.0 ,  LC80310052016136LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052014226LGN00\n",
      "37.11  >  30.0 ,  LC80310052014226LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052014162LGN00\n",
      "59.19  >  30.0 ,  LC80310052014162LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052014274LGN00\n",
      "CCL detected =  False\n",
      "CCL not detected, use CC.\n",
      "LC80310052014274LGN00 B8 downloaded -cc\n",
      "LC80310052014242LGN00\n",
      "LC80310052014242LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n",
      "LC80310052014210LGN00\n",
      "87.67  >  30.0 ,  LC80310052014210LGN00 removed\n",
      "CCL detected =  True\n",
      "LC80310052014194LGN00\n",
      "LC80310052014194LGN00 B8 downloaded -ccl \n",
      "CCL detected =  True\n"
     ]
    }
   ],
   "source": [
    "#loop through all the metadata files in the path_row folder:\n",
    "for image in os.listdir(bp_out):\n",
    "    if image.startswith(\"LC\"):\n",
    "        #list the name of the image folder\n",
    "        print(image)\n",
    "        \n",
    "        #open the metadata file within that folder\n",
    "        mdata = open(bp_out+image+\"/\"+image+\"_MTL.txt\", \"r\")\n",
    "        \n",
    "        #set a detection variable for whether or not the metadata contains land cloud cover\n",
    "        ccl_detected = False\n",
    "        \n",
    "        #loop through each line in metadata to find Land Cloud Cover\n",
    "        for line in mdata:\n",
    "            cc_variable = line.split(\"=\")[0]\n",
    "            \n",
    "            #if there is land cloud cover:\n",
    "            if (\"CLOUD_COVER_LAND\" in cc_variable):\n",
    "                #save it:\n",
    "                ccl = np.float(line.split(\"=\")[1])\n",
    "                         \n",
    "                #switch the ccl_detected variable to True!\n",
    "                ccl_detected = True\n",
    "                    \n",
    "                #if the ccl is less than the threshold, delete the file\n",
    "                if ccl > ccland_thresh:\n",
    "                    #remove the image directory\n",
    "                    subprocess.call('rm -r '+bp_out+image, shell=True)\n",
    "                    print(ccl, ' > ', ccland_thresh, \", \", image, \"removed\")\n",
    "                #otherwise: \n",
    "                else:\n",
    "                    #DOWNLOAD THE B8 FILE\n",
    "                    subprocess.call('source activate aws; aws --no-sign-request s3 cp '+totalp_in+' '+bp_out+' --recursive --exclude \"*\" --include \"*B8.TIF\"', shell=True)\n",
    "                    print(image, \"B8 downloaded -ccl \")\n",
    "        \n",
    "        #Was the ccl detected?\n",
    "        print(\"CCL detected = \", ccl_detected)\n",
    "                        \n",
    "        #if False,use the overall cloud cover:\n",
    "        if ccl_detected == False:   \n",
    "            print(\"CCL not detected, use CC.\")\n",
    "            \n",
    "            #open the metadata file again\n",
    "            mdata = open(bp_out+image+\"/\"+image+\"_MTL.txt\", \"r\")\n",
    "            for line in mdata:\n",
    "                variable = line.split(\"=\")[0]\n",
    "                \n",
    "                #now there should only be one line starting with cloud_cover\n",
    "                if (\"CLOUD_COVER\" in variable):       \n",
    "                    #save the cloud cover:\n",
    "                    cc = np.float(line.split(\"=\")[1])\n",
    "\n",
    "                    #if the cc is less than the threshold, delete the file:\n",
    "                    if cc > cc_thresh:\n",
    "                        #remove the image directory\n",
    "                        subprocess.call('rm -r '+bp_out+image, shell=True)\n",
    "                        print(cc, ' > ', cc_thresh, \", \", image, \"removed\")\n",
    "\n",
    "                    #otherwise: \n",
    "                    else:\n",
    "                        #DOWNLOAD THE B8 FILE\n",
    "                        subprocess.call('source activate aws; aws --no-sign-request s3 cp '+totalp_in+' '+bp_out+' --recursive --exclude \"*\" --include \"*B8.TIF\"', shell=True)\n",
    "                        print(image, \"B8 downloaded -cc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B) Option 2: For all glaciers, loop through the DataFrame and perform all the Option 1 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BoxID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BoxID'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-62f48a640ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#LOOP through each of the glaciers in the DataFrame and download for each path and row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathrows_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BoxID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#SET path and row variables to the LS path and rows of the box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathrows_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BoxID'"
     ]
    }
   ],
   "source": [
    "#SET cloud cover thresholds for filtering\n",
    "ccland_thresh = 30.0\n",
    "cc_thresh = 50.0\n",
    "\n",
    "\n",
    "\n",
    "#LOOP through each of the glaciers in the DataFrame and download for each path and row\n",
    "for i in range(0, len(pathrows_df.index)):\n",
    "    #SET path and row variables to the LS path and rows of the box\n",
    "    path = pathrows_df['Path'][i]\n",
    "    row = pathrows_df['Row'][i]\n",
    "    #print(path, row)\n",
    "    \n",
    "    #1) CREATE path and row folders to download into and set input output paths\n",
    "    #SET path row folder name\n",
    "    folder_name = 'Path'+path+'_Row'+row\n",
    "    print(folder_name)\n",
    "    \n",
    "    #SET input path\n",
    "    bp_in = 's3://landsat-pds/L8/'\n",
    "    totalp_in = bp_in+path+'/'+row+'/'\n",
    "    #print(totalp_in)\n",
    "\n",
    "    #SET output path\n",
    "    bp_out = basepath+'LS8aws/'+folder_name+'/'\n",
    "    #print(bp_out)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #IF the folder exists, it's already been downloaded, do not attempt download.\n",
    "    if os.path.exists(bp_out):\n",
    "        print(folder_name, \" EXISTS ALREADY. SKIP.\")\n",
    "    #2) OTHERWISE, create the folder and download into it\n",
    "    else:\n",
    "        os.mkdir(bp_out)\n",
    "        print(folder_name+\" directory made\")\n",
    "\n",
    "        \n",
    "        #3) DOWNLOAD metadata files into the new path-row folder\n",
    "        #CHECK COMMAND SYNTAX\n",
    "        command = 'source activate aws; aws --no-sign-request s3 cp '+totalp_in+' '+bp_out+' --recursive --exclude \"*\" --include \"*.txt\"'\n",
    "        #print(command)\n",
    "        subprocess.call(command, shell=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #4) LOOP through all the files in the path_row folder to download based on cloud cover\n",
    "        # in the metadata files\n",
    "        for image in os.listdir(bp_out):\n",
    "            if image.startswith(\"LC\"):\n",
    "                #list the name of the image folder\n",
    "                print(image)\n",
    "\n",
    "                #open the metadata file within that folder\n",
    "                mdata = open(bp_out+image+\"/\"+image+\"_MTL.txt\", \"r\")\n",
    "\n",
    "                #set a detection variable for whether or not the metadata contains land cloud cover\n",
    "                ccl_detected = False\n",
    "\n",
    "                #loop through each line in metadata to find the land cloud cover\n",
    "                for line in mdata:\n",
    "                    cc_variable = line.split(\"=\")[0]\n",
    "\n",
    "                    #if there is land cloud cover:\n",
    "                    if (\"CLOUD_COVER_LAND\" in cc_variable):\n",
    "                        #save it:\n",
    "                        ccl = np.float(line.split(\"=\")[1])\n",
    "\n",
    "                        #switch the ccl detected variable to True\n",
    "                        ccl_detected = True\n",
    "\n",
    "                        #if the ccl is less than the threshold, delete the file\n",
    "                        if ccl > ccland_thresh:\n",
    "                            #remove the image directory\n",
    "                            #subprocess.call('rm -r '+bp_out+image, shell=True)\n",
    "                            print(ccl, ' > ', ccland_thresh, \", \", image, \"removed\")\n",
    "                        #otherwise: \n",
    "                        else:\n",
    "                            #download the B8 file\n",
    "                            #subprocess.call('source activate aws; aws --no-sign-request s3 cp '+totalp_in+' '+bp_out+' --recursive --exclude \"*\" --include \"*B8.TIF\"', shell=True)\n",
    "                            print(image, \"B8 downloaded -ccl \")\n",
    "\n",
    "                print(\"CCL detected = \", ccl_detected)\n",
    "\n",
    "                #if False,use the overall cloud cover:\n",
    "                if ccl_detected == False:   \n",
    "                    print(\"CCL not detected, use CC.\")\n",
    "\n",
    "                    #open the metadata file again\n",
    "                    mdata = open(bp_out+image+\"/\"+image+\"_MTL.txt\", \"r\")\n",
    "                    for line in mdata:\n",
    "                        variable = line.split(\"=\")[0]\n",
    "\n",
    "                        #now there should only be one line starting with cloud_cover\n",
    "                        if (\"CLOUD_COVER\" in variable):       \n",
    "                            #save the cloud cover:\n",
    "                            cc = np.float(line.split(\"=\")[1])\n",
    "\n",
    "                            #if the cc is less than the threshold, delete the file:\n",
    "                            if cc > cc_thresh:\n",
    "                                #remove the image directory\n",
    "                                #subprocess.call('rm -r '+bp_out+image, shell=True)\n",
    "                                print(cc, ' > ', cc_thresh, \", \", image, \"removed\")\n",
    "\n",
    "                            #otherwise: \n",
    "                            else:\n",
    "                                #DOWNLOAD THE B8 FILE\n",
    "                                #subprocess.call('source activate aws; aws --no-sign-request s3 cp '+totalp_in+' '+bp_out+' --recursive --exclude \"*\" --include \"*B8.TIF\"', shell=True)\n",
    "                                print(image, \"B8 downloaded -cc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For download using Google instead, follow these instructions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use gsutil: https://krstn.eu/landsat-batch-download-from-google/\n",
    "\n",
    "To access a scene for Path 124, Row 053, use this syntax:\n",
    "\n",
    "gsutil cp -n gs://earthengine-public/landsat/L8/124/053/LC81240532013107LGN01.tar.bz /landsat/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
