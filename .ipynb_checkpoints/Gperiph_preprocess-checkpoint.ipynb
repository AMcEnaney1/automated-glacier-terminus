{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greenland peripherial glacier pre-image download processing\n",
    "\n",
    "#### Jukes Liu\n",
    "__Last modified 10-15-2019.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import packages, set base path, set glaciers of interest by BoxID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "\n",
    "#SET basepath to your own folder\n",
    "basepath='/home/jukes/Documents/Sample_glaciers/'\n",
    "\n",
    "#ENTER list of glaciers of interest by BoxID\n",
    "#make this into a widget where you can enter them in?\n",
    "BOXIDS = ['001', '002', '004', '033', '120', '174', '235', '259', '277', '531'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create buffer zone around terminus boxes and rasterize/subset terminus boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code pulls the buffer distances around the terminus boxes from an existing .csv file with the exported attributes tables for the peripheral glacier terminus boxes. These buffer distances will be used to create a buffer zone to subset the Landsat scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001: 1766 meters\n",
      "Box002: 6741 meters\n",
      "Box004: 7112 meters\n",
      "Box033: 5424 meters\n",
      "Box120: 1720 meters\n",
      "Box174: 3729 meters\n",
      "Box235: 2620 meters\n",
      "Box259: 6974 meters\n",
      "Box277: 2273 meters\n",
      "Box531: 2657 meters\n"
     ]
    }
   ],
   "source": [
    "#PULL buffer distances around terminus boxes from a csv file of attributes\n",
    "df=pd.read_csv(basepath+'Boxes_attributes.csv', sep=','); #reads in csv file \n",
    "df_buffdist = df[\"Buff_dist\"].copy(); #creates a dataframe of the buffer distances\n",
    "\n",
    "df_boxid = df[\"BoxID\"].copy(); #creates a data frame of the BoxIDs\n",
    "df_b = pd.concat([df_buffdist, df_boxid], axis=1); #concatenates the two columns\n",
    "\n",
    "#CREATE dictionary of buffer distances with BoxID as the key\n",
    "bd = df_b.set_index('BoxID').T.to_dict('list'); #turns the concatenated df into a dictionary\n",
    "\n",
    "#PRINT buffer distances for the glaciers of interest\n",
    "for BoxID in BOXIDS: \n",
    "    bd_key = int(BoxID)\n",
    "    buff_dist = str(int(bd[bd_key][0]))\n",
    "    print(\"Box\"+BoxID+\":\", buff_dist, \"meters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section creates a buffer zone using GDAL command **ogr2ogr** with the following syntax:\n",
    "\n",
    "    ogr2ogr Buffer###.shp path_to_terminusbox###.shp  -dialect sqlite -sql \"SELECT ST_Buffer(geometry, buffer_distance) AS geometry,*FROM 'Box###'\" -f \"ESRI Shapefile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001\n",
      "Box002\n",
      "Box004\n",
      "Box033\n",
      "Box120\n",
      "Box174\n",
      "Box235\n",
      "Box259\n",
      "Box277\n",
      "Box531\n"
     ]
    }
   ],
   "source": [
    "#export GDAL path command:\n",
    "export_GDALpath = 'export PATH=/Library/Frameworks/GDAL.framework/Programs:$PATH ; '\n",
    "\n",
    "for BoxID in BOXIDS:\n",
    "    #SET path to the terminus box shapefiles\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    outputbuffer_path = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+\".shp\"\n",
    "    \n",
    "    #PULL the buffer distances as strings from the bd dictionary using the BoxID keys\n",
    "    bd_key = int(BoxID)\n",
    "    buff_dist = str(int(bd[bd_key][0]))\n",
    "    \n",
    "    #SET buffer command and print to check it\n",
    "    buffer_cmd = 'ogr2ogr '+outputbuffer_path+\" \"+terminusbox_path+' -dialect sqlite -sql \"SELECT ST_Buffer(geometry, '+buff_dist+\") AS geometry,*FROM 'Box\"+BoxID+\"'\"+'\" -f \"ESRI Shapefile\"'\n",
    "    #print(export_GDALpath, buffer_cmd)\n",
    "    \n",
    "    subprocess.call(export_GDALpath+buffer_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terminus box shapefiles are then rasterized (to be used as a mask during the WTMM filering) using the GDAL **gdal_rasterize** command and subset to the buffer zone using the GDAL **gdalwarp** command using the following syntax:\n",
    "\n",
    "1) Rasterize\n",
    "\n",
    "    gdal_rasterize -burn 1.0 -tr x_resolution y_resolution -a_nodata 0.0 path_to_terminusbox.shp path_to_terminusbox_raster.TIF\n",
    "\n",
    "The x_resolution and y_resolution are set to be 15.0 (meters) to match the Landsat B8 resolution.\n",
    "    \n",
    "2) Subset\n",
    "\n",
    "    gdalwarp -cutline path_to_Buffer###.shp -crop_to_cutline path_to_terminusbox_raster.TIF path_to_subset_raster_cut.TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001\n",
      "Box002\n",
      "Box004\n",
      "Box033\n",
      "Box120\n",
      "Box174\n",
      "Box235\n",
      "Box259\n",
      "Box277\n",
      "Box531\n"
     ]
    }
   ],
   "source": [
    "#export GDAL path command:\n",
    "export_GDALpath = 'export PATH=/Library/Frameworks/GDAL.framework/Programs:$PATH ; '\n",
    "\n",
    "for BoxID in BOXIDS:\n",
    "    #SET path to the terminus box shapefiles\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    buffer_path = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+\".shp\"\n",
    "    \n",
    "    #output raster path:\n",
    "    terminusraster_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".TIF\"\n",
    "    cutraster_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\"_cut.TIF\"\n",
    "    \n",
    "    #SET commands and print to check\n",
    "    rasterize_cmd = 'gdal_rasterize -burn 1.0 -tr 15.0 15.0 -a_nodata 0.0 '+terminusbox_path+' '+terminusraster_path\n",
    "    subsetbuffer_cmd = 'gdalwarp -cutline '+buffer_path+' -crop_to_cutline '+terminusraster_path+\" \"+cutraster_path\n",
    "    #print(export_GDALpath+rasterize_cmd)\n",
    "    #print(export_GDALpath+subsetbuffer_cmd)\n",
    "    \n",
    "    #RASTERIZE & SUBSET\n",
    "    subprocess.call(export_GDALpath+rasterize_cmd, shell=True)\n",
    "    subprocess.call(export_GDALpath+subsetbuffer_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Calculate average flow direction (weighted by magnitude) for each glacier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code processes 2016-2017 ice velocity data from the ESA Cryoportal to determine each glacier of interest's weighted average flow direction. The ice velocity direction (calculated from yx velocity) and the velocity magnitude at each glacier's terminus  is subset using the terminus box shapefile using a GDAL command (**gdalwarp**) with the following syntax:\n",
    "\n",
    "    gdalwarp -cutline path_to_terminusbox.shp -crop_to_cutline path_to_input_velocity.TIF path_to_output_velocity_at_term###.TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001\n",
      "Box002\n",
      "Box004\n",
      "Box033\n",
      "Box120\n",
      "Box174\n",
      "Box235\n",
      "Box259\n",
      "Box277\n",
      "Box531\n"
     ]
    }
   ],
   "source": [
    "#export GDAL path command:\n",
    "export_GDALpath = 'export PATH=/Library/Frameworks/GDAL.framework/Programs:$PATH ; '\n",
    "\n",
    "for BoxID in BOXIDS:\n",
    "    #SET paths to the terminus box shapefiles and velocity data\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    v_dir_path = basepath+'dir_degree_yx_velocity.tif'\n",
    "    v_mag_path = basepath+'magnitude_velocity.tif'  \n",
    "    \n",
    "    #SET output paths\n",
    "    v_dir_output = basepath+\"Box\"+BoxID+\"/dir_degree_yx_velocity_at_term\"+BoxID+\".tif\"\n",
    "    v_mag_output = basepath+\"Box\"+BoxID+\"/magnitude_velocity_at_term\"+BoxID+\".tif\"\n",
    "    \n",
    "    #SET velocity subset commands and print to check it\n",
    "    v_subset_dir_cmd = 'gdalwarp -cutline '+terminusbox_path+' -crop_to_cutline '+v_dir_path+\" \"+v_dir_output\n",
    "    v_subset_mag_cmd = 'gdalwarp -cutline '+terminusbox_path+' -crop_to_cutline '+v_mag_path+\" \"+v_mag_output\n",
    "    #print(export_GDALpath+v_subset_dir_cmd)\n",
    "    #print(export_GDALpath+v_subset_mag_cmd)\n",
    "    \n",
    "    #SUBSET velocity rasters\n",
    "    subprocess.call(export_GDALpath+v_subset_dir_cmd, shell=True)\n",
    "    subprocess.call(export_GDALpath+v_subset_mag_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, these subset velocity rasters are opened using the **rasterio** package and read into arrays. They are filtered for anomalous values and the velocity magnitudes are converted into weights. Then the **numpy.average()** function is used to calculated the weighted average flow directions where the flow directions of the pixels where the highest velocities are found are weighted more. \n",
    "\n",
    "The resulting average flow direction will be representative of the glacier's main flow. These directions will be used to rotate the images of the glaciers so that their flow is due right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoxID</th>\n",
       "      <th>Flow_dir</th>\n",
       "      <th>Max_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>56.284283</td>\n",
       "      <td>0.043774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>155.987228</td>\n",
       "      <td>3.583226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004</td>\n",
       "      <td>-3.483434</td>\n",
       "      <td>0.623082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>033</td>\n",
       "      <td>142.118164</td>\n",
       "      <td>0.771658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>-77.386398</td>\n",
       "      <td>0.277889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>174</td>\n",
       "      <td>12.677643</td>\n",
       "      <td>0.914503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>235</td>\n",
       "      <td>-145.850769</td>\n",
       "      <td>0.157097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>259</td>\n",
       "      <td>98.999275</td>\n",
       "      <td>3.074901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>277</td>\n",
       "      <td>-65.120186</td>\n",
       "      <td>0.286020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>531</td>\n",
       "      <td>78.835213</td>\n",
       "      <td>0.040785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BoxID    Flow_dir  Max_speed\n",
       "0   001   56.284283   0.043774\n",
       "1   002  155.987228   3.583226\n",
       "2   004   -3.483434   0.623082\n",
       "3   033  142.118164   0.771658\n",
       "4   120  -77.386398   0.277889\n",
       "5   174   12.677643   0.914503\n",
       "6   235 -145.850769   0.157097\n",
       "7   259   98.999275   3.074901\n",
       "8   277  -65.120186   0.286020\n",
       "9   531   78.835213   0.040785"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATE list of glacier average flow directions:\n",
    "boxes = []\n",
    "rot_angles = []\n",
    "max_magnitudes = []\n",
    "\n",
    "\n",
    "for BoxID in BOXIDS :    \n",
    "        #READ velocity direction and magnitude data at terminus for each glacier into an array\n",
    "        direction = rasterio.open(basepath+'Box'+BoxID+'/dir_degree_yx_velocity_at_term'+BoxID+'.tif', \"r\")\n",
    "        dir_array = direction.read()\n",
    "        #print(dir_array.shape)\n",
    "        magnitude = rasterio.open(basepath+'Box'+BoxID+'/magnitude_velocity_at_term'+BoxID+'.tif', \"r\")\n",
    "        mag_array = magnitude.read()\n",
    "        #print(mag_array.shape)\n",
    "        \n",
    "        \n",
    "        #RESHAPE direction array and remove anomalous values\n",
    "        dir2 = dir_array.reshape(dir_array.shape[1] * dir_array.shape[2])\n",
    "        #direction must be between 180 and -180 degrees\n",
    "        mask_dir2 = (dir2 < 180) & (dir2 > -180)\n",
    "        masked_dir = dir2[mask_dir2]\n",
    "        #print(masked_dir.min(), masked_dir.max())\n",
    "\n",
    "        #RESHAPE magnitude array and remove anomalous values\n",
    "        mag2 = mag_array.reshape(mag_array.shape[1] * mag_array.shape[2])\n",
    "        #magnitude must be between 0 and 10 m/d\n",
    "        mask_mag2 = (mag2 < 100) & (mag2 > 0)\n",
    "        masked_mag = mag2[mask_mag2]\n",
    "        #print(masked_mag.min(), masked_mag.max())\n",
    "        \n",
    "    \n",
    "        #CALCULATE weights (0 - 1) from magnitudes\n",
    "        mag_range = masked_mag.max() - masked_mag.min()\n",
    "        stretch = 1/mag_range\n",
    "        weights = stretch*(masked_mag - masked_mag.min())\n",
    "        #print(weights.min(), weights.max()) #should be between 0 and 1\n",
    "        #print(weights.shape, masked_dir.shape)\n",
    "        \n",
    "        \n",
    "        #CALCULATE the weighted average rotation angle\n",
    "        avg_dir = np.average(masked_dir, weights=weights)\n",
    "        #print(avg_dir)\n",
    "        \n",
    "        #APPEND the rotation angles to the dictionary\n",
    "        rot_angles.append(avg_dir)\n",
    "        \n",
    "        #APPEND the maximum flow magnitude\n",
    "        max_magnitudes.append(masked_mag.max())\n",
    "        \n",
    "        #APPEND the BoxID\n",
    "        boxes.append(BoxID)\n",
    "\n",
    "#create dataframe with the calculations\n",
    "velocities_df = pd.DataFrame(list(zip(boxes, rot_angles, max_magnitudes)), columns=['BoxID','Flow_dir', 'Max_speed'])\n",
    "velocities_df = velocities_df.sort_values(by='BoxID')\n",
    "velocities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT MAX VELOCITY AND AVERAGE FLOW DIRECTION TO A .CSV FILE\n",
    "#write the data frame to csv file\n",
    "velocities_df.to_csv(path_or_buf = basepath+'Glacier_velocities.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
