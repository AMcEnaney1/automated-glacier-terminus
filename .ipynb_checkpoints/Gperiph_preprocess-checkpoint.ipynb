{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greenland peripherial glacier pre-image download processing\n",
    "\n",
    "#### Jukes Liu\n",
    "__Last modified 10-15-2019.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import packages, set base path, set glaciers of interest by BoxID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import fiona\n",
    "from shapely.geometry import Polygon, Point\n",
    "import shapely\n",
    "import math\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.misc\n",
    "\n",
    "#SET basepath to your own folder\n",
    "basepath='/home/jukes/Documents/Sample_glaciers/'\n",
    "downloadpath = '/media/jukes/jukes1/LS8aws/'\n",
    "\n",
    "#ENTER list of glaciers of interest by BoxID\n",
    "#make this into a widget where you can enter them in?\n",
    "BOXIDS = ['001', '002', '004', '033', '120', '174', '235', '259', '277', '531'];\n",
    "# BOXIDS = ['Alison', 'Helheim']\n",
    "# BOXIDS = ['147', '148', '149', '150', '152', '190', '191', '192', '193', '194', '195', '195', '196', '213', '214', '215']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, y1, x2, y2):\n",
    "    dist = math.sqrt(((x2-x1)**2) + ((y2-y1)**2))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that uses trigonometry to calculate the slope angle\n",
    "#that each pair of box vertices make\n",
    "def slope_angle(x1, y1, x2, y2):\n",
    "    return np.arctan2(y2-y1, x2-x1)*180/np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create buffer zone around terminus boxes and rasterize/subset terminus boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code pulls the buffer distances around the terminus boxes from an existing .csv file with the exported attributes tables for the peripheral glacier terminus boxes. These buffer distances will be used to create a buffer zone to subset the Landsat scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box147_UTM_23.shp\n",
      "Box147_UTM_24.shp\n",
      "Buffer147_UTM_23.shp\n",
      "Buffer147_UTM_24.shp\n",
      "Box148_UTM_23.shp\n",
      "Box148_UTM_24.shp\n",
      "Buffer148_UTM_24.shp\n",
      "Buffer148_UTM_23.shp\n",
      "Box149_UTM_24.shp\n",
      "Box149_UTM_23.shp\n",
      "Buffer149_UTM_23.shp\n",
      "Buffer149_UTM_24.shp\n",
      "Buffer150_UTM_24.shp\n",
      "Box150_UTM_24.shp\n",
      "Box150_UTM_23.shp\n",
      "Buffer150_UTM_23.shp\n",
      "Box152_UTM_23.shp\n",
      "Buffer152_UTM_24.shp\n",
      "Box152_UTM_24.shp\n",
      "Buffer152_UTM_23.shp\n",
      "Box190_UTM_24.shp\n",
      "Buffer190_UTM_24.shp\n",
      "Box190_UTM_23.shp\n",
      "Buffer190_UTM_23.shp\n",
      "Box191_UTM_24.shp\n",
      "Box191_UTM_23.shp\n",
      "Buffer191_UTM_23.shp\n",
      "Buffer191_UTM_24.shp\n",
      "Buffer192_UTM_23.shp\n",
      "Buffer192_UTM_24.shp\n",
      "Box192_UTM_23.shp\n",
      "Box192_UTM_24.shp\n",
      "Box193_UTM_23.shp\n",
      "Buffer193_UTM_23.shp\n",
      "Buffer193_UTM_24.shp\n",
      "Box193_UTM_24.shp\n",
      "Buffer194_UTM_24.shp\n",
      "Box194_UTM_23.shp\n",
      "Box194_UTM_24.shp\n",
      "Buffer194_UTM_23.shp\n",
      "Buffer195_UTM_23.shp\n",
      "Buffer195_UTM_24.shp\n",
      "Box195_UTM_24.shp\n",
      "Box195_UTM_23.shp\n",
      "Buffer195_UTM_23.shp\n",
      "Buffer195_UTM_24.shp\n",
      "Box195_UTM_24.shp\n",
      "Box195_UTM_23.shp\n",
      "Buffer196_UTM_24.shp\n",
      "Buffer196_UTM_23.shp\n",
      "Box196_UTM_23.shp\n",
      "Box196_UTM_24.shp\n",
      "Box213_UTM_24.shp\n",
      "Buffer213_UTM_24.shp\n",
      "Box213_UTM_23.shp\n",
      "Buffer213_UTM_23.shp\n",
      "Box214_UTM_24.shp\n",
      "Buffer214_UTM_23.shp\n",
      "Buffer214_UTM_24.shp\n",
      "Box214_UTM_23.shp\n",
      "Buffer215_UTM_23.shp\n",
      "Box215_UTM_24.shp\n",
      "Box215_UTM_23.shp\n",
      "Buffer215_UTM_24.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jukes/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: FionaDeprecationWarning: Collection.__next__() is buggy and will be removed in Fiona 2.0. Switch to `next(iter(collection))`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoxID</th>\n",
       "      <th>Buff_dist_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>190</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>191</td>\n",
       "      <td>1685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>193</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>194</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>195</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>195</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>196</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>213</td>\n",
       "      <td>2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>214</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>215</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BoxID  Buff_dist_m\n",
       "0    147         1083\n",
       "1    148          861\n",
       "2    149          662\n",
       "3    150           34\n",
       "4    152          934\n",
       "5    190         1946\n",
       "6    191         1685\n",
       "7    192           33\n",
       "8    193         1509\n",
       "9    194           87\n",
       "10   195           61\n",
       "11   195           61\n",
       "12   196           34\n",
       "13   213         2478\n",
       "14   214         2777\n",
       "15   215          131"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffers = []\n",
    "\n",
    "#Calculate a buffer distance around the terminus box using the UTM projected boxes\n",
    "for BoxID in BOXIDS:\n",
    "    buff_distances = []\n",
    "\n",
    "    for file in os.listdir(basepath+'Box'+BoxID+'/'):\n",
    "        if 'UTM' in file and '.shp' in file:\n",
    "            print(file)\n",
    "            boxpath = basepath+\"Box\"+BoxID+\"/\"+file\n",
    "#             print(boxpath)\n",
    "            \n",
    "            termbox = fiona.open(boxpath)\n",
    "            #grab the box feature:\n",
    "            box = termbox.next()\n",
    "            box_geom= box.get('geometry')\n",
    "            box_coords = box_geom.get('coordinates')[0]\n",
    "#             print(box_geom)\n",
    "            \n",
    "            points = []\n",
    "            for coord_pair in box_coords:\n",
    "                lat = coord_pair[0]\n",
    "                lon = coord_pair[1]\n",
    "                \n",
    "                points.append([lat, lon])\n",
    "            \n",
    "            #Calculate distance between 1 and 2 and distance between 2 and 3\n",
    "            #pick the longer one (length)\n",
    "            coord1 = points[0]\n",
    "            coord2 = points[1]\n",
    "            coord3 = points[2]\n",
    "            \n",
    "            #1 and 2\n",
    "            dist1 = distance(coord1[0], coord1[1], coord2[0], coord2[1])       \n",
    "            #2 and 3\n",
    "            dist2 = distance(coord2[0], coord2[1], coord3[0], coord3[1])\n",
    "            \n",
    "            buff_dist = int(np.max([dist1, dist2]))\n",
    "#             print(buff_dist)\n",
    "            buff_distances.append(buff_dist)\n",
    "    \n",
    "    buffer = buff_distances[0]\n",
    "    buffers.append(buffer)\n",
    "\n",
    "buff_df = pd.DataFrame(list(zip(BOXIDS, buffers)), columns=['BoxID', 'Buff_dist_m'])\n",
    "buff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section creates a buffer zone using GDAL command **ogr2ogr** with the following syntax:\n",
    "\n",
    "    ogr2ogr Buffer###.shp path_to_terminusbox###.shp  -dialect sqlite -sql \"SELECT ST_Buffer(geometry, buffer_distance) AS geometry,*FROM 'Box###'\" -f \"ESRI Shapefile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box147/Buffer147.shp /home/jukes/Documents/Sample_glaciers/Box147/Box147.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1083) AS geometry,*FROM 'Box147'\" -f \"ESRI Shapefile\"\n",
      "Box147\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box148/Buffer148.shp /home/jukes/Documents/Sample_glaciers/Box148/Box148.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 861) AS geometry,*FROM 'Box148'\" -f \"ESRI Shapefile\"\n",
      "Box148\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box149/Buffer149.shp /home/jukes/Documents/Sample_glaciers/Box149/Box149.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 662) AS geometry,*FROM 'Box149'\" -f \"ESRI Shapefile\"\n",
      "Box149\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box150/Buffer150.shp /home/jukes/Documents/Sample_glaciers/Box150/Box150.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 34) AS geometry,*FROM 'Box150'\" -f \"ESRI Shapefile\"\n",
      "Box150\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box152/Buffer152.shp /home/jukes/Documents/Sample_glaciers/Box152/Box152.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 934) AS geometry,*FROM 'Box152'\" -f \"ESRI Shapefile\"\n",
      "Box152\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box190/Buffer190.shp /home/jukes/Documents/Sample_glaciers/Box190/Box190.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1946) AS geometry,*FROM 'Box190'\" -f \"ESRI Shapefile\"\n",
      "Box190\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box191/Buffer191.shp /home/jukes/Documents/Sample_glaciers/Box191/Box191.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1685) AS geometry,*FROM 'Box191'\" -f \"ESRI Shapefile\"\n",
      "Box191\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box192/Buffer192.shp /home/jukes/Documents/Sample_glaciers/Box192/Box192.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 33) AS geometry,*FROM 'Box192'\" -f \"ESRI Shapefile\"\n",
      "Box192\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box193/Buffer193.shp /home/jukes/Documents/Sample_glaciers/Box193/Box193.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1509) AS geometry,*FROM 'Box193'\" -f \"ESRI Shapefile\"\n",
      "Box193\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box194/Buffer194.shp /home/jukes/Documents/Sample_glaciers/Box194/Box194.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 87) AS geometry,*FROM 'Box194'\" -f \"ESRI Shapefile\"\n",
      "Box194\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box195/Buffer195.shp /home/jukes/Documents/Sample_glaciers/Box195/Box195.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 61) AS geometry,*FROM 'Box195'\" -f \"ESRI Shapefile\"\n",
      "Box195\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box195/Buffer195.shp /home/jukes/Documents/Sample_glaciers/Box195/Box195.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 61) AS geometry,*FROM 'Box195'\" -f \"ESRI Shapefile\"\n",
      "Box195\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box196/Buffer196.shp /home/jukes/Documents/Sample_glaciers/Box196/Box196.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 34) AS geometry,*FROM 'Box196'\" -f \"ESRI Shapefile\"\n",
      "Box196\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box213/Buffer213.shp /home/jukes/Documents/Sample_glaciers/Box213/Box213.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 2478) AS geometry,*FROM 'Box213'\" -f \"ESRI Shapefile\"\n",
      "Box213\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box214/Buffer214.shp /home/jukes/Documents/Sample_glaciers/Box214/Box214.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 2777) AS geometry,*FROM 'Box214'\" -f \"ESRI Shapefile\"\n",
      "Box214\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box215/Buffer215.shp /home/jukes/Documents/Sample_glaciers/Box215/Box215.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 131) AS geometry,*FROM 'Box215'\" -f \"ESRI Shapefile\"\n",
      "Box215\n"
     ]
    }
   ],
   "source": [
    "for index, row in buff_df.iterrows():\n",
    "    BoxID = row['BoxID']\n",
    "    buff_dist = str(row['Buff_dist_m'])\n",
    "    \n",
    "    #SET path to the terminus box shapefiles\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    outputbuffer_path = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+\".shp\"\n",
    "    \n",
    "    #SET buffer command and print to check it\n",
    "    buffer_cmd = 'ogr2ogr '+outputbuffer_path+\" \"+terminusbox_path+' -dialect sqlite -sql \"SELECT ST_Buffer(geometry, '+buff_dist+\") AS geometry,*FROM 'Box\"+BoxID+\"'\"+'\" -f \"ESRI Shapefile\"'\n",
    "    print(buffer_cmd)\n",
    "    \n",
    "    subprocess.call(buffer_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terminus box shapefiles are then rasterized (to be used as a mask during the WTMM filering) using the GDAL **gdal_rasterize** command and subset to the buffer zone using the GDAL **gdalwarp** command using the following syntax:\n",
    "\n",
    "1) Rasterize\n",
    "\n",
    "    gdal_rasterize -burn 1.0 -tr x_resolution y_resolution -a_nodata 0.0 path_to_terminusbox.shp path_to_terminusbox_raster.TIF\n",
    "\n",
    "The x_resolution and y_resolution are set to be 15.0 (meters) to match the Landsat B8 resolution.\n",
    "    \n",
    "2) Subset\n",
    "\n",
    "    gdalwarp -cutline path_to_Buffer###.shp -crop_to_cutline path_to_terminusbox_raster.TIF path_to_subset_raster_cut.TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box147\n",
      "Box148\n",
      "Box149\n",
      "Box150\n",
      "Box152\n",
      "Box190\n",
      "Box191\n",
      "Box192\n",
      "Box193\n",
      "Box194\n",
      "Box195\n",
      "Box195\n",
      "Box196\n",
      "Box213\n",
      "Box214\n",
      "Box215\n"
     ]
    }
   ],
   "source": [
    "for index, row in buff_df.iterrows():\n",
    "    BoxID = row['BoxID']\n",
    "    #SET path to the terminus box shapefiles\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    buffer_path = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+\".shp\"\n",
    "    \n",
    "    #output raster path:\n",
    "    terminusraster_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".TIF\"\n",
    "    cutraster_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\"_cut.TIF\"\n",
    "    \n",
    "    #SET commands and print to check\n",
    "    rasterize_cmd = 'gdal_rasterize -burn 1.0 -tr 15.0 15.0 -a_nodata 0.0 '+terminusbox_path+' '+terminusraster_path\n",
    "    subsetbuffer_cmd = 'gdalwarp -cutline '+buffer_path+' -crop_to_cutline '+terminusraster_path+\" \"+cutraster_path\n",
    "    #print(export_GDALpath+rasterize_cmd)\n",
    "    #print(export_GDALpath+subsetbuffer_cmd)\n",
    "    \n",
    "    #RASTERIZE & SUBSET\n",
    "    subprocess.call(rasterize_cmd, shell=True)\n",
    "    subprocess.call(subsetbuffer_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Calculate average flow direction (weighted by magnitude) for each glacier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code processes ice velocity rasters to determine each glacier of interest's weighted average flow direction. The rasters are subset using the terminus box shapefile using a GDAL command (**gdalwarp**) with the following syntax:\n",
    "\n",
    "    gdalwarp -cutline path_to_terminusbox.shp -crop_to_cutline path_to_input_velocity.TIF path_to_output_velocity_at_term###.TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001\n",
      "Box002\n",
      "Box004\n",
      "Box033\n",
      "Box120\n",
      "Box174\n",
      "Box235\n",
      "Box259\n",
      "Box277\n",
      "Box531\n"
     ]
    }
   ],
   "source": [
    "for BoxID in BOXIDS:\n",
    "    #SET paths to the terminus box shapefiles and velocity data\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "\n",
    "#     for vdate in ['2014_15', '2015_16', '2016_17']:\n",
    "    if True == True:\n",
    "#         vdir = 'measures_velocity_dir_degree.tif'; vmag = 'greenland_vel_mosaic250_mag.tif'\n",
    "        vx = 'greenland_vel_mosaic250_vx_v1.tif';vy = 'greenland_vel_mosaic250_vy_v1.tif'\n",
    "        #set input paths\n",
    "#         vdir_in = basepath+vdir; vmag_in = basepath+vmag\n",
    "        vx_in = basepath+vx; vy_in = basepath+vy\n",
    "    \n",
    "        #SET output paths\n",
    "#         vdir_out = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+'_'+vdir; vmag_out = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+'_'+vmag\n",
    "        vx_out = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+'_'+vx; vy_out = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+'_'+vy; \n",
    "    \n",
    "        #SET velocity subset commands and print to check it\n",
    "        v_subset1 = 'gdalwarp -cutline '+terminusbox_path+' -crop_to_cutline '+vx_in+\" \"+vx_out\n",
    "        v_subset2 = 'gdalwarp -cutline '+terminusbox_path+' -crop_to_cutline '+vy_in+\" \"+vy_out\n",
    "#         print(v_subset_dir_cmd); print(v_subset_mag_cmd)\n",
    "\n",
    "        #SUBSET velocity rasters\n",
    "        subprocess.call(v_subset1, shell=True)\n",
    "        subprocess.call(v_subset2, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, these subset velocity rasters are opened using the **rasterio** package and read into arrays. They are filtered for anomalous values and the velocity magnitudes are converted into weights. Then the **numpy.average()** function is used to calculated the weighted average flow directions where the flow directions of the pixels where the highest velocities are found are weighted more. \n",
    "\n",
    "The resulting average flow direction will be representative of the glacier's main flow. These directions will be used to rotate the images of the glaciers so that their flow is due right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.89748\n",
      "148.92923\n",
      "178.67763\n",
      "146.15456\n",
      "284.69482\n",
      "22.610819\n",
      "193.97168\n",
      "101.39329\n",
      "301.74695\n",
      "150.39928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoxID</th>\n",
       "      <th>Flow_dir</th>\n",
       "      <th>Max_speed</th>\n",
       "      <th>Pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>67.897476</td>\n",
       "      <td>0.180412</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>148.929230</td>\n",
       "      <td>3.607409</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004</td>\n",
       "      <td>178.677628</td>\n",
       "      <td>0.335084</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>033</td>\n",
       "      <td>146.154556</td>\n",
       "      <td>1.765913</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>284.694824</td>\n",
       "      <td>0.641524</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>174</td>\n",
       "      <td>22.610819</td>\n",
       "      <td>2.006667</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>235</td>\n",
       "      <td>193.971680</td>\n",
       "      <td>0.225594</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>259</td>\n",
       "      <td>101.393288</td>\n",
       "      <td>3.506471</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>277</td>\n",
       "      <td>301.746948</td>\n",
       "      <td>0.147524</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>531</td>\n",
       "      <td>150.399277</td>\n",
       "      <td>0.029901</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BoxID    Flow_dir  Max_speed  Pixels\n",
       "0   001   67.897476   0.180412       2\n",
       "1   002  148.929230   3.607409      69\n",
       "2   004  178.677628   0.335084     124\n",
       "3   033  146.154556   1.765913      35\n",
       "4   120  284.694824   0.641524       8\n",
       "5   174   22.610819   2.006667      15\n",
       "6   235  193.971680   0.225594      16\n",
       "7   259  101.393288   3.506471      10\n",
       "8   277  301.746948   0.147524      11\n",
       "9   531  150.399277   0.029901      18"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATE list of glacier average flow directions:\n",
    "boxes = []; avg_rot = []; max_mag = []; num_cells = []\n",
    "\n",
    "for BoxID in BOXIDS :\n",
    "    rot_angles = []; max_magnitudes = []\n",
    "    \n",
    "#     for vdate in ['2014_15', '2015_16', '2016_17']:\n",
    "    if True == True:\n",
    "        #READ velocity direction and magnitude data at terminus for each glacier into an array\n",
    "        vx_name = 'greenland_vel_mosaic250_vx_v1.tif';vy_name = 'greenland_vel_mosaic250_vy_v1.tif'\n",
    "        vx = rasterio.open(basepath+\"Box\"+BoxID+\"/Box\"+BoxID+'_'+vx_name, \"r\")\n",
    "        vy = rasterio.open(basepath+\"Box\"+BoxID+\"/Box\"+BoxID+'_'+vy_name, \"r\") \n",
    "        vx_array = vx.read(); vy_array = vy.read()\n",
    "        #remove no data values (-2000000000.0)\n",
    "        vx_masked = vx_array[vx_array != -2000000000.0]; vy_masked = vy_array[vy_array != -2000000000.0]\n",
    "#         print(len(vx_masked), len(vy_masked))\n",
    "#         print(vx_masked.max(), vx_masked.min(), vy_masked.max(), vy_masked.min())\n",
    "        \n",
    "        #CALCULATE FLOW DIRECTION\n",
    "        direction = np.arctan2(vy_masked, vx_masked)*180/np.pi; \n",
    "#         print(BoxID, direction.max(), direction.min())\n",
    "        #transform so any negative angles are placed on 0 to 360 scale:\n",
    "        if len(direction[direction < 0]) > 0:\n",
    "            direction[direction < 0] = 360.0+direction[direction < 0]\n",
    "#             print(BoxID, direction.max(), direction.min())\n",
    "        \n",
    "        #CALCULATE SPEED\n",
    "        magnitude = np.sqrt((vx_masked*vx_masked) + (vy_masked*vy_masked))\n",
    "#         print(magnitude.max(), magnitude.min())\n",
    "        \n",
    "#         print(len(direction), len(magnitude))\n",
    "        \n",
    "        #CALCULATE the weighted average rotation angle\n",
    "        #calculate weights (0 - 1) from magnitudes\n",
    "        mag_range = magnitude.max() - magnitude.min()\n",
    "        stretch = 1/mag_range\n",
    "        weights = stretch*(magnitude - magnitude.min())\n",
    "#         print(weights.min(), weights.max()) #should be between 0 and 1\n",
    "#         print(weights.shape, masked_dir.shape)\n",
    "        avg_dir = np.average(direction, weights=weights)\n",
    "        print(avg_dir)\n",
    "        \n",
    "        #APPEND to lists:\n",
    "        avg_rot.append(avg_dir)\n",
    "        max_mag.append(magnitude.max()*0.00273973)\n",
    "        boxes.append(BoxID)\n",
    "        num_cells.append(len(direction))\n",
    "        \n",
    "velocities_df = pd.DataFrame(list(zip(boxes,avg_rot, max_mag, num_cells)), columns=['BoxID','Flow_dir', 'Max_speed', 'Pixels'])\n",
    "velocities_df = velocities_df.sort_values(by='BoxID')\n",
    "velocities_df = velocities_df.drop_duplicates()\n",
    "velocities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #EXPORT MAX VELOCITY AND AVERAGE FLOW DIRECTION TO A .CSV FILE\n",
    "# #write the data frame to csv file\n",
    "velocities_df.to_csv(path_or_buf = basepath+'Glacier_vel_measures_sample10.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Rotate all images by flow direction\n",
    "\n",
    "Read in the glacier velocity file as velocities_df if not already loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow_dir</th>\n",
       "      <th>Max_speed</th>\n",
       "      <th>Pixels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoxID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001</th>\n",
       "      <td>67.89747619628906</td>\n",
       "      <td>0.18041196880882263</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002</th>\n",
       "      <td>148.92922973632812</td>\n",
       "      <td>3.6074087115783695</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004</th>\n",
       "      <td>178.67762756347656</td>\n",
       "      <td>0.33508397443992616</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>033</th>\n",
       "      <td>146.15455627441406</td>\n",
       "      <td>1.7659133388775636</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>284.69482421875</td>\n",
       "      <td>0.6415244847628785</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>22.61081886291504</td>\n",
       "      <td>2.0066666109680176</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>193.9716796875</td>\n",
       "      <td>0.22559381039527893</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>101.3932876586914</td>\n",
       "      <td>3.5064711321069337</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>301.7469482421875</td>\n",
       "      <td>0.14752424545749665</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>150.39927673339844</td>\n",
       "      <td>0.029900719612970354</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Flow_dir             Max_speed Pixels\n",
       "BoxID                                                 \n",
       "001     67.89747619628906   0.18041196880882263      2\n",
       "002    148.92922973632812    3.6074087115783695     69\n",
       "004    178.67762756347656   0.33508397443992616    124\n",
       "033    146.15455627441406    1.7659133388775636     35\n",
       "120       284.69482421875    0.6415244847628785      8\n",
       "174     22.61081886291504    2.0066666109680176     15\n",
       "235        193.9716796875   0.22559381039527893     16\n",
       "259     101.3932876586914    3.5064711321069337     10\n",
       "277     301.7469482421875   0.14752424545749665     11\n",
       "531    150.39927673339844  0.029900719612970354     18"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velocities_df = pd.read_csv(basepath+'Glacier_vel_measures_sample10.csv', sep=',', dtype=str)\n",
    "# velocities_df = pd.read_csv(basepath+'Glacier_velocities.csv', sep=',', dtype=str, usecols=[1,2,3])\n",
    "velocities_df = velocities_df.set_index('BoxID')\n",
    "velocities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow_dir</th>\n",
       "      <th>Max_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoxID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001</th>\n",
       "      <td>56.28428268432617</td>\n",
       "      <td>0.043774381279945374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002</th>\n",
       "      <td>155.9872283935547</td>\n",
       "      <td>3.583226442337036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004</th>\n",
       "      <td>-3.483433723449707</td>\n",
       "      <td>0.6230824589729309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>033</th>\n",
       "      <td>142.1181640625</td>\n",
       "      <td>0.7716577649116516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-77.38639831542969</td>\n",
       "      <td>0.27788856625556946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>12.677642822265625</td>\n",
       "      <td>0.9145031571388245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-145.85076904296875</td>\n",
       "      <td>0.15709678828716278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>98.99927520751953</td>\n",
       "      <td>3.0749008655548096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>-65.12018585205078</td>\n",
       "      <td>0.28601959347724915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>78.83521270751953</td>\n",
       "      <td>0.04078477621078491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Flow_dir             Max_speed\n",
       "BoxID                                           \n",
       "001      56.28428268432617  0.043774381279945374\n",
       "002      155.9872283935547     3.583226442337036\n",
       "004     -3.483433723449707    0.6230824589729309\n",
       "033         142.1181640625    0.7716577649116516\n",
       "120     -77.38639831542969   0.27788856625556946\n",
       "174     12.677642822265625    0.9145031571388245\n",
       "235    -145.85076904296875   0.15709678828716278\n",
       "259      98.99927520751953    3.0749008655548096\n",
       "277     -65.12018585205078   0.28601959347724915\n",
       "531      78.83521270751953   0.04078477621078491"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# velocities_df = pd.read_csv(basepath+'Glacier_vel_measures_sample10.csv', sep=',', dtype=str)\n",
    "velocities_df = pd.read_csv(basepath+'Glacier_velocities.csv', sep=',', dtype=str, usecols=[1,2,3])\n",
    "velocities_df = velocities_df.set_index('BoxID')\n",
    "velocities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists.\n",
      "Already exists.\n",
      "Already exists.\n",
      "Already exists.\n",
      "Already exists.\n",
      "Already exists.\n",
      "Already exists.\n",
      "Already exists.\n",
      "Already exists.\n",
      "Already exists.\n"
     ]
    }
   ],
   "source": [
    "#make rotated images directory in BoxID folders if it doesn't already exist\n",
    "for BoxID in BOXIDS:\n",
    "    if os.path.exists(downloadpath+\"Box\"+BoxID+'/rotated/'):\n",
    "        print(\"Already exists.\")\n",
    "        #OTHERWISE, create the folder and download into it\n",
    "    else:\n",
    "        os.mkdir(downloadpath+\"Box\"+BoxID+'/rotated/')\n",
    "        print(\"Folder made for Box\"+BoxID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all files in reprojected folder to png from TIF\n",
    "for BoxID in BOXIDS:\n",
    "    command = 'cd '+downloadpath+'Box'+BoxID+'/reprojected/; '+'mogrify -format png *.TIF'\n",
    "#     print(command)\n",
    "    subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move box raster into reprojected folder:\n",
    "for BoxID in BOXIDS:\n",
    "    boxfile = 'Box'+BoxID+'_raster_cut.png'\n",
    "    boxrasterpath = basepath+'Box'+BoxID+'/'+boxfile\n",
    "    newpath = downloadpath+'Box'+BoxID+'/reprojected/'+boxfile\n",
    "    \n",
    "    shutil.copyfile(boxrasterpath, newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n",
      "002\n",
      "004\n"
     ]
    }
   ],
   "source": [
    "#ROTATE THE IMAGES\n",
    "for BoxID in BOXIDS:\n",
    "    print(BoxID) \n",
    "    #for each file in the reprojected folder:\n",
    "    for file in os.listdir(downloadpath+\"Box\"+BoxID+'/reprojected/'):\n",
    "        if file.endswith('.png'):\n",
    "#             print(file)\n",
    "            img  = Image.open(downloadpath+\"Box\"+BoxID+'/reprojected/'+file)\n",
    "            #rotate the image by the flow direction from flowspeed_df\n",
    "            rotated = img.rotate(-float(velocities_df.loc[BoxID, 'Flow_dir']))\n",
    "            rotated.save(downloadpath+\"Box\"+BoxID+'/rotated/R_'+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Resize images to minimum dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Make sure resized folders are removed\n",
    "# for BoxID in BOXIDS:\n",
    "#     if os.path.exists(downloadpath+\"Box\"+BoxID+'/resized/'):\n",
    "#         shutil.rmtree(downloadpath+\"Box\"+BoxID+'/resized/', ignore_errors=False, onerror=None)\n",
    "#     else:\n",
    "#         print(\"Resized folder already removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jukes/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "for BoxID in BOXIDS:\n",
    "    dimensions_x = []; dimensions_y = []\n",
    "    images = os.listdir(downloadpath+\"Box\"+BoxID+'/rotated/')\n",
    "    for image in images:\n",
    "        img = mpimg.imread(downloadpath+\"Box\"+BoxID+'/rotated/'+image)\n",
    "        dimensions_x.append(img.shape[1]); dimensions_y.append(img.shape[0])\n",
    "    \n",
    "    #find minimum dimensions\n",
    "    min_y = np.min(dimensions_y); min_x = np.min(dimensions_x)\n",
    "    index_y = dimensions_y.index(min_y); index_x = dimensions_x.index(min_x)\n",
    "          \n",
    "    if index_x != index_y:\n",
    "        print('Something is funky with the image dimesions for Box'+BoxID)\n",
    "    else:\n",
    "        crop_y = dimensions_y[index_y]; crop_x = dimensions_x[index_y]\n",
    "\n",
    "        #crop each image if the dimensions are larger than the minimum\n",
    "        for image in images:\n",
    "            img = mpimg.imread(downloadpath+\"Box\"+BoxID+'/rotated/'+image)\n",
    "            if img.shape[1] > crop_x or img.shape[0] > crop_y:\n",
    "                #calculate difference, and divide by 2 to get amount of rows to remove by\n",
    "                diffx_half = (img.shape[1] - crop_x)/2; diffy_half = (img.shape[0] - crop_y)/2\n",
    "#                 print(diffx_half, diffy_half)\n",
    "                \n",
    "                #if the difference is a half pixel, make sure to remove the full value from the first side only\n",
    "                if int(diffx_half) != diffx_half:\n",
    "                    #remember for image slicing y is the first dimension, x is the second\n",
    "                    img_cropx = img[:, int(diffx_half):-int(diffx_half)-1]\n",
    "                #otherwise remove it from both sides:\n",
    "                else:\n",
    "                    img_cropx = img[:, int(diffx_half):-int(diffx_half)]\n",
    "                \n",
    "                #same for y\n",
    "                if int(diffy_half) != diffy_half:   \n",
    "                    img_cropy = img_cropx[int(diffy_half):-int(diffy_half)-1, :]\n",
    "                #otherwise remove it from both sides:\n",
    "                else:\n",
    "                    img_cropy = img_cropx[int(diffy_half):-int(diffy_half), :]\n",
    "                \n",
    "#                 print(BoxID, crop_y, crop_x)\n",
    "#                 print(BoxID, img_cropy.shape)\n",
    "                    \n",
    "                #save over original images\n",
    "                scipy.misc.imsave(downloadpath+\"Box\"+BoxID+'/rotated/'+image, img_cropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all final files to pgm\n",
    "for BoxID in BOXIDS:\n",
    "    command = 'cd '+downloadpath+'Box'+BoxID+'/rotated/; '+'mogrify -format pgm *.png'\n",
    "#     print(command)\n",
    "    subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we're ready for 2D WTMM analysis!\n",
    "\n",
    "## 6) Run Tcl scripts: \n",
    "\n",
    "Pull in the input BoxIDs from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 002 004 033 120 174 235 259 277 531\n"
     ]
    }
   ],
   "source": [
    "inputIDs = \" \".join(BOXIDS)\n",
    "print(inputIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run scr_gaussian.tcl with BoxIDs as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akhalil/src/xsmurf-2.7/main/xsmurf -nodisplay /home/jukes/Documents/Scripts/scr_gaussian.tcl 001 002 004 033 120 174 235 259 277 531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scr_gaussian = '/home/akhalil/src/xsmurf-2.7/main/xsmurf -nodisplay /home/jukes/Documents/Scripts/scr_gaussian.tcl '+inputIDs\n",
    "print(scr_gaussian)\n",
    "subprocess.call(scr_gaussian, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run terminus_pick.tcl with thresholds and BoxIDs as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_thresh = 0.8\n",
    "mod_thresh = 0.8\n",
    "terminus_pick = '/home/akhalil/src/xsmurf-2.7/main/xsmurf -nodisplay /home/jukes/Documents/Scripts/terminus_pick.tcl '+str(size_thresh)+' '+str(mod_thresh)+' '+inputIDs\n",
    "# print(terminus_pick)\n",
    "subprocess.call(terminus_pick, shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
