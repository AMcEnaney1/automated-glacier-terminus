{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to calculate the centroids of the (trimmed) terminus picks\n",
    "\n",
    "#### Jukes Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.image as mpimg\n",
    "import datetime\n",
    "import types\n",
    "import os\n",
    "import cv2\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If output images have not yet been converted to png format from pgm, do it using cell magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /media/jukes/jukes1/LS8aws/Box033/rotated/resized/\n",
    "mogrify -format png *.pgm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Set up\n",
    "\n",
    "- set BoxIDs to calculate centroids for\n",
    "- set mass or size\n",
    "- define the centroid function\n",
    "- read in dates from datetags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoxIDs = ['001', '002', '004', '033', '120', '174', '235', '259', '277', '531']\n",
    "massorsize = \"size\"\n",
    "\n",
    "#Define the centroid function\n",
    "def centroid(x, y):\n",
    "    length = len(x)\n",
    "    return sum(x) / length, sum(y) / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1687, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Img_Date</th>\n",
       "      <th>datetimes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LC80360042017077LGN00</td>\n",
       "      <td>2017-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LC80360042015248LGN00</td>\n",
       "      <td>2015-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LC80360042015184LGN00</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LC80360042016107LGN00</td>\n",
       "      <td>2016-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LC80360042015232LGN00</td>\n",
       "      <td>2015-08-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Img_Date   datetimes\n",
       "0  LC80360042017077LGN00  2017-03-18\n",
       "1  LC80360042015248LGN00  2015-09-05\n",
       "2  LC80360042015184LGN00  2015-07-03\n",
       "3  LC80360042016107LGN00  2016-04-16\n",
       "4  LC80360042015232LGN00  2015-08-20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in datetags csv as datetime_df\n",
    "datetime_df = pd.read_csv('/home/jukes/Documents/Sample_glaciers/datetags.csv', sep=',', dtype=str, header=0, names=['Img_Date', 'datetimes'])\n",
    "print(datetime_df.shape)\n",
    "datetime_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) OPTION A: Calculate centroids for terminus picked using a metric (mass or size)\n",
    "\n",
    "Grabs the terminus pick line coordinates from the .dat files generated from the 2D WTMM in Xsmurf and calculates their centroid using the centroid function. This calculates the centroids for the original dat file (term_dat) AND the trimmed terminus pick (term_trim_dat). Currently only outputs the trimmed termini centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001\n",
      "137 137 137 137 137\n",
      "Box002\n",
      "29 29 29 29 29\n",
      "Box004\n",
      "20 20 20 20 20\n",
      "Box033\n",
      "94 94 94 94 94\n",
      "Box120\n",
      "106 106 106 106 106\n",
      "Box174\n",
      "47 47 47 47 47\n",
      "Box235\n",
      "93 93 93 93 93\n",
      "Box259\n",
      "76 76 76 76 76\n",
      "Box277\n",
      "62 62 62 62 62\n",
      "Box531\n",
      "208 208 208 208 208\n"
     ]
    }
   ],
   "source": [
    "centroid_xs = []\n",
    "centroid_ys = []\n",
    "BOIs_final = []\n",
    "scenenames = []\n",
    "basepath = '/media/jukes/jukes1/LS8aws/'\n",
    "metric = \"terminus_highest\"+massorsize+\"/\" \n",
    "\n",
    "for BOI in BoxIDs:\n",
    "    print(\"Box\"+BOI)\n",
    "    imagepath = basepath+\"Box\"+BOI+\"/rotated/resized/\"\n",
    "\n",
    "#     #make results directory in BoxID folder if it doesn't already exist\n",
    "#     if os.path.exists(basepath+\"Box\"+BOI+\"/Results/\"):\n",
    "#         print(\"RESULTS FOLDER EXISTS ALREADY. SKIP.\")\n",
    "#     #OTHERWISE, create the folder and download into it\n",
    "#     else:\n",
    "#         os.mkdir(basepath+\"Box\"+BOI+\"/Results/\")\n",
    "#         print(\"Results  folder made\")\n",
    "\n",
    "    #make lists to store image data and grab image files\n",
    "    imgfiles = os.listdir(imagepath)\n",
    "    image_arrays = []\n",
    "    dats = []\n",
    "    trimdats = []\n",
    "    imgnames = []\n",
    "    avgpix_values = []\n",
    "    skews = []\n",
    "    BOIs =[]\n",
    "\n",
    "    for imgfile in imgfiles:\n",
    "        #grab image files and append to images list\n",
    "        if imgfile.endswith(BOI+\".png\"):\n",
    "    #         print(imgfile)\n",
    "            image = mpimg.imread(imagepath+imgfile)\n",
    "            imgname = imgfile[0:-4]\n",
    "            scenename = imgname[7:-16]\n",
    "            pathtodat = imagepath+imgname+\".pgm_max_gaussian/\"+metric\n",
    "            datfiles = os.listdir(pathtodat)\n",
    "            \n",
    "        \n",
    "            #NOT FILTERING FOR CLOUDS AGAIN CURRENTLY:\n",
    "            #If pixel values are skewed toward 1, it's prob cloudy\n",
    "            pixelvals = image.reshape(image.shape[0]*image.shape[1])\n",
    "    #         print(pixelvals.shape)\n",
    "            skew = scipy.stats.skew(pixelvals, bias=False)\n",
    "\n",
    "            avgpix_val = np.average(pixelvals)\n",
    "            avgpix_thresh = 0.50  \n",
    "\n",
    "            #if there are 2 datfiles and not cloudy, grab the trimmed and non-trimmed files\n",
    "            if len(datfiles) == 2: #and avgpix_val < avgpix_thresh and skew > -0.80:\n",
    "                #append the image array and the image name to the list\n",
    "                image_arrays.append(image)\n",
    "                imgnames.append(scenename)\n",
    "                skews.append(skew)\n",
    "                avgpix_values.append(avgpix_val)\n",
    "                BOIs.append(BOI)\n",
    "\n",
    "                #find the trimmed dat file and the original\n",
    "                for dat in datfiles:\n",
    "                    if \"trim\" in dat:\n",
    "                        datfile_trim = dat\n",
    "                        trimdats.append(datfile_trim)\n",
    "                    else:\n",
    "                        datfile = dat\n",
    "                        dats.append(datfile)\n",
    "\n",
    "    #         print(image, datfile_trim, datfile)\n",
    "#             else:\n",
    "#                 print(\"NO DAT FILES CREATED FOR TERMINUS PICK\")\n",
    "\n",
    "    print(len(image_arrays), len(dats), len(trimdats), len(imgnames), len(avgpix_values))\n",
    "    images_df = pd.DataFrame(list(zip(imgnames, BOIs, image_arrays, dats, trimdats, avgpix_values, skews)),\n",
    "                  columns=['Scene', 'BoxID','Image array', 'Dat file name', \"Trimmed dat file name\", 'Avg pix val', 'Skew'])\n",
    "    \n",
    "    #JOIN DATAFRAMES\n",
    "    images_df.sort_values(by='Scene')\n",
    "    # images_df\n",
    "    datetime_df = datetime_df.sort_values(by='Img_Date')\n",
    "#     print(datetime_df.head())\n",
    "    \n",
    "    new_df = images_df.set_index('Scene').join(datetime_df.set_index('Img_Date'))\n",
    "    dated_images_df = new_df.sort_values(by='datetimes')\n",
    "#     print(dated_images_df.head())\n",
    "\n",
    "    #CALCULATE ALL CENTROIDS\n",
    "    for index, row in dated_images_df.iterrows():\n",
    "        imagename = index\n",
    "        trimdat = row['Trimmed dat file name']\n",
    "        dat = row['Dat file name']\n",
    "        BoxID = row['BoxID']\n",
    "        \n",
    "        datpath = basepath+\"Box\"+BoxID+\"/rotated/resized/crop_R_\"+imagename+\"_B8_PS_Buffer\"+BoxID+\".pgm_max_gaussian/\"+metric\n",
    "\n",
    "        #Read in dat file as np array and grab x and y values\n",
    "        #TRIMMED:\n",
    "        term_trim_dat = np.loadtxt(datpath+trimdat)\n",
    "\n",
    "        #ORIGINAL:\n",
    "        term_dat = np.loadtxt(datpath+dat)\n",
    "\n",
    "        #ORIGINAL\n",
    "        term_xs = []\n",
    "        term_ys = []\n",
    "\n",
    "        #grab x and y values for the terminus line\n",
    "        for j in term_dat:\n",
    "            x, y = (j[0], j[1])\n",
    "            term_xs.append(x)\n",
    "            term_ys.append(y)\n",
    "\n",
    "        #TRIMMED\n",
    "        term_trim_xs = []\n",
    "        term_trim_ys = []\n",
    "\n",
    "        #grab x and y values for the terminus line\n",
    "        for j in term_trim_dat:\n",
    "    #         print(j)\n",
    "            x, y = (j[0], j[1])\n",
    "            term_trim_xs.append(x)\n",
    "            term_trim_ys.append(y)\n",
    "\n",
    "        #CALCULATE CENTROIDS AND APPEND TO LISTS\n",
    "        center_x, center_y = centroid(term_xs, term_ys)\n",
    "        trim_center_x, trim_center_y = centroid(term_trim_xs, term_trim_ys)\n",
    "        centroid_xs.append(trim_center_x)\n",
    "        centroid_ys.append(trim_center_y)\n",
    "        BOIs_final.append(BoxID)\n",
    "        scenenames.append(imagename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) OPTION B: Calculate midpoints for terminus picked using a metric (mass or size)\n",
    "\n",
    "Grabs the terminus pick line coordinates from the .dat files generated from the 2D WTMM in Xsmurf and identifies the middle one/ This calculates the centroids for the trimmed terminus pick (term_trim_dat). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001\n",
      "137 137 137 137 137\n",
      "Box002\n",
      "29 29 29 29 29\n",
      "Box004\n",
      "20 20 20 20 20\n",
      "Box033\n",
      "94 94 94 94 94\n",
      "Box120\n",
      "106 106 106 106 106\n",
      "Box174\n",
      "47 47 47 47 47\n",
      "Box235\n",
      "93 93 93 93 93\n",
      "Box259\n",
      "76 76 76 76 76\n",
      "Box277\n",
      "62 62 62 62 62\n",
      "Box531\n",
      "208 208 208 208 208\n"
     ]
    }
   ],
   "source": [
    "midpoints_xs = []\n",
    "midpoints_ys = []\n",
    "BOIs_final = []\n",
    "scenenames = []\n",
    "basepath = '/media/jukes/jukes1/LS8aws/'\n",
    "metric = \"terminus_highest\"+massorsize+\"/\" \n",
    "\n",
    "for BOI in BoxIDs:\n",
    "    print(\"Box\"+BOI)\n",
    "    imagepath = basepath+\"Box\"+BOI+\"/rotated/resized/\"\n",
    "\n",
    "#     #make results directory in BoxID folder if it doesn't already exist\n",
    "#     if os.path.exists(basepath+\"Box\"+BOI+\"/Results/\"):\n",
    "#         print(\"RESULTS FOLDER EXISTS ALREADY. SKIP.\")\n",
    "#     #OTHERWISE, create the folder and download into it\n",
    "#     else:\n",
    "#         os.mkdir(basepath+\"Box\"+BOI+\"/Results/\")\n",
    "#         print(\"Results  folder made\")\n",
    "\n",
    "    #make lists to store image data and grab image files\n",
    "    imgfiles = os.listdir(imagepath)\n",
    "    image_arrays = []\n",
    "    dats = []\n",
    "    trimdats = []\n",
    "    imgnames = []\n",
    "    avgpix_values = []\n",
    "    skews = []\n",
    "    BOIs =[]\n",
    "\n",
    "    for imgfile in imgfiles:\n",
    "        #grab image files and append to images list\n",
    "        if imgfile.endswith(BOI+\".png\"):\n",
    "    #         print(imgfile)\n",
    "            image = mpimg.imread(imagepath+imgfile)\n",
    "            imgname = imgfile[0:-4]\n",
    "            scenename = imgname[7:-16]\n",
    "            pathtodat = imagepath+imgname+\".pgm_max_gaussian/\"+metric\n",
    "            datfiles = os.listdir(pathtodat)\n",
    "            \n",
    "        \n",
    "            #NOT FILTERING FOR CLOUDS AGAIN CURRENTLY:\n",
    "            #If pixel values are skewed toward 1, it's prob cloudy\n",
    "            pixelvals = image.reshape(image.shape[0]*image.shape[1])\n",
    "    #         print(pixelvals.shape)\n",
    "            skew = scipy.stats.skew(pixelvals, bias=False)\n",
    "\n",
    "            avgpix_val = np.average(pixelvals)\n",
    "            avgpix_thresh = 0.50  \n",
    "\n",
    "            #if there are 2 datfiles and not cloudy, grab the trimmed and non-trimmed files\n",
    "            if len(datfiles) == 2: #and avgpix_val < avgpix_thresh and skew > -0.80:\n",
    "                #append the image array and the image name to the list\n",
    "                image_arrays.append(image)\n",
    "                imgnames.append(scenename)\n",
    "                skews.append(skew)\n",
    "                avgpix_values.append(avgpix_val)\n",
    "                BOIs.append(BOI)\n",
    "\n",
    "                #find the trimmed dat file and the original\n",
    "                for dat in datfiles:\n",
    "                    if \"trim\" in dat:\n",
    "                        datfile_trim = dat\n",
    "                        trimdats.append(datfile_trim)\n",
    "                    else:\n",
    "                        datfile = dat\n",
    "                        dats.append(datfile)\n",
    "\n",
    "    #         print(image, datfile_trim, datfile)\n",
    "#             else:\n",
    "#                 print(\"NO DAT FILES CREATED FOR TERMINUS PICK\")\n",
    "\n",
    "    print(len(image_arrays), len(dats), len(trimdats), len(imgnames), len(avgpix_values))\n",
    "    images_df = pd.DataFrame(list(zip(imgnames, BOIs, image_arrays, dats, trimdats, avgpix_values, skews)),\n",
    "                  columns=['Scene', 'BoxID','Image array', 'Dat file name', \"Trimmed dat file name\", 'Avg pix val', 'Skew'])\n",
    "    \n",
    "    #JOIN DATAFRAMES\n",
    "    images_df.sort_values(by='Scene')\n",
    "    # images_df\n",
    "    datetime_df = datetime_df.sort_values(by='Img_Date')\n",
    "#     print(datetime_df.head())\n",
    "    \n",
    "    new_df = images_df.set_index('Scene').join(datetime_df.set_index('Img_Date'))\n",
    "    dated_images_df = new_df.sort_values(by='datetimes')\n",
    "#     print(dated_images_df.head())\n",
    "\n",
    "    #CALCULATE ALL MIDPOINTS\n",
    "    for index, row in dated_images_df.iterrows():\n",
    "        imagename = index\n",
    "        trimdat = row['Trimmed dat file name']\n",
    "        dat = row['Dat file name']\n",
    "        BoxID = row['BoxID']\n",
    "        \n",
    "        datpath = basepath+\"Box\"+BoxID+\"/rotated/resized/crop_R_\"+imagename+\"_B8_PS_Buffer\"+BoxID+\".pgm_max_gaussian/\"+metric\n",
    "\n",
    "        #Read in dat file as np array and grab x and y values\n",
    "        #TRIMMED:\n",
    "        term_trim_dat = np.loadtxt(datpath+trimdat)\n",
    "\n",
    "        #TRIMMED\n",
    "        term_trim_xs = []\n",
    "        term_trim_ys = []\n",
    "\n",
    "        #grab x and y values for the terminus line\n",
    "        for j in term_trim_dat:\n",
    "    #         print(j)\n",
    "            x, y = (j[0], j[1])\n",
    "            term_trim_xs.append(x)\n",
    "            term_trim_ys.append(y)\n",
    "        \n",
    "        #determine the index of the \"midpoint\" of the terminus line to find the x and y coordinate of it\n",
    "        mid_index = int(np.round_(len(term_trim_xs)/2))\n",
    "        trim_mid_x = term_trim_xs[mid_index]\n",
    "        trim_mid_y = term_trim_ys[mid_index]\n",
    "\n",
    "        #APPEND TO LISTS       \n",
    "        midpoints_xs.append(trim_mid_x)\n",
    "        midpoints_ys.append(trim_mid_y)\n",
    "        BOIs_final.append(BoxID)\n",
    "        scenenames.append(imagename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Store the centroids in a DataFrame and export to a csv file\n",
    "\n",
    "\n",
    "Exports the trimmed terminus midpoints to a csv file called __trim_term_midpoints.csv__.\n",
    "\n",
    "OR \n",
    "\n",
    "Exports the trimmed terminus centroids to a csv file called __trim_centroids.csv__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scene</th>\n",
       "      <th>BoxID</th>\n",
       "      <th>Mid_X</th>\n",
       "      <th>Mid_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LC80330052013125LGN01</td>\n",
       "      <td>001</td>\n",
       "      <td>146.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LC80320052013134LGN03</td>\n",
       "      <td>001</td>\n",
       "      <td>169.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LC80330052013141LGN01</td>\n",
       "      <td>001</td>\n",
       "      <td>184.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LC80360042013146LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>145.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LC80340052013148LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>145.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LC80340052013244LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>143.0</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LC80350052013251LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>139.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LC80360042013258LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>168.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LC80340052013260LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>139.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LC80330052013269LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>135.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LC80310052013271LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>138.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LC80320052014073LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>158.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LC80350052014078LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>155.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LC80310052014082LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>153.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LC80340052014087LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>152.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LC80310052014098LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>148.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LC80360042014101LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>148.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LC80340052014103LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>149.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LC80350052014126LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>146.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LC80370042014140LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>153.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LC80350052014142LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>175.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LC80330052014144LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>147.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LC80310052014146LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>146.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LC80320052014153LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>147.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LC80370042014156LGN01</td>\n",
       "      <td>001</td>\n",
       "      <td>168.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LC80330052014160LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>181.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LC80340052014167LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>129.0</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LC80330052014176LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>143.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LC80310052014178LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>142.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LC80340052014183LGN00</td>\n",
       "      <td>001</td>\n",
       "      <td>152.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>LC80100022016245LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>233.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>LC80080022016247LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>233.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>LC80130022016250LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>232.0</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>LC80110022016252LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>236.0</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>LC80080022016263LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>224.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>LC80150012016264LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>189.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>LC80130022016266LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>LC80110022016268LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>232.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>LC80070022016272LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>235.0</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>LC80060032017075LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>180.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>LC80110022017078LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>172.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>LC80160012017081LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>229.0</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>LC80100022017087LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>173.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>LC80080022017089LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>171.0</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>LC80150012017090LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>190.0</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>LC80060032017091LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>201.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>LC80110022017094LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>173.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>LC80090022017096LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>170.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>LC80070032017098LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>202.0</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>LC80140012017099LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>230.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>LC80120022017101LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>231.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>LC80100022017103LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>173.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>LC80080022017105LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>172.0</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>LC80060032017107LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>202.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>LC80130022017108LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>226.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>LC80090022017112LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>173.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>LC80160012017113LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>229.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>LC80070032017114LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>173.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>LC80140012017115LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>228.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>LC80100022017119LGN00</td>\n",
       "      <td>531</td>\n",
       "      <td>173.0</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>872 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Scene BoxID  Mid_X  Mid_Y\n",
       "0    LC80330052013125LGN01   001  146.0  160.0\n",
       "1    LC80320052013134LGN03   001  169.0  149.0\n",
       "2    LC80330052013141LGN01   001  184.0  153.0\n",
       "3    LC80360042013146LGN00   001  145.0  160.0\n",
       "4    LC80340052013148LGN00   001  145.0  161.0\n",
       "5    LC80340052013244LGN00   001  143.0  162.0\n",
       "6    LC80350052013251LGN00   001  139.0  160.0\n",
       "7    LC80360042013258LGN00   001  168.0  158.0\n",
       "8    LC80340052013260LGN00   001  139.0  161.0\n",
       "9    LC80330052013269LGN00   001  135.0  154.0\n",
       "10   LC80310052013271LGN00   001  138.0  163.0\n",
       "11   LC80320052014073LGN00   001  158.0  160.0\n",
       "12   LC80350052014078LGN00   001  155.0  161.0\n",
       "13   LC80310052014082LGN00   001  153.0  160.0\n",
       "14   LC80340052014087LGN00   001  152.0  158.0\n",
       "15   LC80310052014098LGN00   001  148.0  159.0\n",
       "16   LC80360042014101LGN00   001  148.0  158.0\n",
       "17   LC80340052014103LGN00   001  149.0  159.0\n",
       "18   LC80350052014126LGN00   001  146.0  158.0\n",
       "19   LC80370042014140LGN00   001  153.0  159.0\n",
       "20   LC80350052014142LGN00   001  175.0  152.0\n",
       "21   LC80330052014144LGN00   001  147.0  158.0\n",
       "22   LC80310052014146LGN00   001  146.0  159.0\n",
       "23   LC80320052014153LGN00   001  147.0  159.0\n",
       "24   LC80370042014156LGN01   001  168.0  160.0\n",
       "25   LC80330052014160LGN00   001  181.0  156.0\n",
       "26   LC80340052014167LGN00   001  129.0  169.0\n",
       "27   LC80330052014176LGN00   001  143.0  160.0\n",
       "28   LC80310052014178LGN00   001  142.0  160.0\n",
       "29   LC80340052014183LGN00   001  152.0  165.0\n",
       "..                     ...   ...    ...    ...\n",
       "842  LC80100022016245LGN00   531  233.0  251.0\n",
       "843  LC80080022016247LGN00   531  233.0  258.0\n",
       "844  LC80130022016250LGN00   531  232.0  257.0\n",
       "845  LC80110022016252LGN00   531  236.0  229.0\n",
       "846  LC80080022016263LGN00   531  224.0  248.0\n",
       "847  LC80150012016264LGN00   531  189.0  248.0\n",
       "848  LC80130022016266LGN00   531  238.0  238.0\n",
       "849  LC80110022016268LGN00   531  232.0  260.0\n",
       "850  LC80070022016272LGN00   531  235.0  249.0\n",
       "851  LC80060032017075LGN00   531  180.0  256.0\n",
       "852  LC80110022017078LGN00   531  172.0  250.0\n",
       "853  LC80160012017081LGN00   531  229.0  242.0\n",
       "854  LC80100022017087LGN00   531  173.0  251.0\n",
       "855  LC80080022017089LGN00   531  171.0  249.0\n",
       "856  LC80150012017090LGN00   531  190.0  247.0\n",
       "857  LC80060032017091LGN00   531  201.0  287.0\n",
       "858  LC80110022017094LGN00   531  173.0  250.0\n",
       "859  LC80090022017096LGN00   531  170.0  248.0\n",
       "860  LC80070032017098LGN00   531  202.0  288.0\n",
       "861  LC80140012017099LGN00   531  230.0  259.0\n",
       "862  LC80120022017101LGN00   531  231.0  260.0\n",
       "863  LC80100022017103LGN00   531  173.0  250.0\n",
       "864  LC80080022017105LGN00   531  172.0  249.0\n",
       "865  LC80060032017107LGN00   531  202.0  287.0\n",
       "866  LC80130022017108LGN00   531  226.0  259.0\n",
       "867  LC80090022017112LGN00   531  173.0  251.0\n",
       "868  LC80160012017113LGN00   531  229.0  258.0\n",
       "869  LC80070032017114LGN00   531  173.0  251.0\n",
       "870  LC80140012017115LGN00   531  228.0  259.0\n",
       "871  LC80100022017119LGN00   531  173.0  252.0\n",
       "\n",
       "[872 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midpoints_df = pd.DataFrame(list(zip(scenenames, BOIs_final, midpoints_xs, midpoints_ys)),\n",
    "              columns=['Scene','BoxID', 'Mid_X','Mid_Y'])\n",
    "\n",
    "#save as\n",
    "midpoints_df.to_csv(path_or_buf = '/home/jukes/Documents/Sample_glaciers/trim_term_midpoints_'+massorsize+'.csv', sep=',')\n",
    "midpoints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroids_df = pd.DataFrame(list(zip(scenenames, BOIs_final, centroid_xs, centroid_ys)),\n",
    "#               columns=['Scene','BoxID', 'Centroid_X','Centroid_Y'])\n",
    "\n",
    "# #save as\n",
    "# centroids_df.to_csv(path_or_buf = '/home/jukes/Documents/Sample_glaciers/trim_centroids_'+massorsize+'.csv', sep=',')\n",
    "# centroids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
