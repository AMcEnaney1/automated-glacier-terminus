{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions written for automated-glacier-terminus detection\n",
    "Jukes Liu. _Github: julialiu18_\n",
    "\n",
    " - calc_changerates3\n",
    " - calc_changerates1\n",
    " - remove_dips\n",
    " - remove_jumps\n",
    " - within\n",
    " - distance\n",
    " - to_datetimes\n",
    " - midpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to calculate terminus change rate:\n",
    "def calc_changerates3(df):\n",
    "    import pandas as pd; import numpy as np\n",
    "    tchange50 = []; tchange25 = []; tchange75 = []\n",
    "    \n",
    "    for i in range(0, len(df.index)):\n",
    "        date = list(df['datetimes'])[i]\n",
    "        #grab the earliest date\n",
    "        earliestdate = list(df['datetimes'])[0]\n",
    "        \n",
    "        flowlines = ['tpos50', 'tpos25', 'tpos75']\n",
    "        flowline_changes = []\n",
    "        for flowline in flowlines:\n",
    "            tpos = list(df[flowline])[i]\n",
    "            t_\n",
    "            if date==earliestdate:\n",
    "                changerate = np.NaN\n",
    "            else:\n",
    "                #grab all other subsequent entries\n",
    "                t = date; x=tpos; counter=1; \n",
    "                t_prev = list(df['datetimes'])[i-counter]\n",
    "                while t_prev ==t:\n",
    "                    counter = counter+1\n",
    "                    t_prev = list(df['datetimes'])[i-counter]\n",
    "                \n",
    "                prev_df=df[df['datetimes'] == t_prev].copy()\n",
    "                highestorder = np.min(np.array(prev_df.Order))\n",
    "                positions = np.array(prev_df[prev_df.Order==highestorder][flowline])\n",
    "                x_prev = np.nanmean(positions) #if there are multiple grab the average\n",
    "                \n",
    "                if str(x_prev) == 'NaN':\n",
    "                    changerate = np.NaN()\n",
    "                else:\n",
    "                    #calculate changes and changerate\n",
    "                    dx = x-x_prev; dt = t-t_prev; dt = dt.days\n",
    "                    changerate = dx/dt\n",
    "            \n",
    "            flowline_changes.append(changerate)\n",
    "        tchange50.append(flowline_changes[0]); tchange25 = flowline_changes[1]; tchange75 = flowline_changes[2]\n",
    "    df['changerate50'] = tchange50\n",
    "    df['changerate25'] = tchange25\n",
    "    df['changerate75'] = tchange75\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to calculate terminus change rate:\n",
    "def calc_changerates1(df):\n",
    "    import pandas as pd; import numpy as np\n",
    "    df = df.dropna(subset=['tpos']) # drop any NaN terminus positions\n",
    "    tchange = [] # store the terminus change rates\n",
    "    \n",
    "    for i in range(0, len(df.index)):\n",
    "        date = list(df['datetimes'])[i]; tpos = list(df['tpos'])[i] # grab the date and terminus position\n",
    "        \n",
    "        #CALCULATE TERMINUS CHANGE RATE\n",
    "        earliestdate = list(df['datetimes'])[0] #grab the earliest date\n",
    "        #for the first date, the changerate is nan\n",
    "        if date == earliestdate:\n",
    "            changerate = np.NaN\n",
    "        else: \n",
    "            # set current date and terminus position\n",
    "            t = date; x = tpos; \n",
    "        \n",
    "            #grab previous date of analysis \n",
    "            counter = 1; t_prev = list(df['datetimes'])[i-counter]\n",
    "            \n",
    "            # if it's the same date (previous = current), keep going back while this is true\n",
    "            while t_prev == t:\n",
    "                counter = counter+1; t_prev = list(df['datetimes'])[i-counter]\n",
    "                \n",
    "            # when previous time point is found, grab the terminus positions\n",
    "            prev_df = df[df['datetimes'] == t_prev].copy(); positions = list(prev_df.tpos)\n",
    "            \n",
    "            #if there are multiple, grab the average of all of them\n",
    "            x_prev = np.nanmean(np.array(positions));\n",
    "            \n",
    "            #calculate terminus change for center (dx) in meters and time change (dt in days)\n",
    "            dx = x - x_prev                  \n",
    "            #calculate time change (dt) in days\n",
    "            dt = t - t_prev; dt = dt.days\n",
    "            #calculate change rate\n",
    "            changerate = dx/dt\n",
    "                   \n",
    "        tchange.append(changerate);\n",
    "    df['changerate'] = tchange\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dips(df, flow_thresh, iterations):\n",
    "    import pandas as pd; import numpy as np\n",
    "    for iteration in range(0, iterations):\n",
    "        df = df.reset_index(drop=True); dip_indices = []; # reset indices (this will be important later)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            date = row['datetimes']; rate = row['changerate'] # grab date and change rate\n",
    "            \n",
    "            # for negative change rates:\n",
    "            if rate < 0 and rate < -flow_thresh:\n",
    "                # check the next entry only if it's in the range of indices\n",
    "                if index+1 < len(df.index):  \n",
    "                    # pick the next immediate rate & date\n",
    "                    counter = 1\n",
    "                    nextrate = df.loc[index+counter]['changerate']; nextdate = df.loc[index+counter]['datetimes']                    \n",
    "                    # if next date is the same as the current, increment the counter\n",
    "                    # to grab the next next date until the next date is different from the current\n",
    "                    while nextdate == date and index+counter < len(df.index)-1:\n",
    "                        counter = counter + 1; nextrate = df.loc[index+counter]['changerate']\n",
    "                        nextdate = df.loc[index+counter]['datetimes']\n",
    "\n",
    "                    # if it's a sudden jump (change rate to next > flow_thresh), then we have found a dip\n",
    "                    if nextrate > abs(flow_thresh):\n",
    "                        dip_indices.append(index)\n",
    "                            \n",
    "                # if it's a crazy large negative change, flag it even if there isn't a positive change following\n",
    "                if rate < -(15*abs(flow_thresh)):\n",
    "                    dip_indices.append(index) \n",
    "                    \n",
    "        print(\"Dropping\", len(dip_indices), \"dips\") # show number of dropped indices \n",
    "        \n",
    "        # REMOVE those points and recalculate terminus change rates \n",
    "        df = df.drop(dip_indices); df = calc_changerates1(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_jumps(df, flow_thresh, iterations):\n",
    "    import pandas as pd; import numpy as np\n",
    "    for iteration in range(0, iterations):\n",
    "        df = df.reset_index(drop=True); jump_indices = []\n",
    "\n",
    "        for i in range(0, len(df.index)):\n",
    "            date = list(df['datetimes'])[i]; rate = list(df['changerate'])[i] # grab date and change rate\n",
    "            tpos = list(df['tpos'])[i]; index = list(df.index)[i] # grab the terminus position and index\n",
    "            \n",
    "            # if the change rate is faster than our threshold, then we have found a jump\n",
    "            if rate > abs(flow_thresh):\n",
    "                jump_indices.append(index)\n",
    "\n",
    "            # grab previous date of analysis \n",
    "            counter = 1; prev_date = list(df['datetimes'])[i-counter]\n",
    "            # while the previous date = current, append the counter and find the actual previous timepoint\n",
    "            while prev_date == date:\n",
    "                counter = counter+1; prev_date = list(df['datetimes'])[i-counter]\n",
    "            \n",
    "            # calculate the time between this point and the previous\n",
    "            delta_date = date - prev_date; delta_date = delta_date.days\n",
    "\n",
    "            #if the time gap is more than 2 months, and has a positive change rate\n",
    "            #and the terminus position is more than 80% of the max,\n",
    "            tpos_thresh = 0.8*np.max(np.array(df['tpos']))\n",
    "            #remove it\n",
    "            if delta_date > 60 and rate > 0:\n",
    "                if tpos > tpos_thresh:\n",
    "                    jump_indices.append(index)\n",
    "        print(\"Dropping\", len(jump_indices), \"jumps\") # show number of dropped indices \n",
    "        #drop the indices and reclaculate terminus change rates\n",
    "        df = df.drop(jump_indices)\n",
    "        df = calc_changerates1(df)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to help us find the intersection of a line and a collection of points:\n",
    "#determines if an input value is within a certain range/interval or a setvalue:\n",
    "def within(value, setval, interval):\n",
    "    if value >= setval-interval and value <= setval+interval:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, y1, x2, y2):\n",
    "    dist = (((x2-x1)**2)+((y2-y1)**2))**(1/2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetimes(df):\n",
    "    import datetime; import numpy as np\n",
    "    datetimes = df.loc[:,'datetimes']; datetime_objs = []\n",
    "    for date in datetimes:\n",
    "        datetime_obj = datetime.datetime.strptime(str(date), '%Y-%m-%d'); datetime_obj = np.datetime64(datetime_obj)\n",
    "        datetime_objs.append(datetime_obj)\n",
    "    df['datetimes'] = datetime_objs\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(x1, y1, x2, y2):\n",
    "    midx = (x1+x2)/2; midy = (y1+y2)/2\n",
    "    return midx, midy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_theta():\n",
    "    import pandas as pd; import numpy as np\n",
    "    #MANUAL TERMINUS POSITIONS\n",
    "    manual_path = '/media/jukes/jukes1/Manual/'; manual_filename = 'manual_tpos.csv'\n",
    "    auto_path = '/home/jukes/Documents/Sample_glaciers/'\n",
    "    manual_df = pd.read_csv(manual_path+manual_filename, dtype=str,sep=',')\n",
    "    #SPLIT INTO 3 DATAFRAMES FOR 3 FLOWLINES:\n",
    "    manual50 = manual_df[['BoxID','datetimes', 'intersect_x', 'intersect_y', \n",
    "                                          'tpos50']].copy().reset_index(drop=True).rename(columns={\"tpos50\": \"tpos\"})\n",
    "    manual25 = manual_df[['BoxID','datetimes', 'intersect_x', 'intersect_y', \n",
    "                                          'tpos25']].copy().reset_index(drop=True).rename(columns={\"tpos25\": \"tpos\"})\n",
    "    manual75 = manual_df[['BoxID','datetimes', 'intersect_x', 'intersect_y',\n",
    "                                          'tpos75']].copy().reset_index(drop=True).rename(columns={\"tpos75\": \"tpos\"})\n",
    "    #SIGMAS (DATA ERRORS) ALONG EACH FLOWLINE (FROM INTERANALYST DIFFERENCES)\n",
    "    sigmas = [35.02, 27.65, 30.45]; sigma_avg = np.average(sigmas);\n",
    "    \n",
    "    theta1s = []; theta2s = []\n",
    "    #FOR EACH GLACIER BOXID:\n",
    "    BoxIDs = list(set(manual_df.BoxID))\n",
    "    for BoxID in BoxIDs:\n",
    "        #grab automated tpos\n",
    "        auto50 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline50_filtered.csv', dtype=str,sep=',')\n",
    "        auto25 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline25_filtered.csv', dtype=str,sep=',')\n",
    "        auto75 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline75_filtered.csv', dtype=str,sep=',')\n",
    "        autodfs = [auto50, auto25, auto75]\n",
    "        #grab manual tpos that corresponds to just boxID\n",
    "        manual50_df = manual50[manual50.BoxID == BoxID].copy()\n",
    "        manual25_df = manual25[manual25.BoxID == BoxID].copy()\n",
    "        manual75_df = manual75[manual75.BoxID == BoxID].copy()\n",
    "        manualdfs = [manual50, manual25, manual75]\n",
    "        #calculate difference in terminus positions along the three flowlines\n",
    "        lists3 = []; lists3_norm = []\n",
    "        for i in range(0, len(manualdfs)):\n",
    "            man = manualdfs[i]; auto = autodfs[i]; sigma = sigmas[i]\n",
    "            compare_df = man.merge(auto, how='inner', on=['datetimes'])\n",
    "            #cast terminus positions into float values\n",
    "            compare_df = compare_df.astype({'tpos_x': 'float', 'tpos_y': 'float'})\n",
    "            #subtract the absolute value of the difference and put into df as a column named \"diff\"\n",
    "            compare_df['diff'] = abs(np.array(compare_df.tpos_x) - np.array(compare_df.tpos_y))  \n",
    "            compare_df['diff/sigma'] = abs(np.array(compare_df.tpos_x) - np.array(compare_df.tpos_y))/sigma\n",
    "            lists3.append(list(compare_df['diff']))  \n",
    "            lists3_norm.append(list(compare_df['diff/sigma']))\n",
    "        diff_all = lists3[0]+lists3[1]+lists3[2] #list of all the differences between manual and auto\n",
    "        normalizeddiff_all = lists3_norm[0]+lists3_norm[1]+lists3_norm[2] #list of all the normalized differences\n",
    "        N = len(manual_df) #number of total terminus position points detected\n",
    "        Nfrac = N/(len(manual50_df)+len(manual25_df)+len(manual75_df)) # fraction of manual delineations that automated method picked up\n",
    "\n",
    "        #CALCULATE THETA:\n",
    "        theta1 = (1.0/N)*np.sum(normalizeddiff_all) #sum of normalized differences along flowlines\n",
    "        theta2 = (1.0/N)*(np.sum(diff_all)/sigma_avg) #sum of differences normalized by average sigma\n",
    "        theta1s.append(theta1); theta2s.append(theta2)\n",
    "        #print(\"Theta values:\",theta1, theta2)   \n",
    "        \n",
    "    #CALCULATE OVERALL THETA\n",
    "    theta1_all = np.average(theta1s); theta2_all = np.average(theta2s)\n",
    "#     #organize data in dataframe\n",
    "#     column_titles = ['Theta_avg']+BoxIDs\n",
    "#     theta1_for_df = [theta1_all]+theta1s; theta2_for_df = [theta2_all]+theta2s\n",
    "#     #write to csv\n",
    "#     theta_df = pd.DataFrame(list(zip(column_titles, theta1_for_df, theta2_for_df)), \n",
    "#                  columns=['ID', 'theta1', 'theta2'])\n",
    "#     return theta_df \n",
    "    return theta2_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(size_thresh, mod_thresh, arg_thresh, order, dataset, V, N1, N2):\n",
    "    import subprocess\n",
    "    import os\n",
    "    inputIDs = \" \".join(['001', '002', '120', '174', '259']) # the BoxIDs to input\n",
    "    #from thresholds, pick the lines\n",
    "    terminus_pick = '/home/akhalil/src/xsmurf-2.7/main/xsmurf -nodisplay /home/jukes/Documents/Scripts/terminus_pick'+str(order)+'.tcl '+str(size_thresh)+' '+str(mod_thresh)+' '+str(arg_thresh)+' '+str(dataset)+' '+str(inputIDs)\n",
    "    subprocess.call(terminus_pick, shell=True)\n",
    "#     #from the lines, get the results by calling the .py script in terminal\n",
    "#     results_allglaciers = '/home/jukes/anaconda3/bin/python3.7 /home/jukes/automated-glacier-terminus/Results_allglaciers.py'\n",
    "#     subprocess.call(results_allglaciers, shell=True)\n",
    "    # from the lines, get the results using the new result_all glaciers function:\n",
    "    os.chdir('/home/jukes/automated-glacier-terminus')\n",
    "    from automated_terminus_functions import results_allglaciers\n",
    "    results_allglaciers(V,N1,N2)\n",
    "    #calculate value of theta\n",
    "    return calc_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_allglaciers(download_csv, date_csv, centerline_csv, vel_csv, analysis_date, V, N1, N2):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd    \n",
    "    import scipy.stats\n",
    "    import datetime\n",
    "    import math\n",
    "    import shutil\n",
    "    import subprocess\n",
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.pylab as pl\n",
    "    os.chdir('/home/jukes/automated-glacier-terminus')\n",
    "    from automated_terminus_functions import calc_changerates1, to_datetimes, within, remove_dips, remove_jumps\n",
    "\n",
    "    csvpaths = '/home/jukes/Documents/Sample_glaciers/'; basepath = '/media/jukes/jukes1/LS8aws/'; \n",
    "    massorsize = \"mass\"\n",
    "    \n",
    "    #IMAGE DATES\n",
    "    datetime_df = pd.read_csv(csvpaths+date_csv, sep=',', dtype=str, header=0, names=['Scene', 'datetimes'])\n",
    "    print(datetime_df.shape)\n",
    "          \n",
    "#     #DELINEATION METRIC AND ORDER \n",
    "#     for file in os.listdir(csvpaths):\n",
    "#         if analysis_date in file and file.endswith('.csv'):\n",
    "#             print('found'); thefile = file\n",
    "#     order_df = pd.read_csv(csvpaths+thefile, sep=',', dtype=str, header=1, usecols=[0,1,2,3,4])\n",
    "#     order_df = order_df.dropna()\n",
    "    \n",
    "    #CENTERLINE INFO\n",
    "    centerline_df = pd.read_csv(csvpaths+centerline_csv, sep=',', dtype=str, header=0).set_index('BoxID')\n",
    "    \n",
    "    #GLACIER VELOCITIES\n",
    "    flowspeed_df= pd.read_csv(csvpaths+vel_csv, sep=',', dtype=str).set_index('BoxID')\n",
    "    \n",
    "    BoxIDs = list(pd.read_csv(csvpaths+download_csv, sep=',', dtype=str)['BoxID']) # List of BoxIDs\n",
    "    \n",
    "    for BOI in BoxIDs:\n",
    "        print(\"Box\"+BOI)\n",
    "        metric = \"Datfiles/\"; imagepath = basepath+\"Box\"+BOI+\"/rotated/\"\n",
    "        \n",
    "        order_box_df = pd.read_csv(csvpaths+'terminuspicks_Box'+BOI+'_'+analysis_date+'.csv', \n",
    "                                   sep=',', dtype=str, usecols=[1,2,3,4,0], header = 1)\n",
    "#         order_box_df = order_df[order_df[\"BoxID\"]==BOI].copy()\n",
    "        order_box_df = order_box_df.drop('BoxID', axis=1)\n",
    "        order_box_df = order_box_df.dropna()\n",
    "\n",
    "        #GRAB INFO FROM IMAGE FILES\n",
    "        image_arrays = []; dats = []; trimdats = []; imgnames = []; boxids = []; scales = []\n",
    "        imgfiles = os.listdir(imagepath)\n",
    "        for imgfile in imgfiles:\n",
    "            #grab image files and append to images list\n",
    "            if imgfile.endswith(BOI+\".png\"):\n",
    "                image = mpimg.imread(imagepath+imgfile); imgname = imgfile[0:-4]; scenename = imgname[2:23]\n",
    "                pathtodat = imagepath+imgname+\".pgm_max_gaussian/\"+metric\n",
    "                datfiles = os.listdir(pathtodat)\n",
    "                #if there are datfiles, grab the trimmed and non-trimmed files\n",
    "                if len(datfiles) > 1: \n",
    "                    #find the trimmed dat file and the original\n",
    "                    for dat in datfiles:\n",
    "                        if \"trim\" in dat:\n",
    "                            datfile_trim = dat\n",
    "                            #append to trimmed dats list\n",
    "                            trimdats.append(datfile_trim)\n",
    "                            #grab the scale and append the equivalent original dat\n",
    "                            scale = dat[-7:-4]\n",
    "                            datfile = \"terminus_\"+scale+\".dat\"\n",
    "                            dats.append(datfile)\n",
    "                            #append the image array and the image name to the list\n",
    "                            image_arrays.append(image); imgnames.append(scenename); boxids.append(BOI); scales.append(scale)\n",
    "        images_df = pd.DataFrame(list(zip(imgnames, boxids, image_arrays, dats, trimdats, scales)),\n",
    "                      columns=['Scene','BoxID','Image_array', 'Dat_filename', \"Trimmed_dat_filename\", \"Scale\"])\n",
    "        images_df.sort_values(by='Scene'); datetime_df = datetime_df.sort_values(by='Scene')\n",
    "\n",
    "        #MERGE IMAGE INFO WITH IMAGEDATES AND MERGE WITH ORDER\n",
    "        new_df = images_df.merge(datetime_df, how= 'inner', on = 'Scene')\n",
    "        dated_images_df = new_df.sort_values(by='datetimes', ascending = True)\n",
    "        final_images_df = dated_images_df.merge(order_box_df, how='inner', on=['Scene', 'Scale'])\n",
    "        final_images_df = final_images_df.sort_values(by=['datetimes','Scene','Order'], ascending=True)\n",
    "\n",
    "        #CALCULATE TERMINUS POSITIONS\n",
    "        #LOAD IN REFERENCE POINTS to calculate terminus position with respect to\n",
    "        box_midpoint_x = np.float(centerline_df.loc[BOI, 'lmid50_x']); box_midpoint_y = np.float(centerline_df.loc[BOI, 'lmid50_y'])\n",
    "        boxmid_x_25 = np.float(centerline_df.loc[BOI, 'lmid25_x']); boxmid_y_25 = np.float(centerline_df.loc[BOI, 'lmid25_y'])\n",
    "        boxmid_x_75 = np.float(centerline_df.loc[BOI, 'lmid75_x']); boxmid_y_75 = np.float(centerline_df.loc[BOI, 'lmid75_y'])\n",
    "\n",
    "        #GRAB CENTERLINE POINTS\n",
    "        #grab slopes and intercepts from the dataframe\n",
    "        c_slope = float(centerline_df.loc[BOI]['m50']); c_intercept = float(centerline_df.loc[BOI]['b50']) \n",
    "        c25_slope = float(centerline_df.loc[BOI]['m25']); c25_intercept = float(centerline_df.loc[BOI]['b25'])\n",
    "        c75_slope = float(centerline_df.loc[BOI]['m75']); c75_intercept = float(centerline_df.loc[BOI]['b75'])  \n",
    "\n",
    "        #grab range of x-values\n",
    "        xmin50 = float(box_midpoint_x); xmax50 = float(centerline_df.loc[BOI, 'rmid50_x']); ymid50 = float(box_midpoint_y)\n",
    "        xmin25 = float(boxmid_x_25); xmax25 = float(centerline_df.loc[BOI, 'rmid25_x']); ymid25 = float(boxmid_y_25)\n",
    "        xmin75 = float(boxmid_x_75); xmax75 = float(centerline_df.loc[BOI, 'lmid75_x']); ymid75 = float(boxmid_y_75)\n",
    "        xmax = np.max([xmax50, xmax25, xmax75]); xmin = np.min([xmin50, xmin25, xmin75]); c_x = np.linspace(xmin, xmax, int(xmax-xmin)*2)\n",
    "\n",
    "        #calculate y-values using the various centerlines\n",
    "        c_y = c_slope*c_x + c_intercept; c_y_25 = c25_slope*c_x + c25_intercept; c_y_75 = c75_slope*c_x + c75_intercept\n",
    "\n",
    "        #LISTS TO HOLD TERMINUS POSITIONS AND INTERSECTION POINTS\n",
    "        terminus_positions = []; tpositions_25 = []; tpositions_75 = []\n",
    "        intersections = []; X25 = []; X75 = []\n",
    "\n",
    "        #for each scene and scale:\n",
    "        for index, row in final_images_df.iterrows():\n",
    "            trimdat = row['Trimmed_dat_filename']; dat = row['Dat_filename']; scene = row['Scene']    \n",
    "            #CALCULATE TERMINUS POSITION\n",
    "            #load in dat files and calculate intersection points\n",
    "            datpath = imagepath+\"R_\"+scene+\"_B8_PS_Buffer\"+BOI+\".pgm_max_gaussian/\"+metric\n",
    "        #     term_trimdat = np.loadtxt(datpath+trimdat)\n",
    "            term_dat = np.loadtxt(datpath+dat)                          \n",
    "            intersect_xs = []; intersect_xs_25 = []; intersect_xs_75 = []\n",
    "            intersect_ys = []; intersect_ys_25 = []; intersect_ys_75 = []\n",
    "\n",
    "            #loop through all the x,y values for the centerline\n",
    "            for j in range(0, len(c_x)):\n",
    "                x = c_x[j]; y = c_y[j]; y25 = c_y_25[j]; y75 = c_y_75[j]        \n",
    "                interval = 0.6\n",
    "                #where are the intersections with the terminus pick?\n",
    "        #         for dat_x, dat_y in term_trimdat:\n",
    "                for dat_x, dat_y in term_dat:\n",
    "                    #midway centerline\n",
    "                    if within(dat_x, x, interval) and within (dat_y, y, interval):\n",
    "                        #intersect_x = dat_x; intersect_y = dat_y; intersect_found = True\n",
    "                        intersect_xs.append(dat_x); intersect_ys.append(dat_y)            \n",
    "                    #1/4th centerline\n",
    "                    if within(dat_x, x, interval) and within (dat_y, y25, interval):\n",
    "                        intersect_xs_25.append(dat_x); intersect_ys_25.append(dat_y)              \n",
    "                    #3/4th centerline\n",
    "                    if within(dat_x, x, interval) and within (dat_y, y75, interval):\n",
    "                        intersect_xs_75.append(dat_x); intersect_ys_75.append(dat_y)\n",
    "            #for 50 centerline\n",
    "            #if no intersections are found with the terminus line, append Nans\n",
    "            if len(intersect_xs) == 0:\n",
    "                tpos50 = np.NaN; intersect_x = np.NaN; intersect_y = np.NaN\n",
    "            #if at least one is found:\n",
    "            else:\n",
    "                #intersection with the greatest x\n",
    "                #use distance formula to calculate distance between\n",
    "                max_index = intersect_xs.index(np.max(intersect_xs))\n",
    "                intersect_x = intersect_xs[max_index]; intersect_y = intersect_ys[max_index]\n",
    "        #         term_position = distance(xmin50, ymid50, intersect_x, intersect_y)*15.0\n",
    "                tpos50 = (intersect_x-xmin50)*15.0\n",
    "        #         print(tpos50)\n",
    "\n",
    "            #for 25 centerline\n",
    "            if len(intersect_xs_25) == 0:\n",
    "                tpos25 = np.NaN; intersect_x25 = np.NaN; intersect_y25 = np.NaN\n",
    "            else:\n",
    "                max_index_25 = intersect_xs_25.index(np.max(intersect_xs_25))\n",
    "                intersect_x25 = intersect_xs_25[max_index_25]; intersect_y25 = intersect_ys_25[max_index_25]\n",
    "                tpos25 = (intersect_x25-xmin25)*15.0\n",
    "        #         tpos25 = distance(xmin25, ymid25, intersect_x25, intersect_y25)*15.0\n",
    "\n",
    "            #for 75 centerline\n",
    "            if len(intersect_xs_75) == 0:\n",
    "                tpos75 = np.NaN; intersect_x75 = np.NaN; intersect_y75 = np.NaN\n",
    "            else:\n",
    "                max_index_75 = intersect_xs_75.index(np.max(intersect_xs_75))\n",
    "                intersect_x75 = intersect_xs_75[max_index_75]; intersect_y75 = intersect_ys_75[max_index_75]\n",
    "                tpos75 = (intersect_x75-xmin75)*15.0\n",
    "        #         tpos75 = distance(xmin75, ymid75, intersect_x75, intersect_y75)*15.0\n",
    "\n",
    "            #append to lists\n",
    "            terminus_positions.append(tpos50); tpositions_25.append(tpos25); tpositions_75.append(tpos75)\n",
    "            intersections.append([intersect_x, intersect_y]); X25.append([intersect_x25, intersect_y25]); X75.append([intersect_x75, intersect_y75])\n",
    "\n",
    "        # ADD TERMINUS POSITION AND INTERSECTIONS\n",
    "        final_images_df['tpos50'] = terminus_positions; final_images_df['tpos25'] = tpositions_25; final_images_df['tpos75'] = tpositions_75\n",
    "        final_images_df['X50'] = intersections ;final_images_df['X25'] = X25; final_images_df['X75'] = X75\n",
    "\n",
    "        #SPLIT INTO 3 DATAFRAMES FOR 3 FLOWLINES:\n",
    "        final_images_50 = final_images_df[['Scene', 'BoxID', 'Scale', 'datetimes', 'Metric', 'Order', \n",
    "                                          'tpos50', 'X50',]].copy().reset_index(drop=True)\n",
    "        final_images_50 = final_images_50.rename(columns={\"tpos50\": \"tpos\", \"X50\": \"X\"})\n",
    "        final_images_25 = final_images_df[['Scene', 'BoxID', 'Scale', 'datetimes', 'Metric', 'Order', \n",
    "                                          'tpos25', 'X25']].copy().reset_index(drop=True)\n",
    "        final_images_25 = final_images_25.rename(columns={\"tpos25\": \"tpos\", \"X25\": \"X\"})\n",
    "        final_images_75 = final_images_df[['Scene', 'BoxID', 'Scale', 'datetimes', 'Metric', 'Order', \n",
    "                                          'tpos75', 'X75']].copy().reset_index(drop=True)\n",
    "        final_images_75 = final_images_75.rename(columns={\"tpos75\": \"tpos\", \"X75\": \"X\"})\n",
    "        dfs = [final_images_50, final_images_25, final_images_75]\n",
    "\n",
    "        #CALCULATE TERMINUS CHANGE RATES\n",
    "        dfs_new = []\n",
    "        for df in dfs: \n",
    "            to_datetimes(df); dfs_new.append(calc_changerates1(df))\n",
    "\n",
    "        #FILTER USING 5*MAXIMUM FLOW SPEEDS\n",
    "        max_flow = float(flowspeed_df['Max_speed'][BOI])\n",
    "        if max_flow < 1.0:\n",
    "            flow_thresh = V\n",
    "        else:\n",
    "            flow_thresh = V*max_flow\n",
    "        #remove dips\n",
    "#         N1 = 3; \n",
    "        nodips = []\n",
    "        for df in dfs_new:\n",
    "            nodips.append(remove_dips(df, flow_thresh, N1))\n",
    "        #remove jumps\n",
    "#         N2 = 2; \n",
    "        nojumps = []\n",
    "        for df in nodips:\n",
    "            nojumps.append(remove_jumps(df, flow_thresh, N2))\n",
    "        \n",
    "        stop = 0\n",
    "        #stop the process if there are no points\n",
    "        for df in nojumps:\n",
    "            if len(df) == 0:\n",
    "                stop = 1\n",
    "                # print('No points remaining. Processed stopped for Box'+BOI)\n",
    "                \n",
    "        if stop == 0:\n",
    "            #GRAB HIGHEST ORDER PICK AFTER FILTERING\n",
    "            highestorder_dfs = []\n",
    "            for df in nojumps:\n",
    "                    #grab unique dates\n",
    "                    unique_dates = set(list(df['datetimes']))\n",
    "                    # print(len(unique_dates))\n",
    "                    #grab highest orders:\n",
    "                    order_list = []\n",
    "                    for date in unique_dates:\n",
    "                        date_df = df[df['datetimes'] == date].copy()\n",
    "                        highestorder = np.min(np.array(date_df['Order']))\n",
    "                        order_list.append(highestorder)\n",
    "                    highestorder_df = pd.DataFrame(list(zip(unique_dates, order_list)), columns=['datetimes', 'Order']).sort_values(by='datetimes', ascending=True)\n",
    "                    highestorder_dfs.append(highestorder_df)\n",
    "\n",
    "            onepick_dfs = []\n",
    "            for i in range(0, len(highestorder_dfs)):\n",
    "                onepick_df = nojumps[i].merge(highestorder_dfs[i], how='inner', on=['datetimes', 'Order'])\n",
    "                onepick_dfs.append(onepick_df)\n",
    "                # print(onepick_df.shape[0])\n",
    "\n",
    "            #PLOT AND SAVE\n",
    "            fig, ax1 = plt.subplots(figsize=(12,4))\n",
    "            markers = ['mo', 'ro', 'bo']\n",
    "            for j in range(0, len(onepick_dfs)):\n",
    "                df = onepick_dfs[j];    print(len(df))\n",
    "                ax1.plot(df['datetimes'], df['tpos'], markers[j], markersize=5, alpha=0.7)\n",
    "            #general plot parameters\n",
    "            ax1.set_ylabel('Terminus position (m)', color='k', fontsize=12)\n",
    "            ax1.set_title(\"Box\"+BOI, fontsize=16); ax1.set_xlabel('Date', fontsize=12)\n",
    "            ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "            #save figure\n",
    "            plt.legend(['1/2', '1/4', '3/4'])\n",
    "            plt.savefig(csvpaths+\"/Figures/Termposition_LS8_m_Box\"+BOI+\"_\"+analysis_date+\".png\", dpi=200)\n",
    "            plt.show()\n",
    "\n",
    "            flowlines = ['flowline50', 'flowline25', 'flowline75']\n",
    "            for k in range(0, len(onepick_dfs)):\n",
    "                df = onepick_dfs[k];\n",
    "                df.to_csv(path_or_buf = csvpaths+'Tpos_Box'+BOI+'_'+flowlines[k]+'_filtered.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
