{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: 2D WTMM and automated terminus picking\n",
    "\n",
    "_Last modified 2022-07-01._\n",
    "\n",
    "This script analyzes image subsets over the glaciers using the adapted 2D Wavelet Transform Modulus Maxima (WTMM) segmentation method, producing terminus delineations.\n",
    "\n",
    "The code is streamlined to analyze images for hundreds of glaciers, specifically, the marine-terminating glaciers along the periphery of Greenland. For use on other glaciers, sections of code must be modified:\n",
    "\n",
    "    ##########################################################################################\n",
    "    \n",
    "    code to modify\n",
    "\n",
    "    ##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyfftw\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import os\n",
    "import json\n",
    "import geojson\n",
    "import pandas as pd\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import datetime\n",
    "from pyproj import Proj\n",
    "\n",
    "from Xsmurf_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "basepath = '/media/jukes/jukes1/LS8aws/' # contains glacier BoxID folders with downloaded/preprocessed images\n",
    "csvpath = '/home/jukes/Documents/Sample_glaciers/' # path to where CSV files are saved\n",
    "rotated_foldername = 'rotated_c2/' # name of subfolder containing preprocessed images for each glacier\n",
    "PSproj = Proj(init='EPSG:3413') # desired projection for output delineations\n",
    "\n",
    "# set glacier IDs here\n",
    "BoxIDs = ['Helheim']\n",
    "# BoxIDs = list(pd.read_csv(csvpath+'Buffdist_SE_1.csv',dtype=str).BoxID) # read from a CSV file\n",
    "print(BoxIDs)\n",
    "\n",
    "# Default values are shown for the following parameters:\n",
    "# Wavelet parameters (dictates number of spatial scales analyzed):\n",
    "amin = 1\n",
    "nOct = 5\n",
    "nVox = 10\n",
    "wavelet = 'gauss'\n",
    "\n",
    "# Terminus pick parameters:\n",
    "size_thresh = 0.4 # minimum size percentile across all images (0.4 recommended)\n",
    "mod_thresh = 0.7 # minimum linemeanmod percentile across all images (0.7 recommended)\n",
    "arg_thresh = 0.1 # minimum left-right argument fraction (0.1 recommended)\n",
    "metric = 0 # 0 = mass, 1 = scaledmass, 2 = size, DEFAULT = 1\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How would you like to run the analysis?\n",
    "\n",
    "    1) All images in a loop (slow)\n",
    "    2) In batches (fast)\n",
    "    3) Just one image (slowest, for development purposes only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1) Process all images in series (loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process all the images for the glaciers specified and show top 5 terminus chains\n",
    "for BoxID in BoxIDs:\n",
    "    t0 = time.time()\n",
    "    processed_image_path = basepath+'Box'+BoxID+'/'+rotated_foldername\n",
    "    imagelist = []\n",
    "    for file in os.listdir(processed_image_path):\n",
    "        if file.endswith('PS.pgm') and 'L1TP' in file: # grab the L1TP corrected images only\n",
    "            imagelist.append(file)\n",
    "        elif file.endswith('cut.pgm'):\n",
    "            boxfile = file\n",
    "        \n",
    "    # Load terminus box\n",
    "    box = Image.open(processed_image_path+boxfile)\n",
    "    box_array = np.array(box)\n",
    "    if len(box_array.shape) == 3: # 3D array\n",
    "        box_array = box_array[:,:,0]/255 # grab 1D slice from array and convert to binary\n",
    "    elif len(box_array.shape) == 2: # 2D array\n",
    "        box_array = box_array # already in binary\n",
    "    print('Box raster dimensions:', box_array.shape)\n",
    "    plt.imshow(box_array); plt.show()  # Display mask\n",
    "\n",
    "    # read in image Greenland Polar Stereographic coordinates\n",
    "    PSy = np.array(pd.read_csv(basepath+'Box'+BoxID+'/'+rotated_foldername+'img_yidx_Box'+BoxID+'.csv',\n",
    "                              delimiter=' ',header=None))\n",
    "    # read in Greenland Polar Stereographic coordinates\n",
    "    PSx = np.array(pd.read_csv(basepath+'Box'+BoxID+'/'+rotated_foldername+'img_xidx_Box'+BoxID+'.csv',\n",
    "                              delimiter=' ',header=None))\n",
    "    \n",
    "    # hold all top chains produced from terminus picking\n",
    "    topchains_alldfs = []\n",
    "    \n",
    "    image_num = 1\n",
    "    # process all the images\n",
    "    for image in imagelist:\n",
    "        img = Image.open(processed_image_path+image)\n",
    "        print(str(image_num)+' out of '+str(len(imagelist))+' '+image)\n",
    "        \n",
    "        # WTMM\n",
    "        counter = 0\n",
    "        all_cmm = [] # to hold all the chains produced\n",
    "        # ascend over all scales\n",
    "        for iOct in np.arange(0, nOct):\n",
    "            for iVox in np.arange(0, nVox):\n",
    "\n",
    "                # calculate scale in pixels\n",
    "                scale = 6/0.86*amin*2**(iOct+(iVox/nVox))\n",
    "                print('Scale: '+str(scale))\n",
    "\n",
    "                # wavelet transform\n",
    "                [dx, dy, mm, m, a] = wtmm2d_v(img, wavelet, scale)\n",
    "                \n",
    "                # emask\n",
    "                masked_a = emask(box_array, a)\n",
    "                masked_mm = emask(box_array, mm)\n",
    "                masked_m = emask(box_array, m)\n",
    "\n",
    "                # chain\n",
    "                cmm = wtmmchains(masked_mm,masked_a,0,scale,counter)\n",
    "\n",
    "                # increment\n",
    "                all_cmm.extend(cmm)\n",
    "                counter = counter +1 \n",
    "       \n",
    "    \n",
    "        # Make directory to store chain jsons:\n",
    "        imgfolder = processed_image_path+image+'_chains/'\n",
    "        if not os.path.exists(imgfolder):\n",
    "            os.mkdir(imgfolder)\n",
    "\n",
    "        # Pick the terminus line\n",
    "        # Find maximum mods and sizes for thresholding\n",
    "        mods = []; sizes = []\n",
    "        for chain in all_cmm:\n",
    "            sizes.append(chain.size)\n",
    "            mods.append(chain.linemeanmod)\n",
    "        maxmod = np.nanmax(mods); maxsize = np.nanmax(sizes)\n",
    "            \n",
    "        mass_or_size = []\n",
    "        passed_chains = []\n",
    "        passcount = 0\n",
    "        for chain in all_cmm:\n",
    "            if chain.linemeanmod > mod_thresh*maxmod: # only chains that pass the mod threshold\n",
    "#                 if chain.size > size_thresh*maxsize: # only chains that pass the size threshold\n",
    "                if chain.size > size_thresh*np.sqrt(len(box_array[box_array > 0])):\n",
    "                    [passedargs, argfrac] = filter_args(chain.args, np.pi/3) # identify the left & right-pointing args\n",
    "                    if argfrac > arg_thresh: # only chains that pass the orientation threshold\n",
    "                        if metric == 0:\n",
    "                            mass_or_size.append(chain.mass)\n",
    "                        elif metric == 1:\n",
    "                            mass_or_size.append(chain.scaledmass)\n",
    "                        else:\n",
    "                            mass_or_size.append(chain.size)\n",
    "                        passcount += 1\n",
    "                        passed_chains.append(chain)\n",
    "        \n",
    "        if passcount > 0: # if chains remain:\n",
    "            # sort by mass or size and grab the top 5\n",
    "            zipped = zip(mass_or_size, passed_chains)              \n",
    "            top_chains = sorted(zipped,reverse=True,\n",
    "                                key=lambda zipped: zipped[0])[:5] # sort chains that passed\n",
    "\n",
    "            # grab info from top 5 chains\n",
    "            scales = []; boxids = []; orders = []; scenes = []; dates = []\n",
    "            # write the top 5 to json\n",
    "            for chain in top_chains:\n",
    "                # grab the chain\n",
    "                chain = chain[1]\n",
    "\n",
    "                # convert dtypes to json serializable dtypes:\n",
    "                chain.size = int(chain.size)\n",
    "                chain.linemeanmod = float(chain.linemeanmod)\n",
    "                chain.mass = float(chain.mass)\n",
    "                chain.scaledmass = float(chain.scaledmass)\n",
    "                chain.args = list(map(float, chain.args))\n",
    "                chain.ix = list(map(int, chain.ix))\n",
    "                chain.iy = list(map(int, chain.iy))\n",
    "                chain.scale = str(chain.scale)\n",
    "                scales.append(chain.scale.zfill(3))\n",
    "                \n",
    "                # grab geographic coordinates\n",
    "                PSys = PSy[chain.iy, chain.ix]; PSxs = PSx[chain.iy,chain.ix]\n",
    "                lons, lats = PSproj(PSxs, PSys, inverse=True) # project to WGS84\n",
    "                polyline = geojson.LineString(list(zip(lons, lats))) # create polyline\n",
    "                features = []\n",
    "                date = datetime.datetime.strptime(image[19:27], '%Y%m%d'); date = date.strftime(\"%Y-%m-%d\")\n",
    "                features.append(geojson.Feature(geometry=polyline,\n",
    "                                                properties={'datetime':date}))\n",
    "                feature_collection = geojson.FeatureCollection(features)\n",
    "\n",
    "                # write chain object to json file\n",
    "                with open(imgfolder+chain.scale.zfill(3)+'_chain.json', 'w') as f:\n",
    "                    json.dump(chain.__dict__, f)\n",
    "                # write georeferenced chain to geojson file\n",
    "                with open(imgfolder+chain.scale.zfill(3)+'_chain.geojson', 'w') as f:\n",
    "                    geojson.dump(feature_collection, f)\n",
    "\n",
    "            topchains_df = pd.DataFrame(top_chains,columns=['Metric','chain'])\n",
    "            rows = len(topchains_df)\n",
    "\n",
    "            for n in range(0,rows):\n",
    "                boxids.append(BoxID.zfill(3)) # box string\n",
    "                order = n+1 # order of chains (already sorted)\n",
    "                orders.append(order)\n",
    "                scenes.append(image[2:-20])\n",
    "                date = datetime.datetime.strptime(image[19:27], '%Y%m%d')\n",
    "                date = date.strftime(\"%Y-%m-%d\"); dates.append(date)\n",
    "            topchains_df['BoxID'] = boxids; topchains_df['Scene'] = scenes\n",
    "            topchains_df['datetimes'] = dates;\n",
    "            topchains_df['Scale'] = scales; topchains_df['Order'] = orders\n",
    "            topchains_df = topchains_df[['BoxID','Scene','datetimes','Scale','Metric','Order']]\n",
    "            topchains_alldfs.append(topchains_df)\n",
    "\n",
    "            # visualize top chains:\n",
    "            colors = pl.cm.viridis(np.linspace(0,1,5)) # generate colors using a colormap\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(np.array(img), aspect='equal', cmap = 'gray')\n",
    "            plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "            for k in range(0, len(top_chains)): # plot chains (purple = top, yellow = 5th)\n",
    "                plt.plot(top_chains[len(top_chains)-1-k][1].ix, \n",
    "                         top_chains[len(top_chains)-1-k][1].iy, 's-', color=colors[k],markersize=0.1)\n",
    "            plt.title(date, fontsize=16)\n",
    "            plt.xticks([]); plt.yticks([])\n",
    "            # make directory to save results to:\n",
    "            resultsfolder = processed_image_path+'results/'\n",
    "            if not os.path.exists(resultsfolder):\n",
    "                os.mkdir(resultsfolder)\n",
    "            plt.savefig(resultsfolder+date+'_'+image[:-4]+'_topchains.png',dpi=200)\n",
    "            plt.show()\n",
    "\n",
    "        image_num = image_num +1\n",
    "\n",
    "    print(str(time.time() - t0)+' sec to process '+str(len(imagelist))+' images.')\n",
    "    # write terminus pick file\n",
    "    today = datetime.datetime.now().strftime(\"%Y_%m_%d\")  # today's date string\n",
    "    terminuspick_df = pd.concat(topchains_alldfs) # concatenate all the top pick data together\n",
    "    terminuspick_df.to_csv(csvpath+'terminuspicks_Box'+BoxID.zfill(3)+'_'+today+'.csv') # write to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2) Parallel process images in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run wtmm2d_img() in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of cpus on machine using os:\n",
    "print(os.cpu_count())\n",
    "\n",
    "################################################################################################\n",
    "# set batch size accordingly\n",
    "# recommendation is to leave one or two cpus available for other background processing\n",
    "batch_size = 10\n",
    "print('Batch size:',batch_size)\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtmm2d_img(image):\n",
    "    topchains_dfs = []       \n",
    "    img = Image.open(processed_image_path+image)\n",
    "    print(image)\n",
    "       \n",
    "    # Make directory to store chain jsons:\n",
    "    imgfolder = processed_image_path+image+'_chains/'\n",
    "    if not os.path.exists(imgfolder):\n",
    "        os.mkdir(imgfolder)\n",
    "        \n",
    "    # WTMM\n",
    "    counter = 0\n",
    "    all_cmm = [] # to hold all the chains produced\n",
    "    # ascend over all scales\n",
    "    for iOct in np.arange(0, nOct):\n",
    "        for iVox in np.arange(0, nVox):\n",
    "\n",
    "            # calculate scale in pixels\n",
    "            scale = 6/0.86*amin*2**(iOct+(iVox/nVox))\n",
    "\n",
    "            # wavelet transform\n",
    "            [dx, dy, mm, m, a] = wtmm2d_v2(img, wavelet, scale)\n",
    "\n",
    "            # emask\n",
    "            masked_a = emask(box_array, a)\n",
    "            masked_mm = emask(box_array, mm)\n",
    "            masked_m = emask(box_array, m)\n",
    "\n",
    "            # chain\n",
    "            cmm = wtmmchains(masked_mm,masked_a,0,scale,counter)\n",
    "\n",
    "            # increment\n",
    "            all_cmm.extend(cmm)\n",
    "            counter = counter +1 \n",
    "\n",
    "    # Pick the terminus line\n",
    "    # Find maximum mods and sizes for thresholding\n",
    "    mods = []; sizes = []\n",
    "    for chain in all_cmm:\n",
    "        sizes.append(chain.size)\n",
    "        mods.append(chain.linemeanmod)\n",
    "    maxmod = np.nanmax(mods); maxsize = np.nanmax(sizes)\n",
    "\n",
    "    mass_or_size = []; passed_chains = []; passcount = 0\n",
    "    for chain in all_cmm:\n",
    "        if chain.linemeanmod > mod_thresh*maxmod: # only chains that pass the mod threshold\n",
    "#                 if chain.size > size_thresh*maxsize: # only chains that pass the size threshold\n",
    "            if chain.size > size_thresh*np.sqrt(len(box_array[box_array > 0])):\n",
    "                [passedargs, argfrac] = filter_args(chain.args, np.pi/3) # identify the left & right-pointing args\n",
    "                if argfrac > arg_thresh: # only chains that pass the orientation threshold\n",
    "                    if metric == 0:\n",
    "                        mass_or_size.append(chain.mass)\n",
    "                    elif metric == 1:\n",
    "                        mass_or_size.append(chain.scaledmass)\n",
    "                    else:\n",
    "                        mass_or_size.append(chain.size)\n",
    "                    passcount += 1\n",
    "                    passed_chains.append(chain)\n",
    "\n",
    "    if passcount > 0: # if chains remain:\n",
    "        # sort by mass or size and grab the top 5\n",
    "        zipped = zip(mass_or_size, passed_chains)              \n",
    "        top_chains = sorted(zipped,reverse=True,\n",
    "                            key=lambda zipped: zipped[0])[:5] # sort chains that passed\n",
    "\n",
    "        # grab info from top 5 chains\n",
    "        scales = []; boxids = []; orders = []; scenes = []; dates = []\n",
    "        # write the top 5 to json\n",
    "        for chain in top_chains:\n",
    "            # grab the chain\n",
    "            chain = chain[1]\n",
    "\n",
    "            # convert dtypes to json serializable dtypes:\n",
    "            chain.size = int(chain.size)\n",
    "            chain.linemeanmod = float(chain.linemeanmod)\n",
    "            chain.mass = float(chain.mass)\n",
    "            chain.scaledmass = float(chain.scaledmass)\n",
    "            chain.args = list(map(float, chain.args))\n",
    "            chain.ix = list(map(int, chain.ix))\n",
    "            chain.iy = list(map(int, chain.iy))\n",
    "            chain.scale = str(chain.scale)\n",
    "            scales.append(chain.scale.zfill(3))\n",
    "\n",
    "            # grab geographic coordinates\n",
    "            PSys = PSy[chain.iy, chain.ix]; PSxs = PSx[chain.iy,chain.ix]\n",
    "            lons, lats = PSproj(PSxs, PSys, inverse=True) # project to WGS84\n",
    "            polyline = geojson.LineString(list(zip(lons, lats))) # create polyline\n",
    "            features = []\n",
    "            date = datetime.datetime.strptime(image[19:27], '%Y%m%d'); date = date.strftime(\"%Y-%m-%d\")\n",
    "            features.append(geojson.Feature(geometry=polyline,\n",
    "                                            properties={'datetime':date}))\n",
    "            feature_collection = geojson.FeatureCollection(features)\n",
    "\n",
    "            # write chain object to json file\n",
    "            with open(imgfolder+chain.scale.zfill(3)+'_chain.json', 'w') as f:\n",
    "                json.dump(chain.__dict__, f)\n",
    "            # write georeferenced chain to geojson file\n",
    "            with open(imgfolder+chain.scale.zfill(3)+'_chain.geojson', 'w') as f:\n",
    "                geojson.dump(feature_collection, f)\n",
    "\n",
    "        topchains_df = pd.DataFrame(top_chains,columns=['Metric','chain'])\n",
    "        rows = len(topchains_df)\n",
    "\n",
    "        for n in range(0,rows):\n",
    "            boxids.append(BoxID.zfill(3)) # box string\n",
    "            order = n+1 # order of chains (already sorted)\n",
    "            orders.append(order)\n",
    "            scenes.append(image[2:-20])\n",
    "            date = datetime.datetime.strptime(image[19:27], '%Y%m%d')\n",
    "            date = date.strftime(\"%Y-%m-%d\"); dates.append(date)\n",
    "        topchains_df['BoxID'] = boxids; topchains_df['Scene'] = scenes\n",
    "        topchains_df['datetimes'] = dates;\n",
    "        topchains_df['Scale'] = scales; topchains_df['Order'] = orders\n",
    "        topchains_df = topchains_df[['BoxID','Scene','datetimes','Scale','Metric','Order']]\n",
    "        topchains_dfs.append(topchains_df)\n",
    "\n",
    "        # visualize top chains:\n",
    "        colors = pl.cm.viridis(np.linspace(0,1,5)) # generate colors using a colormap\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(np.array(img), aspect='equal', cmap = 'gray')\n",
    "        plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "        for k in range(0, len(top_chains)): # plot chains (purple = top, yellow = 5th)\n",
    "            plt.plot(top_chains[len(top_chains)-1-k][1].ix, \n",
    "                     top_chains[len(top_chains)-1-k][1].iy, 's-', color=colors[k],markersize=0.1)\n",
    "        plt.title(date, fontsize=16)\n",
    "        plt.xticks([]); plt.yticks([])\n",
    "        # make directory to save results to:\n",
    "        resultsfolder = processed_image_path+'results/'\n",
    "        if not os.path.exists(resultsfolder):\n",
    "            os.mkdir(resultsfolder)\n",
    "        plt.savefig(resultsfolder+image[:-4]+'_topchains.png',dpi=200)\n",
    "        plt.show()\n",
    "\n",
    "        return topchains_dfs\n",
    "    else:\n",
    "        print('No chains passed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for BoxID in BoxIDs:\n",
    "    t1 = time.time()\n",
    "    processed_image_path = basepath+'Box'+BoxID+'/'+rotated_foldername\n",
    "    imagelist = []\n",
    "    for file in os.listdir(processed_image_path):\n",
    "        if file.endswith('PS.pgm') and 'L1TP' in file: # L1TP corrected images only\n",
    "            imagelist.append(file)\n",
    "        elif file.endswith('cut.pgm'):\n",
    "            boxfile = file\n",
    "        \n",
    "    # Load terminus box\n",
    "    box = Image.open(processed_image_path+boxfile)\n",
    "    box_array = np.array(box)\n",
    "    if len(box_array.shape) == 3: # 3D array\n",
    "        box_array = box_array[:,:,0]/255 # grab 1D slice from array and convert to binary\n",
    "    elif len(box_array.shape) == 2: # 2D array\n",
    "        box_array = box_array # already in binary\n",
    "    print('Box',BoxID,'raster dimensions:', box_array.shape)\n",
    "    plt.imshow(box_array); plt.show()  # Display mask\n",
    "    \n",
    "    # read in image Greenland Polar Stereographic coordinates\n",
    "    PSy = np.array(pd.read_csv(basepath+'Box'+BoxID+'/'+rotated_foldername+'img_yidx_Box'+BoxID+'.csv',\n",
    "                              delimiter=' ',header=None))\n",
    "    # read in Greenland Polar Stereographic coordinates\n",
    "    PSx = np.array(pd.read_csv(basepath+'Box'+BoxID+'/'+rotated_foldername+'img_xidx_Box'+BoxID+'.csv',\n",
    "                              delimiter=' ',header=None))\n",
    "    \n",
    "    # hold all top chains produced from terminus picking\n",
    "    topchains_alldfs = []\n",
    "    \n",
    "    # process all the images in parallel\n",
    "    pcount = 0\n",
    "    image_num = 1\n",
    "    nbatches = int(np.ceil(len(imagelist)/batch_size)) # round up to the next batch size\n",
    "    nfullbatches = int(np.floor(len(imagelist)/batch_size)) # number of full batches\n",
    "    print(nbatches, 'batches')\n",
    "    print(nfullbatches, 'full batches')\n",
    "    \n",
    "    # full batches\n",
    "    for b in range(0, nfullbatches):\n",
    "        pool = Pool() # initialize pool\n",
    "        batchimgs = imagelist[b*batch_size:(b+1)*batch_size]\n",
    "        topchains_dfs = pool.map(wtmm2d_img, batchimgs) # process all in pool\n",
    "        topchains_alldfs += topchains_dfs\n",
    "    \n",
    "    # for the last batch\n",
    "    if nbatches - nfullbatches == 1:\n",
    "        pool = Pool()\n",
    "        lastbatchimgs = imagelist[(b+1)*batch_size:] # grab all remaining images\n",
    "        topchains_dfs = pool.map(wtmm2d_img, lastbatchimgs) # process all in pool\n",
    "        topchains_alldfs += topchains_dfs\n",
    "\n",
    "    dfs = []\n",
    "    for df in topchains_alldfs:\n",
    "        if df == None:\n",
    "            topchains_alldfs.remove(df)\n",
    "        else:\n",
    "            dfs.append(df[0])\n",
    "    \n",
    "    print(str(time.time() - t1)+' sec to process '+str(len(imagelist))+' images.' )\n",
    "    # write terminus pick file\n",
    "    today = datetime.datetime.now().strftime(\"%Y_%m_%d\")  # today's date string\n",
    "    terminuspick_df = pd.concat(dfs) # concatenate all the top pick data together\n",
    "    terminuspick_df = terminuspick_df.reset_index(drop=True) # reset the index\n",
    "    terminuspick_df.to_csv(csvpath+'terminuspicks_Box'+BoxID.zfill(3)+'_'+today+'.csv') # write to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 3) Process 1 image at a time\n",
    "\n",
    "## 3A) Load terminus box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# use terminus box raster to mask out external chains\n",
    "# box = Image.open(basepath+'R_Box174_raster_cut.png')\n",
    "BOI = '012' # BoxID\n",
    "box = Image.open(basepath+'Box'+BOI+'/'+rotated_foldername+'R_Box'+BOI+'_raster_cut.png')\n",
    "######################################################################################\n",
    "if len(box_array.shape) == 3: # 3D array\n",
    "    box_array = box_array[:,:,0]/255 # grab 1D slice from array and convert to binary\n",
    "elif len(box_array.shape) == 2: # 2D array\n",
    "    box_array = box_array # already in binary\n",
    "print(box_array.shape)\n",
    "plt.imshow(box_array); plt.show()  # Display mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B) Open image(s) for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# # open glacier image for testing\n",
    "img = Image.open(basepath+'Box'+BOI+'/'+subfoldername+'R_LC08_L1TP_031005_20150716_20200908_02_T1_B8_Buffer012_PS.pgm')\n",
    "# img = Image.open(basepath+'R_LC08_L1TP_233017_20170813_20170814_01_RT_B8_Buffer174_PS.pgm')\n",
    "# OR generate circle image\n",
    "# img = generate_circle_image(100, 436, 428) # inputs are radius, xsize, ysize\n",
    "######################################################################################\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3C) Run wtmm2d and show outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# [dx,dy,F,f,gx,gy] = wtmm2d(img,'gauss',10)\n",
    "[dx,dy,mm,m,a] = wtmm2d_v2(img,'gauss',25) # scale = 10 pixels\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize outputs from wtmm2d:\n",
    "fig, axs = plt.subplots(2,3,figsize=(15,10))\n",
    "axs[0,0].imshow(dx, aspect='equal', cmap = 'gray', interpolation='none'); axs[0,0].set_title('dx') # x gradient\n",
    "axs[0,1].imshow(dy, aspect='equal', cmap = 'gray', interpolation='none'); axs[0,1].set_title('dy') # y gradient\n",
    "\n",
    "axs[0,2].imshow(a, aspect='equal', cmap = 'gray', interpolation='none'); axs[0,2].set_title('a') # argument            \n",
    "axs[1,0].imshow(mm, aspect='equal', cmap = 'gray', interpolation='none', vmin = np.min(mm), vmax = np.max(m)); \n",
    "axs[1,0].set_title('mm') # modulus maxima (interpolated)\n",
    "axs[1,1].imshow(m, aspect='equal', cmap = 'gray', interpolation='none',vmin = np.min(mm), vmax = np.max(m));\n",
    "axs[1,1].set_title('m') # modulus\n",
    "axs[-1, -1].axis('off')\n",
    "\n",
    "# Image.fromarray(mm).save('mm.tif')   \n",
    "# Image.fromarray(m).save('m.tif')   \n",
    "\n",
    "# plt.savefig('glacier_WTMM_test.png',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D) Mask using terminus box (emask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mask\n",
    "masked_a = emask(box_array, a)\n",
    "masked_mm = emask(box_array, mm)\n",
    "masked_m = emask(box_array, m)\n",
    "\n",
    "# Visualize masked outputs from wtmm2d:\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,10))\n",
    "\n",
    "axs[0].imshow(masked_a, aspect='equal', cmap = 'viridis', interpolation='none'); axs[0].set_title('a')              \n",
    "axs[1].imshow(masked_mm, aspect='equal', cmap = 'gray', interpolation='none', vmin = np.min(masked_mm), vmax = np.max(masked_mm)); \n",
    "axs[1].set_title('mm')\n",
    "axs[2].imshow(masked_m, aspect='equal', cmap = 'gray', interpolation='none',vmin = np.min(masked_m), vmax = np.max(masked_m));\n",
    "axs[2].set_title('m')\n",
    "# plt.savefig('glacier_WTMM_test.png',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3E) Chain remaining mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "cmm = wtmmchains(masked_mm,masked_a,1,10,3) # chain at a specified scale\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmm_passed = []\n",
    "# Filter chains based on size threshold\n",
    "for j in range(0, len(cmm)):\n",
    "    if cmm[j].size > 0: # adjust this condition to threshold\n",
    "        cmm_passed.append(cmm[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(masked_mm,cmap='gray')\n",
    "plt.xlim([0, mm.shape[1]])\n",
    "plt.ylim([0, mm.shape[0]])\n",
    "plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "    \n",
    "for k in range(0, len(cmm_passed)):\n",
    "    plt.plot(cmm_passed[k].ix, cmm_passed[k].iy, 's-', markersize=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3F) Use thresholds on chain properties to pick the glacier terminus chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "size_thresh = 0.4 # Size percentile across all images\n",
    "mod_thresh = 0.7 # Linemeanmod percentile across all images\n",
    "arg_thresh = 0.1 # left-right argument fraction\n",
    "metric = 0 # 0 = mass, 1 = scaledmass, 2 = size\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in Greenland Polar Stereographic coordinates\n",
    "PSy = np.array(pd.read_csv(basepath+'Box'+BOI+'/'+subfoldername+'img_idx_PSy_Box'+BOI+'.csv',\n",
    "                          delimiter=' ',header=None))\n",
    "# read in Greenland Polar Stereographic coordinates\n",
    "PSx = np.array(pd.read_csv(basepath+'Box'+BOI+'/'+subfoldername+'img_idx_PSx_Box'+BOI+'.csv',\n",
    "                          delimiter=' ',header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_or_size = []\n",
    "passed_chains = []\n",
    "for chain in cmm_passed:\n",
    "    if chain.linemeanmod > mod_thresh: # only chains that pass the mod threshold\n",
    "        if chain.size > size_thresh: # only chains that pass the size threshold\n",
    "            [passedargs, argfrac] = filter_args(chain.args, np.pi/3) # identify the left & right-pointing args\n",
    "            if argfrac > arg_thresh: # only chains that pass the orientation threshold\n",
    "                if metric == 0:\n",
    "                    mass_or_size.append(chain.mass) # evaluate by mass (length*gradient value)\n",
    "                elif metric == 1:\n",
    "                    mass_or_size.append(chain.scaled_mass) # evaluate by scaled mass (mass/2**scale)\n",
    "                else:\n",
    "                    mass_or_size.append(chain.size)\n",
    "                PSxs = PSx[np.array(chain.ix,dtype=int)]\n",
    "                PSys = PSy[np.array(chain.iy,dtype=int)]\n",
    "                passed_chains.append(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_chains = pd.DataFrame(list(zip(mass_or_size, passed_chains)), columns=['metric_val','chainobj'])\n",
    "top_chains = top_chains.sort_values(by=['metric_val'],ascending=False) # sort chains with highest metric at top\n",
    "top_chains = top_chains[:5].reset_index(drop=True) # and grab the top 5\n",
    "top_chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize top chains:\n",
    "colors = pl.cm.viridis(np.linspace(0,1,5)) # generate colors using a colormap\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(np.array(nuMage), aspect='equal', cmap = 'gray')\n",
    "plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "for k in range(0, len(top_chains)):\n",
    "    # plot chains, darker = better picks\n",
    "    plt.plot(top_chains.iloc[k][1].ix, top_chains.iloc[k][1].iy, 's-', color=colors[k],markersize=0.1)\n",
    "#     break\n",
    "            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_chains.iloc[k][1].ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoterm",
   "language": "python",
   "name": "autoterm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
