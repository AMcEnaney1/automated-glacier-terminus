{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D WTMM and automated terminus picking\n",
    "\n",
    "_Last modified 2022-05-22._\n",
    "\n",
    "This script analyzes the Landsat 8 image subsets over the glaciers using the 2D Wavelet Transform Modulus Maxima (WTMM) segmentation method, producing automated terminus delineations.\n",
    "\n",
    "The code is streamlined to analyze images for hundreds of glaciers, specifically, the marine-terminating glaciers along the periphery of Greenland. For use on other glaciers, sections of code must be modified:\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "__Indicates code that must be modified__\n",
    "\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 9,
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyfftw\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from Xsmurf_functions import *"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 10,
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['008']\n"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
<<<<<<< HEAD
    "basepath = '/media/jukes/jukes1/LS8aws/' # contains glacier BoxID folders with downloaded/preprocessed images\n",
    "csvpath = '/home/jukes/Documents/Sample_glaciers/' # path to where CSV files are saved\n",
    "subfoldername = 'rotated_c2/' # name of subfolder containing preprocessed images for each glacier\n",
    "\n",
    "# BoxIDs = ['002','531'] # set glacier IDs here\n",
    "BoxIDs = ['008']\n",
    "# BoxIDs = list(pd.read_csv(csvpath+'Buffdist_SE_1.csv',dtype=str).BoxID) # read from a CSV file\n",
=======
    "# basepath = '/Users/jukesliu/Documents/AUTO-TERMINUS/Python_translation/' # CHANGE THIS\n",
    "basepath = '/Users/phoebekinzelman/research/greenland/LS8aws/'\n",
    "csvpath = '/Users/phoebekinzelman/research/greenland/updated_shps/'\n",
    "\n",
    "# BoxIDs = ['002','531'] # set glacier IDs here\n",
    "# BoxIDs = ['HM','Petermann']\n",
    "BoxIDs = ['008']\n",
    "# BoxIDs = list(pd.read_csv(csvpath+'Buffdist_SE_1.csv',dtype=str).BoxID); BoxIDs = BoxIDs[:8]\n",
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
    "print(BoxIDs)\n",
    "\n",
    "# Default values are shown for the following parameters:\n",
    "# Wavelet parameters (dictates number of spatial scales analyzed):\n",
    "amin = 1\n",
    "nOct = 5\n",
    "nVox = 10\n",
    "wavelet = 'gauss'\n",
    "\n",
    "# Terminus pick parameters:\n",
    "size_thresh = 0.4 # minimum size percentile across all images (0.4 recommended)\n",
    "mod_thresh = 0.7 # minimum linemeanmod percentile across all images (0.7 recommended)\n",
    "arg_thresh = 0.1 # minimum left-right argument fraction (0.1 recommended)\n",
    "metric = 1 # 0 = mass, 1 = scaledmass, 2 = size, DEFAULT = 1\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# How would you like to run the analysis?\n",
    "\n",
    "    1) All images in a loop (slow)\n",
    "    2) In batches (fast)\n",
    "    3) Just one image (slowest, for development purposes only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1) Process all images in series (loop)"
=======
    "# Process all images in a loop"
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "# Process all the images for the glaciers specified and show top 5 terminus chains\n",
    "for BoxID in BoxIDs:\n",
    "    t1 = time.time()\n",
    "    processed_image_path = basepath+'Box'+BoxID+'/'+subfoldernmae\n",
    "    imagelist = []\n",
    "    for file in os.listdir(processed_image_path):\n",
    "        if file.endswith('PS.pgm') and 'L1TP' in file: # grab the L1TP corrected images only\n",
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box raster dimensions: (2948, 3101)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAD8CAYAAACsLLusAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAU3ElEQVR4nO3da2xc9Z3G8e/jS5yL7WDnRmI71wapoduGkk1CYauu2C0pb0K1qpS+KKyElAqB1ErdF9Cutuy77qVUYlegTVXUsOo2ipZW5AXslo1Y0W5DINBAEkKKIRc7cWNobnYuvs1vX8xJOwTHmdj+z4yH5yMdzZnfnMvPJ+Mn5+YZRQRmZinUlLsBM6teDhgzS8YBY2bJOGDMLBkHjJkl44Axs2RKHjCSNkg6JKlT0sOlXr+ZlY5KeR+MpFrgt8BfAt3Aq8BXI+KtkjVhZiVT6j2YtUBnRLwXEYPANmBjiXswsxKpK/H62oCugufdwLorJ5K0GdgMUEvtrTNpLk13ZjamS5xnMAZU7PSlDpjRGvvIMVpEbAG2ADSrNdbpztR9mVkRdsfO65q+1IdI3UBHwfN24ESJezCzEil1wLwKrJS0TNI0YBOwo8Q9mFmJlPQQKSKGJT0E/DdQCzwVEQdK2YOZlU6pz8EQEc8Bz5V6vWZWer6T18ySccCYWTIOGDNLxgFjZsk4YMwsGQeMmSXjgDGzZBwwZpaMA8bMknHAmFkyDhgzS8YBY2bJOGDMLBkHjJkl44Axs2QcMGaWjAPGzJJxwJhZMg4YM0vGAWNmyThgzCwZB4yZJeOAMbNkHDBmlowDxsySccCYWTIOGDNLxgFjZslMKGAkHZG0T9JeSXuyWqukFyS9kz22FEz/iKROSYck3TXR5s2ssk3GHsyfR8TqiFiTPX8Y2BkRK4Gd2XMkrQI2ATcDG4AnJNVOwvrNrEKlOETaCGzNxrcC9xTUt0XEQEQcBjqBtQnWb2YVYqIBE8AvJL0maXNWWxARPQDZ4/ys3gZ0FczbndU+QtJmSXsk7RliYIItmlm51E1w/tsj4oSk+cALkt4eY1qNUovRJoyILcAWgGa1jjqNmVW+Ce3BRMSJ7LEX+Dn5Q56TkhYCZI+92eTdQEfB7O3AiYms38wq27gDRtIsSU2Xx4EvAvuBHcB92WT3Ac9m4zuATZIaJC0DVgKvjHf9Zlb5JnKItAD4uaTLy/mPiPgvSa8C2yXdDxwDvgIQEQckbQfeAoaBByNiZELdm1lFU0Rln+JoVmus053lbsPMgN2xk3NxarTzqaPynbxmlowDxsySccCYWTIOGDNLxgFjZsk4YMwsGQeMmSXjgDGzZBwwZpaMA8bMknHAmFkyDhgzS8YBY2bJOGDMLBkHjJkl44Axs2QcMGaWjAPGzJJxwJhZMg4YM0vGAWNmyThgzCwZB4yZJeOAMbNkHDBmlowDxsySccCYWTIOGDNL5poBI+kpSb2S9hfUWiW9IOmd7LGl4LVHJHVKOiTproL6rZL2Za89LqnoL9A2s6mpmD2YHwMbrqg9DOyMiJXAzuw5klYBm4Cbs3mekFSbzfMksBlYmQ1XLtPMqsw1AyYiXgJOXVHeCGzNxrcC9xTUt0XEQEQcBjqBtZIWAs0RsSsiAni6YB4zq1LjPQezICJ6ALLH+Vm9DegqmK47q7Vl41fWRyVps6Q9kvYMMTDOFs2s3Cb7JO9o51VijPqoImJLRKyJiDX1NExac2ZWWuMNmJPZYQ/ZY29W7wY6CqZrB05k9fZR6mZWxcYbMDuA+7Lx+4BnC+qbJDVIWkb+ZO4r2WFUn6T12dWjewvmMbMqVXetCST9FPgCMFdSN/Bd4HvAdkn3A8eArwBExAFJ24G3gGHgwYgYyRb1APkrUjOA57PBzKqY8hd1KlezWmOd7ix3G2YG7I6dnItTRd/D5jt5zSwZB4yZJeOAMbNkHDBmlowDxsySccCYWTIOGDNLxgFjZsk4YMwsGQeMmSXjgDGzZBwwZpaMA8bMknHA2MeLhBoaqJ07BzX40xJTu+bnwZhNKRKaNo2apkaY08Lgomb62hvoWywudgwzr+M06xccYU3jG2z5279i1n/uLnfHVc0BY1OO6qdR09wILbMZWngD/e0N9C2p4ULHCC2LT3PbjUe5o/l1VjX00FGbo7Gmgfo/fHvOH/3TslpmlaH/jxMHjFUc1dVRM3MmmtPC0I03cL59OueW1XJ+8Qiz2vpYs7CLO2a/xZ9M72Jp3SAtNdNHDRCYPuZ6zi8eGfN1mzgHjJVeTS01s2ZS03oDwwtuoH/JTPo6ajnfkWP64j5uWXicdbMP86czXmRJ3UVaaxtoUP0oC6rPhvFp6jg37nmtOA4Ym3yXA2R2MyM3tnC+YxbnluQDpKbtAp9a1MMdre+yZuYvWV7Xz7yrBkgt0JiszTU3dnG8fhoxNJhsHR93Dhi7fjW11MyYTk3LDYzMu4GL7bPoa6+lfzHkllzkU209fH7OO3xmxq9ZWX+WBVcNEEgZINfyudmdPNP4SUZOO2BSccDYR9XUUjO9gZrmJnLzW7jY1kTf4jr622F46SU+2fE7Ptf6HutmvczK+rPMrZnGzJppV1lY+QLkWlZPP8Yzc26D06fL3UrVcsB8HEnUNDSg2c3EvFYutTVybkk9/UtgqH2Ale29rJ/7HrfM3MvN03pZUFvHDE2jVqPdNlW5AXItS+qGGLpxNjWd5e6kejlgqlHhvSDz53CpvZlzHfWc7xCXOgbpaP896+Yd4famX7Nq2kkW1NbQqIaqC5BrmV0znf6O6TSXu5Eq5oCpIqf/+jbe/9wwC9rzN5Otb3ydzzQcZ1GdxgiQj++dIPWqpW9JjQMmIQdMFTn7pfMc/rOnr6jOLEsvU8X5pcPlbqGq+W+RqsjIsY/v3sh4zes4DSr6iwrtOjlgqkjjMf+iXK+184+haVe7AmYT5YCpIk3HRxiIoXK3MaWsbXqXmkbv+aVyzYCR9JSkXkn7C2qPSjouaW823F3w2iOSOiUdknRXQf1WSfuy1x6XvF862WZ1XeD9kYFytzGlfLrhOMxpKXcbVauYPZgfAxtGqf8gIlZnw3MAklYBm4Cbs3mekP7wV2hPApuBldkw2jJtAmp7z/DecPVeVk5hSd0Ig4tml7uNqnXNgImIl4BTRS5vI7AtIgYi4jDQCayVtBBojohdERHA08A94+zZriJ36gx7LiwvdxtTSmNNA30d/uCpVCZyDuYhSW9mh1CX9zHbgK6CabqzWls2fmV9VJI2S9ojac8Q3uUvVu78BX51akW525hS6lVLf7uP1lMZb8A8CawAVgM9wPez+mj/UjFGfVQRsSUi1kTEmnr8v0vRciPsP7Gw3F1MORc6fC9MKuMKmIg4GREjEZEDfgiszV7qBjoKJm0HTmT19lHqNsnC98JctwVLT/lemETGdSevpIUR0ZM9/TJw+QrTDuA/JD0GLCJ/MveViBiR1CdpPbAbuBf4l4m1bqNpPOJflNGMRI7+GKB7GA4M3sjuvhW8/P5STnTNoeW1OuDdcrdYla4ZMJJ+CnwBmCupG/gu8AVJq8kf5hwBvg4QEQckbQfeAoaBByPi8ucSPkD+itQM4PlssEnWdHyYC7nBMT4+oTpdDpCTIzneHpzH//XfxO73l3K0ey7Tj02j6UjQ1DVIw4lz8MEZoq+PxoHD3BTvlbv1qqb8RZ3K1azWWKc7y93GlKFbbmbLs//G4rrqulw9EjkuxiAnR4Z5Z2gOu85/gpd6P8GR7rk0HGugsSto6hpi+vF+aj44Te7MWXIDA1Dh7++pZnfs5FycKno32X/sWGVqe0/z9mALi+um3h29F3KDnBwZ5NDQHHafX8GvPljBu8fnUXe8gcaj0HxsmBnH+6npPU3u7DmmXTzGTXH0Q8vIZYNVBgdMlcmdOcsrF1bwxZlvl7uVj7iQG+SD3CDvDM1mz4Xl7Dq1nAPHF8KxGTQeE81dw8zoPk9t72lyp89Qc7GbldH1oWU4QKYWB0yVyV28xMunlsHc0gfMQAzx/sgAR4dn8urF5fz69ArePLGIoe5ZNB2pofnoMDOPX6D25Jn8Icz5D1ieO/mhZQT5k3dWHRww1SY3wqETC+CmyV/0QAxxamSAo8MzeO3SUnadWcFvetq4dLSJpiM1NHWPMKvrArXvnyVOnSF34SxLhn//oWU4QD5eHDDV6NiMcc02FCOczV3i6HA9r11ayq/OfILXezq40NXErO4amo/mmNV9kfqeM8TpM+T6+2kfPvChZThArJADpgo1do1+kv9ygHQP17F3oINfnrmJ10+2c+Z4M7OO1dF0NEdj9wD1vzsLH5wm19dH2xUBAg4QK54DpgrNPjzElrOL2H++jZdPLuX9rhZmdNXRdCxoPnIpHyCnzpA718/8obeZf8X8/kJVmyy+D6YKXf5y+Fz/eWJw0PeC2KTxfTBGDA0y8vtiP2HDLB1/ZKaZJeOAMbNkHDBmlowDxsySccCYWTIOGDNLxgFjZsk4YMwsGQeMmSXjgDGzZBwwZpaMA8bMknHAmFkyDhgzS8YBY2bJOGDMLBkHjJkl44Axs2QcMGaWzDUDRlKHpBclHZR0QNI3snqrpBckvZM9thTM84ikTkmHJN1VUL9V0r7stcclFf3hwWY29RSzBzMMfCsiPgmsBx6UtAp4GNgZESuBndlzstc2ATcDG4AnJNVmy3oS2AyszIYNk/izmFmFuWbARERPRLyejfcBB4E2YCOwNZtsK3BPNr4R2BYRAxFxGOgE1kpaCDRHxK7If1fK0wXzmFkVuq5zMJKWArcAu4EFEdED+RCCP3x/VxvQVTBbd1Zry8avrI+2ns2S9kjaM8TA9bRoZhWk6ICR1Ag8A3wzIs6NNekotRij/tFixJaIWBMRa+ppKLZFM6swRQWMpHry4fKTiPhZVj6ZHfaQPfZm9W6go2D2duBEVm8fpW5mVaqYq0gCfgQcjIjHCl7aAdyXjd8HPFtQ3ySpQdIy8idzX8kOo/okrc+WeW/BPGZWhYr56tjbga8B+yTtzWrfBr4HbJd0P3AM+ApARByQtB14i/wVqAcj4vL3qT8A/BiYATyfDWZWpRQV/sXozWqNdbqz3G2YGbA7dnIuThV9/5rv5DWzZBwwZpaMA8bMknHAmFkyDhgzS8YBY2bJOGDMLBkHjJkl44Axs2QcMGaWjAPGzJJxwJhZMg4YM0vGAWNmyThgzCwZB4yZJeOAMbNkHDBmlowDxsySccCYWTIOGDNLxgFjZsk4YMwsGQeMmSXjgDGzZBwwZpaMA8bMknHAmFky1wwYSR2SXpR0UNIBSd/I6o9KOi5pbzbcXTDPI5I6JR2SdFdB/VZJ+7LXHpdU9Jdom9nUU1fENMPAtyLidUlNwGuSXshe+0FE/HPhxJJWAZuAm4FFwP9IuikiRoAngc3Ay8BzwAbg+cn5Ucys0lxzDyYieiLi9Wy8DzgItI0xy0ZgW0QMRMRhoBNYK2kh0BwRuyIigKeBeyb6A5hZ5bquczCSlgK3ALuz0kOS3pT0lKSWrNYGdBXM1p3V2rLxK+ujrWezpD2S9gwxcD0tmlkFKTpgJDUCzwDfjIhz5A93VgCrgR7g+5cnHWX2GKP+0WLElohYExFr6mkotkUzqzBFBYykevLh8pOI+BlARJyMiJGIyAE/BNZmk3cDHQWztwMnsnr7KHUzq1LFXEUS8CPgYEQ8VlBfWDDZl4H92fgOYJOkBknLgJXAKxHRA/RJWp8t817g2Un6OcysAhVzFel24GvAPkl7s9q3ga9KWk3+MOcI8HWAiDggaTvwFvkrUA9mV5AAHgB+DMwgf/XIV5DMqpjyF3QqV7NaY53uLHcbZgbsjp2ci1NF37/mO3nNLBkHjJkl44Axs2QcMGaWjAPGzJJxwJhZMg4YM0vGAWNmyThgzCwZB4yZJeOAMbNkHDBmlowDxsySccCYWTIOGDNLxgFjZsk4YMwsGQeMmSXjgDGzZBwwZpaMA8bMknHAmFkyDhgzS8YBY2bJOGDMLBkHjJkl44Axs2Qq/rupJfUBh8rdxxXmAh+Uu4kCldYPuKdiTbWelkTEvGIXVDc5/SR1KCLWlLuJQpL2VFJPldYPuKdiVXtPPkQys2QcMGaWzFQImC3lbmAUldZTpfUD7qlYVd1TxZ/kNbOpayrswZjZFOWAMbNkKjZgJG2QdEhSp6SHS7zuI5L2SdoraU9Wa5X0gqR3sseWgukfyfo8JOmuSerhKUm9kvYX1K67B0m3Zj9Lp6THJWmSe3pU0vFsW+2VdHepepLUIelFSQclHZD0jaxetu00Rk/l3E7TJb0i6Y2sp78v2XaKiIobgFrgXWA5MA14A1hVwvUfAeZeUftH4OFs/GHgH7LxVVl/DcCyrO/aSejh88Bngf0T6QF4BbgNEPA88KVJ7ulR4G9GmTZ5T8BC4LPZeBPw22y9ZdtOY/RUzu0koDEbrwd2A+tLsZ0qdQ9mLdAZEe9FxCCwDdhY5p42Aluz8a3APQX1bRExEBGHgU7y/U9IRLwEnJpID5IWAs0RsSvy746nC+aZrJ6uJnlPEdETEa9n433AQaCNMm6nMXq6mlL0FBHRnz2tz4agBNupUgOmDegqeN7N2P9Iky2AX0h6TdLmrLYgInog/yYC5mf1UvZ6vT20ZeOpe3tI0pvZIdTl3eyS9iRpKXAL+f+dK2I7XdETlHE7SaqVtBfoBV6IiJJsp0oNmNGO60p5Pf32iPgs8CXgQUmfH2Pacvc6Vg+l6O1JYAWwGugBvl/qniQ1As8A34yIc2NNWsaeyrqdImIkIlYD7eT3Rj41xuST1lOlBkw30FHwvB04UaqVR8SJ7LEX+Dn5Q56T2S4i2WNvGXq93h66s/FkvUXEyezNmwN+yB8PD0vSk6R68r/IP4mIn2Xlsm6n0Xoq93a6LCLOAP8LbKAE26lSA+ZVYKWkZZKmAZuAHaVYsaRZkpoujwNfBPZn678vm+w+4NlsfAewSVKDpGXASvInwlK4rh6y3d4+Seuzs/33FswzKS6/QTNfJr+tStJTNv+PgIMR8VjBS2XbTlfrqczbaZ6kG7LxGcBfAG9Tiu00nrPSpRiAu8mfgX8X+E4J17uc/Bn0N4ADl9cNzAF2Au9kj60F83wn6/MQE7hKc0UfPyW/Kz1E/n+O+8fTA7CG/Jv5XeBfye7ensSe/h3YB7yZvTEXlqon4A7yu+hvAnuz4e5ybqcxeirndvo08Jts3fuBvxvve/p6e/KfCphZMpV6iGRmVcABY2bJOGDMLBkHjJkl44Axs2QcMGaWjAPGzJL5f75pW9BSZmZoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 62 R_LC08_L1TP_032005_2021_B8_Buffer008_PS.png\n",
      "Scale: 6.976744186046512\n"
     ]
    }
   ],
   "source": [
    "# Process all the images for the glaciers specified and show top 5 terminus chains\n",
    "for BoxID in BoxIDs:\n",
    "    t0 = time.time()\n",
    "    processed_image_path = basepath+'Box'+BoxID+'/rotated_c1/'\n",
    "    imagelist = []\n",
    "    for file in os.listdir(processed_image_path):\n",
    "        if file.endswith('PS.png') and 'L1TP' in file: # grab the L1TP corrected images only\n",
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
    "            imagelist.append(file)\n",
    "        elif file.endswith('cut.png'):\n",
    "            boxfile = file\n",
    "        \n",
    "    # Load terminus box\n",
    "    box = Image.open(processed_image_path+boxfile)\n",
    "    box_array = np.array(box)\n",
    "    if len(box_array.shape) == 3: # 3D array\n",
    "        box_array = box_array[:,:,0]/255 # grab 1D slice from array and convert to binary\n",
    "    elif len(box_array.shape) == 2: # 2D array\n",
    "        box_array = box_array # already in binary\n",
    "    print('Box raster dimensions:', box_array.shape)\n",
    "    plt.imshow(box_array); plt.show()  # Display mask\n",
    "    \n",
    "    # hold all top chains produced from terminus picking\n",
    "    topchains_alldfs = []\n",
    "    \n",
    "    image_num = 1\n",
    "    # process all the images\n",
    "    for image in imagelist:\n",
    "        img = Image.open(processed_image_path+image)\n",
    "        print(str(image_num)+' out of '+str(len(imagelist))+' '+image)\n",
    "        \n",
    "        # WTMM\n",
    "        counter = 0\n",
    "        all_cmm = [] # to hold all the chains produced\n",
    "        # ascend over all scales\n",
    "        for iOct in np.arange(0, nOct):\n",
    "            for iVox in np.arange(0, nVox):\n",
    "\n",
    "                # calculate scale in pixels\n",
    "                scale = 6/0.86*amin*2**(iOct+(iVox/nVox))\n",
    "                print('Scale: '+str(scale))\n",
    "\n",
    "                # wavelet transform\n",
    "                [dx, dy, mm, m, a] = wtmm2d_v2(img, wavelet, scale)\n",
    "                \n",
    "                # emask\n",
    "                masked_a = emask(box_array, a)\n",
    "                masked_mm = emask(box_array, mm)\n",
    "                masked_m = emask(box_array, m)\n",
    "\n",
    "                # chain\n",
    "                cmm = wtmmchains(masked_mm,masked_a,0,scale,counter)\n",
    "\n",
    "                # increment\n",
    "                all_cmm.extend(cmm)\n",
    "                counter = counter +1 \n",
    "       \n",
    "    \n",
    "        # Make directory to store chain jsons:\n",
    "        imgfolder = processed_image_path+image+'_chains/'\n",
    "        if not os.path.exists(imgfolder):\n",
    "            os.mkdir(imgfolder)\n",
    "\n",
    "        # Pick the terminus line\n",
    "        # Find maximum mods and sizes for thresholding\n",
    "        mods = []; sizes = []\n",
    "        for chain in all_cmm:\n",
    "            sizes.append(chain.size)\n",
    "            mods.append(chain.linemeanmod)\n",
    "        maxmod = np.nanmax(mods); maxsize = np.nanmax(sizes)\n",
    "            \n",
    "        mass_or_size = []\n",
    "        passed_chains = []\n",
    "        passcount = 0\n",
    "        for chain in all_cmm:\n",
    "            if chain.linemeanmod > mod_thresh*maxmod: # only chains that pass the mod threshold\n",
    "#                 if chain.size > size_thresh*maxsize: # only chains that pass the size threshold\n",
    "                if chain.size > size_thresh*np.sqrt(len(box_array[box_array > 0])):\n",
    "                    [passedargs, argfrac] = filter_args(chain.args, np.pi/3) # identify the left & right-pointing args\n",
    "                    if argfrac > arg_thresh: # only chains that pass the orientation threshold\n",
    "                        if metric == 0:\n",
    "                            mass_or_size.append(chain.mass)\n",
    "                        elif metric == 1:\n",
    "                            mass_or_size.append(chain.scaledmass)\n",
    "                        else:\n",
    "                            mass_or_size.append(chain.size)\n",
    "                        passcount += 1\n",
    "                        passed_chains.append(chain)\n",
    "        print(passcount)\n",
    "        \n",
    "        if passcount > 0: # if chains remain:\n",
    "            # sort by mass or size and grab the top 5\n",
    "            zipped = zip(mass_or_size, passed_chains)              \n",
    "            top_chains = sorted(zipped,reverse=True,\n",
    "                                key=lambda zipped: zipped[0])[:5] # sort chains that passed\n",
    "\n",
    "            # grab info from top 5 chains\n",
    "            scales = []; boxids = []; orders = []; scenes = []; dates = []\n",
    "            # write the top 5 to json\n",
    "            for chain in top_chains:\n",
    "                # grab the chain\n",
    "                chain = chain[1]\n",
    "\n",
    "                # convert dtypes to json serializable dtypes:\n",
    "                chain.size = int(chain.size)\n",
    "                chain.linemeanmod = float(chain.linemeanmod)\n",
    "                chain.mass = float(chain.mass)\n",
    "                chain.scaledmass = float(chain.scaledmass)\n",
    "                chain.args = list(map(float, chain.args))\n",
    "                chain.ix = list(map(int, chain.ix))\n",
    "                chain.iy = list(map(int, chain.iy))\n",
    "                chain.scale = str(chain.scale)\n",
    "                scales.append(chain.scale.zfill(3))\n",
    "\n",
    "                # write object to json file\n",
    "                with open(imgfolder+chain.scale.zfill(3)+'_chain.json', 'w') as f:\n",
    "                    json.dump(chain.__dict__, f)\n",
    "\n",
    "            topchains_df = pd.DataFrame(top_chains,columns=['Metric','chain'])\n",
    "            rows = len(topchains_df)\n",
    "\n",
    "            for n in range(0,rows):\n",
    "                boxids.append(BoxID.zfill(3)) # box string\n",
    "                order = n+1 # order of chains (already sorted)\n",
    "                orders.append(order)\n",
    "                scenes.append(image[2:-20])\n",
    "                date = datetime.datetime.strptime(image[19:27], '%Y%m%d')\n",
    "                date = date.strftime(\"%Y-%m-%d\"); dates.append(date)\n",
    "            topchains_df['BoxID'] = boxids; topchains_df['Scene'] = scenes\n",
    "            topchains_df['datetimes'] = dates;\n",
    "            topchains_df['Scale'] = scales; topchains_df['Order'] = orders\n",
    "            topchains_df = topchains_df[['BoxID','Scene','datetimes','Scale','Metric','Order']]\n",
    "            topchains_alldfs.append(topchains_df)\n",
    "\n",
    "            # visualize top chains:\n",
    "            colors = pl.cm.viridis(np.linspace(0,1,5)) # generate colors using a colormap\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(np.array(img), aspect='equal', cmap = 'gray')\n",
    "            plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "            for k in range(0, len(top_chains)): # plot chains (purple = top, yellow = 5th)\n",
    "                plt.plot(top_chains[len(top_chains)-1-k][1].ix, \n",
    "                         top_chains[len(top_chains)-1-k][1].iy, 's-', color=colors[k],markersize=0.1)\n",
    "            plt.show()\n",
    "\n",
    "    #         print(time.time() - t1)\n",
    "            image_num = image_num +1\n",
    "\n",
<<<<<<< HEAD
    "    print(str(time.time() - t1))+' sec to process '+str(len(imagelist))+' images.' )\n",
    "    # write terminus pick file\n",
    "    today = datetime.datetime.now().strftime(\"%Y_%m_%d\")  # today's date string\n",
=======
    "    print((str(time.time() - t0))+' sec to process '+str(len(imagelist))+' images.')\n",
    "    # write terminus pick file\n",
    "    today = time.strftime(\"%Y_%m_%d\")  # today's date string\n",
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
    "    terminuspick_df = pd.concat(topchains_alldfs) # concatenate all the top pick data together\n",
    "    terminuspick_df.to_csv(csvpath+'terminuspicks_Box'+BoxID.zfill(3)+'_'+today+'.csv') # write to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Option 2) Parallel process images in batches"
=======
    "# Parallel process images in batches"
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# check number of cpus on machine using os:\n",
    "print(os.cpu_count())\n",
    "\n",
    "################################################################################################\n",
    "# set batch size accordingly\n",
    "# recommendation is to leave one or two cpus available for other background processing\n",
    "batch_size = 10\n",
    "print('Batch size:',batch_size)\n",
    "################################################################################################"
=======
    "# # check number of cpus on machine using os:\n",
    "# print(os.cpu_count())\n",
    "\n",
    "# ################################################################################################\n",
    "# # set batch size accordingly\n",
    "# # recommendation is to leave one or two cpus available for other background processing\n",
    "# batch_size = 10\n",
    "# print('Batch size:',batch_size)\n",
    "# ################################################################################################"
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def wtmm2d_img(image):\n",
    "    if True == True:\n",
    "        topchains_dfs = []       \n",
    "        img = Image.open(processed_image_path+image)\n",
    "        print(image)\n",
    "        \n",
    "        # WTMM\n",
    "        counter = 0\n",
    "        all_cmm = [] # to hold all the chains produced\n",
    "        # ascend over all scales\n",
    "        for iOct in np.arange(0, nOct):\n",
    "            for iVox in np.arange(0, nVox):\n",
    "\n",
    "                # calculate scale in pixels\n",
    "                scale = 6/0.86*amin*2**(iOct+(iVox/nVox))\n",
    "\n",
    "                # wavelet transform\n",
    "                [dx, dy, mm, m, a] = wtmm2d_v2(img, wavelet, scale)\n",
    "                \n",
    "                # emask\n",
    "                masked_a = emask(box_array, a)\n",
    "                masked_mm = emask(box_array, mm)\n",
    "                masked_m = emask(box_array, m)\n",
    "\n",
    "                # chain\n",
    "                cmm = wtmmchains(masked_mm,masked_a,0,scale,counter)\n",
    "\n",
    "                # increment\n",
    "                all_cmm.extend(cmm)\n",
    "                counter = counter +1 \n",
    "       \n",
    "    \n",
    "        # Make directory to store chain jsons:\n",
    "        imgfolder = processed_image_path+image+'_chains/'\n",
    "        if not os.path.exists(imgfolder):\n",
    "            os.mkdir(imgfolder)\n",
    "\n",
    "        # Pick the terminus line\n",
    "        # Find maximum mods and sizes for thresholding\n",
    "        mods = []; sizes = []\n",
    "        for chain in all_cmm:\n",
    "            sizes.append(chain.size)\n",
    "            mods.append(chain.linemeanmod)\n",
    "        maxmod = np.nanmax(mods); maxsize = np.nanmax(sizes)\n",
    "            \n",
    "        mass_or_size = []\n",
    "        passed_chains = []\n",
    "        passcount = 0\n",
    "        for chain in all_cmm:\n",
    "            if chain.linemeanmod > mod_thresh*maxmod: # only chains that pass the mod threshold\n",
    "#                 if chain.size > size_thresh*maxsize: # only chains that pass the size threshold\n",
    "                if chain.size > size_thresh*np.sqrt(len(box_array[box_array > 0])):\n",
    "                    [passedargs, argfrac] = filter_args(chain.args, np.pi/3) # identify the left & right-pointing args\n",
    "                    if argfrac > arg_thresh: # only chains that pass the orientation threshold\n",
    "                        if metric == 0:\n",
    "                            mass_or_size.append(chain.mass)\n",
    "                        elif metric == 1:\n",
    "                            mass_or_size.append(chain.scaledmass)\n",
    "                        else:\n",
    "                            mass_or_size.append(chain.size)\n",
    "                        passcount += 1\n",
    "                        passed_chains.append(chain)\n",
    "        \n",
    "        if passcount > 0: # if chains remain:\n",
    "            # sort by mass or size and grab the top 5\n",
    "            zipped = zip(mass_or_size, passed_chains)              \n",
    "            top_chains = sorted(zipped,reverse=True,\n",
    "                                key=lambda zipped: zipped[0])[:5] # sort chains that passed\n",
    "\n",
    "            # grab info from top 5 chains\n",
    "            scales = []; boxids = []; orders = []; scenes = []; dates = []\n",
    "            # write the top 5 to json\n",
    "            for chain in top_chains:\n",
    "                # grab the chain\n",
    "                chain = chain[1]\n",
    "\n",
    "                # convert dtypes to json serializable dtypes:\n",
    "                chain.size = int(chain.size)\n",
    "                chain.linemeanmod = float(chain.linemeanmod)\n",
    "                chain.mass = float(chain.mass)\n",
    "                chain.scaledmass = float(chain.scaledmass)\n",
    "                chain.args = list(map(float, chain.args))\n",
    "                chain.ix = list(map(int, chain.ix))\n",
    "                chain.iy = list(map(int, chain.iy))\n",
    "                chain.scale = str(chain.scale)\n",
    "                scales.append(chain.scale.zfill(3))\n",
    "\n",
    "                # write object to json file\n",
    "                with open(imgfolder+chain.scale.zfill(3)+'_chain.json', 'w') as f:\n",
    "                    json.dump(chain.__dict__, f)\n",
    "\n",
    "            topchains_df = pd.DataFrame(top_chains,columns=['Metric','chain'])\n",
    "            rows = len(topchains_df)\n",
    "\n",
    "            for n in range(0,rows):\n",
    "                boxids.append(BoxID.zfill(3)) # box string\n",
    "                order = n+1 # order of chains (already sorted)\n",
    "                orders.append(order)\n",
    "                scenes.append(image[2:-20])\n",
    "                date = datetime.datetime.strptime(image[19:27], '%Y%m%d')\n",
    "                date = date.strftime(\"%Y-%m-%d\"); dates.append(date)\n",
    "            topchains_df['BoxID'] = boxids; topchains_df['Scene'] = scenes\n",
    "            topchains_df['datetimes'] = dates;\n",
    "            topchains_df['Scale'] = scales; topchains_df['Order'] = orders\n",
    "            topchains_df = topchains_df[['BoxID','Scene','datetimes','Scale','Metric','Order']]\n",
    "            topchains_dfs.append(topchains_df)\n",
    "\n",
    "            # visualize top chains:\n",
    "            colors = pl.cm.viridis(np.linspace(0,1,5)) # generate colors using a colormap\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(np.array(img), aspect='equal', cmap = 'gray')\n",
    "            plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "            for k in range(0, len(top_chains)): # plot chains (purple = top, yellow = 5th)\n",
    "                plt.plot(top_chains[len(top_chains)-1-k][1].ix, \n",
    "                         top_chains[len(top_chains)-1-k][1].iy, 's-', color=colors[k],markersize=0.1)\n",
    "            plt.show()\n",
    "            return topchains_dfs\n",
    "        else:\n",
    "            print('No chains passed.')"
=======
    "# def wtmm2d_img(image):\n",
    "#     if True == True:\n",
    "#         topchains_dfs = []       \n",
    "#         img = Image.open(processed_image_path+image)\n",
    "#         print(image)\n",
    "        \n",
    "#         # WTMM\n",
    "#         counter = 0\n",
    "#         all_cmm = [] # to hold all the chains produced\n",
    "#         # ascend over all scales\n",
    "#         for iOct in np.arange(0, nOct):\n",
    "#             for iVox in np.arange(0, nVox):\n",
    "\n",
    "#                 # calculate scale in pixels\n",
    "#                 scale = 6/0.86*amin*2**(iOct+(iVox/nVox))\n",
    "\n",
    "#                 # wavelet transform\n",
    "#                 [dx, dy, mm, m, a] = wtmm2d_v2(img, wavelet, scale)\n",
    "                \n",
    "#                 # emask\n",
    "#                 masked_a = emask(box_array, a)\n",
    "#                 masked_mm = emask(box_array, mm)\n",
    "#                 masked_m = emask(box_array, m)\n",
    "\n",
    "#                 # chain\n",
    "#                 cmm = wtmmchains(masked_mm,masked_a,0,scale,counter)\n",
    "\n",
    "#                 # increment\n",
    "#                 all_cmm.extend(cmm)\n",
    "#                 counter = counter +1 \n",
    "       \n",
    "    \n",
    "#         # Make directory to store chain jsons:\n",
    "#         imgfolder = processed_image_path+image+'_chains/'\n",
    "#         if not os.path.exists(imgfolder):\n",
    "#             os.mkdir(imgfolder)\n",
    "\n",
    "#         # Pick the terminus line\n",
    "#         # Find maximum mods and sizes for thresholding\n",
    "#         mods = []; sizes = []\n",
    "#         for chain in all_cmm:\n",
    "#             sizes.append(chain.size)\n",
    "#             mods.append(chain.linemeanmod)\n",
    "#         maxmod = np.nanmax(mods); maxsize = np.nanmax(sizes)\n",
    "            \n",
    "#         mass_or_size = []\n",
    "#         passed_chains = []\n",
    "#         passcount = 0\n",
    "#         for chain in all_cmm:\n",
    "#             if chain.linemeanmod > mod_thresh*maxmod: # only chains that pass the mod threshold\n",
    "# #                 if chain.size > size_thresh*maxsize: # only chains that pass the size threshold\n",
    "#                 if chain.size > size_thresh*np.sqrt(len(box_array[box_array > 0])):\n",
    "#                     [passedargs, argfrac] = filter_args(chain.args, np.pi/3) # identify the left & right-pointing args\n",
    "#                     if argfrac > arg_thresh: # only chains that pass the orientation threshold\n",
    "#                         if metric == 0:\n",
    "#                             mass_or_size.append(chain.mass)\n",
    "#                         elif metric == 1:\n",
    "#                             mass_or_size.append(chain.scaledmass)\n",
    "#                         else:\n",
    "#                             mass_or_size.append(chain.size)\n",
    "#                         passcount += 1\n",
    "#                         passed_chains.append(chain)\n",
    "        \n",
    "#         if passcount > 0: # if chains remain:\n",
    "#             # sort by mass or size and grab the top 5\n",
    "#             zipped = zip(mass_or_size, passed_chains)              \n",
    "#             top_chains = sorted(zipped,reverse=True,\n",
    "#                                 key=lambda zipped: zipped[0])[:5] # sort chains that passed\n",
    "\n",
    "#             # grab info from top 5 chains\n",
    "#             scales = []; boxids = []; orders = []; scenes = []; dates = []\n",
    "#             # write the top 5 to json\n",
    "#             for chain in top_chains:\n",
    "#                 # grab the chain\n",
    "#                 chain = chain[1]\n",
    "\n",
    "#                 # convert dtypes to json serializable dtypes:\n",
    "#                 chain.size = int(chain.size)\n",
    "#                 chain.linemeanmod = float(chain.linemeanmod)\n",
    "#                 chain.mass = float(chain.mass)\n",
    "#                 chain.scaledmass = float(chain.scaledmass)\n",
    "#                 chain.args = list(map(float, chain.args))\n",
    "#                 chain.ix = list(map(int, chain.ix))\n",
    "#                 chain.iy = list(map(int, chain.iy))\n",
    "#                 chain.scale = str(chain.scale)\n",
    "#                 scales.append(chain.scale.zfill(3))\n",
    "\n",
    "#                 # write object to json file\n",
    "#                 with open(imgfolder+chain.scale.zfill(3)+'_chain.json', 'w') as f:\n",
    "#                     json.dump(chain.__dict__, f)\n",
    "\n",
    "#             topchains_df = pd.DataFrame(top_chains,columns=['Metric','chain'])\n",
    "#             rows = len(topchains_df)\n",
    "\n",
    "#             for n in range(0,rows):\n",
    "#                 boxids.append(BoxID.zfill(3)) # box string\n",
    "#                 order = n+1 # order of chains (already sorted)\n",
    "#                 orders.append(order)\n",
    "#                 scenes.append(image[2:-20])\n",
    "#                 date = datetime.datetime.strptime(image[19:27], '%Y%m%d')\n",
    "#                 date = date.strftime(\"%Y-%m-%d\"); dates.append(date)\n",
    "#             topchains_df['BoxID'] = boxids; topchains_df['Scene'] = scenes\n",
    "#             topchains_df['datetimes'] = dates;\n",
    "#             topchains_df['Scale'] = scales; topchains_df['Order'] = orders\n",
    "#             topchains_df = topchains_df[['BoxID','Scene','datetimes','Scale','Metric','Order']]\n",
    "#             topchains_dfs.append(topchains_df)\n",
    "\n",
    "#             # visualize top chains:\n",
    "#             colors = pl.cm.viridis(np.linspace(0,1,5)) # generate colors using a colormap\n",
    "#             plt.figure(figsize=(8,8))\n",
    "#             plt.imshow(np.array(img), aspect='equal', cmap = 'gray')\n",
    "#             plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "#             for k in range(0, len(top_chains)): # plot chains (purple = top, yellow = 5th)\n",
    "#                 plt.plot(top_chains[len(top_chains)-1-k][1].ix, \n",
    "#                          top_chains[len(top_chains)-1-k][1].iy, 's-', color=colors[k],markersize=0.1)\n",
    "#             plt.show()\n",
    "#             return topchains_dfs\n",
    "#         else:\n",
    "#             print('No chains passed.')"
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "for BoxID in BoxIDs:\n",
    "    t1 = time.time()\n",
    "    processed_image_path = basepath+'Box'+BoxID+'/'+subfoldername\n",
    "    imagelist = []\n",
    "    for file in os.listdir(processed_image_path):\n",
    "        if file.endswith('PS.pgm') and 'L1TP' in file: # L1TP corrected images only\n",
    "            imagelist.append(file)\n",
    "        elif file.endswith('cut.png'):\n",
    "            boxfile = file\n",
=======
    "# for BoxID in BoxIDs:\n",
    "#     t1 = time.time()\n",
    "#     processed_image_path = basepath+'Box'+BoxID+'/rotated_c1/'\n",
    "#     imagelist = []\n",
    "#     for file in os.listdir(processed_image_path):\n",
    "#         if file.endswith('PS.pgm') and 'L1TP' in file: # L1TP corrected images only\n",
    "#             imagelist.append(file)\n",
    "#         elif file.endswith('cut.png'):\n",
    "#             boxfile = file\n",
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
    "        \n",
    "#     # Load terminus box\n",
    "#     box = Image.open(processed_image_path+boxfile)\n",
    "#     box_array = np.array(box)\n",
    "#     if len(box_array.shape) == 3: # 3D array\n",
    "#         box_array = box_array[:,:,0]/255 # grab 1D slice from array and convert to binary\n",
    "#     elif len(box_array.shape) == 2: # 2D array\n",
    "#         box_array = box_array # already in binary\n",
    "#     print('Box',BoxID,'raster dimensions:', box_array.shape)\n",
    "#     plt.imshow(box_array); plt.show()  # Display mask\n",
    "    \n",
    "#     # hold all top chains produced from terminus picking\n",
    "#     topchains_alldfs = []\n",
    "    \n",
    "#     # process all the images in parallel\n",
    "#     pcount = 0\n",
    "#     image_num = 1\n",
    "#     nbatches = int(np.ceil(len(imagelist)/batch_size)) # round up to the next batch size\n",
    "#     nfullbatches = int(np.floor(len(imagelist)/batch_size)) # number of full batches\n",
    "#     print(nbatches, 'batches')\n",
    "#     print(nfullbatches, 'full batches')\n",
    "    \n",
    "#     # full batches\n",
    "#     for b in range(0, nfullbatches):\n",
    "#         pool = Pool() # initialize pool\n",
    "#         batchimgs = imagelist[b*batch_size:(b+1)*batch_size]\n",
    "#         topchains_dfs = pool.map(wtmm2d_img, batchimgs) # process all in pool\n",
    "#         topchains_alldfs += topchains_dfs\n",
    "    \n",
    "#     # for the last batch\n",
    "#     if nbatches - nfullbatches == 1:\n",
    "#         pool = Pool()\n",
    "#         lastbatchimgs = imagelist[(b+1)*batch_size:] # grab all remaining images\n",
    "#         topchains_dfs = pool.map(wtmm2d_img, lastbatchimgs) # process all in pool\n",
    "#         topchains_alldfs += topchains_dfs\n",
    "\n",
    "#     dfs = []\n",
    "#     for df in topchains_alldfs:\n",
    "#         if df == None:\n",
    "#             topchains_alldfs.remove(df)\n",
    "#         else:\n",
    "#             dfs.append(df[0])\n",
    "    \n",
    "#     print(str(time.time() - t1)+' sec to process '+str(len(imagelist))+' images.' )\n",
    "#     # write terminus pick file\n",
    "#     today = datetime.datetime.now().strftime(\"%Y_%m_%d\")  # today's date string\n",
    "#     terminuspick_df = pd.concat(dfs) # concatenate all the top pick data together\n",
    "#     terminuspick_df = terminuspick_df.reset_index(drop=True) # reset the index\n",
    "#     terminuspick_df.to_csv(csvpath+'terminuspicks_Box'+BoxID.zfill(3)+'_'+today+'.csv') # write to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Option 3) Process 1 image at a time\n",
=======
    "# Process 1 image at a time (use if above doesn't work)\n",
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
    "\n",
    "## 3A) Load terminus box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ######################################################################################\n",
    "# # use terminus box raster to mask out external chains\n",
    "# # box = Image.open(basepath+'Box277/rotated_c1/R_Box277_raster_cut.png')\n",
    "# # box = Image.open(basepath+'R_Box174_raster_cut.png')\n",
    "# box = Image.open(basepath+'Box174/rotated_c1/R_Box174_raster_cut.png')\n",
    "# ######################################################################################\n",
    "# box_array = np.array(box)[:,:,0]/255 # grab 1D slice from array and convert to binary\n",
    "# print(box_array.shape)\n",
    "# plt.imshow(box_array); plt.show()  # Display mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B) Open image(s) for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "######################################################################################\n",
    "# # open glacier image for testing, check paths:\n",
    "# img  = Image.open(basepath+'Box277/rotated_c1/R_LC08_L1GT_001014_20180519_20180520_01_RT_B8_Buffer277_PS.pgm')\n",
    "img = Image.open(basepath+'Box174/rotated_c1/R_LC08_L1TP_233017_20170813_20170814_01_RT_B8_Buffer174_PS.pgm')\n",
    "# img = Image.open(basepath+'R_LC08_L1TP_233017_20170813_20170814_01_RT_B8_Buffer174_PS.pgm')\n",
    "# OR generate circle image\n",
    "# img = generate_circle_image(100, 436, 428)\n",
    "######################################################################################\n",
    "img"
=======
    "# ######################################################################################\n",
    "# # # open glacier image for testing\n",
    "# # img  = Image.open(basepath+'Box277/rotated_c1/R_LC08_L1GT_001014_20180519_20180520_01_RT_B8_Buffer277_PS.pgm')\n",
    "# img = Image.open(basepath+'Box174/rotated_c1/R_LC08_L1TP_233017_20170813_20170814_01_RT_B8_Buffer174_PS.pgm')\n",
    "# # img = Image.open(basepath+'R_LC08_L1TP_233017_20170813_20170814_01_RT_B8_Buffer174_PS.pgm')\n",
    "# # OR generate circle image\n",
    "# # img = generate_circle_image(100, 436, 428)\n",
    "# ######################################################################################\n",
    "# img"
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3C) Run wtmm2d and show outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ######################################################################################\n",
    "# # [dx,dy,F,f,gx,gy] = wtmm2d(img,'gauss',10)\n",
    "# [dx,dy,mm,m,a] = wtmm2d_v2(img,'gauss',10) # scale = 200 pixels\n",
    "# ######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Visualize outputs from wtmm2d:\n",
    "# fig, axs = plt.subplots(2,3,figsize=(15,10))\n",
    "# axs[0,0].imshow(dx, aspect='equal', cmap = 'gray', interpolation='none'); axs[0,0].set_title('dx') # x gradient\n",
    "# axs[0,1].imshow(dy, aspect='equal', cmap = 'gray', interpolation='none'); axs[0,1].set_title('dy') # y gradient\n",
    "\n",
    "# axs[0,2].imshow(a, aspect='equal', cmap = 'gray', interpolation='none'); axs[0,2].set_title('a') # argument            \n",
    "# axs[1,0].imshow(mm, aspect='equal', cmap = 'gray', interpolation='none', vmin = np.min(mm), vmax = np.max(m)); \n",
    "# axs[1,0].set_title('mm') # modulus maxima (interpolated)\n",
    "# axs[1,1].imshow(m, aspect='equal', cmap = 'gray', interpolation='none',vmin = np.min(mm), vmax = np.max(m));\n",
    "# axs[1,1].set_title('m') # modulus\n",
    "# axs[-1, -1].axis('off')\n",
    "\n",
    "# # Image.fromarray(mm).save('mm.tif')   \n",
    "# # Image.fromarray(m).save('m.tif')   \n",
    "\n",
    "# # plt.savefig('glacier_WTMM_test.png',dpi=200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D) Mask using terminus box - emask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Mask\n",
    "# masked_a = emask(box_array, a)\n",
    "# masked_mm = emask(box_array, mm)\n",
    "# masked_m = emask(box_array, m)\n",
    "\n",
    "# # Visualize masked outputs from wtmm2d:\n",
    "# fig, axs = plt.subplots(1,3,figsize=(15,10))\n",
    "\n",
    "# axs[0].imshow(masked_a, aspect='equal', cmap = 'viridis', interpolation='none'); axs[0].set_title('a')              \n",
    "# axs[1].imshow(masked_mm, aspect='equal', cmap = 'gray', interpolation='none', vmin = np.min(masked_mm), vmax = np.max(masked_mm)); \n",
    "# axs[1].set_title('mm')\n",
    "# axs[2].imshow(masked_m, aspect='equal', cmap = 'gray', interpolation='none',vmin = np.min(masked_m), vmax = np.max(masked_m));\n",
    "# axs[2].set_title('m')\n",
    "# # plt.savefig('glacier_WTMM_test.png',dpi=200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3E) Chain remaining mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################################################################################\n",
    "# cmm = wtmmchains(masked_mm,masked_a,1,10) # chain at a specified scale\n",
    "# ######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmm_passed = []\n",
    "# # Filter chains based on size threshold\n",
    "# for j in range(0, len(cmm)):\n",
    "#     if cmm[j].size > 0:\n",
    "#         cmm_passed.append(cmm[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(masked_mm,cmap='gray')\n",
    "# plt.xlim([0, mm.shape[1]])\n",
    "# plt.ylim([0, mm.shape[0]])\n",
    "# plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "    \n",
    "# for k in range(0, len(cmm_passed)):\n",
    "#     plt.plot(cmm_passed[k].ix, cmm_passed[k].iy, 's-', markersize=0.5)\n",
    "# plt.show()"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(cmm_passed)"
   ]
  },
  {
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3F) Use thresholds on chain properties to pick the glacier terminus chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################################################################################\n",
    "# size_thresh = 0.4 # Size percentile across all images\n",
    "# mod_thresh = 0.7 # Linemeanmod percentile across all images\n",
    "# arg_thresh = 0.1 # left-right argument fraction\n",
    "# metric = 1 # 0 = mass, 1 = scaledmass, 2 = size\n",
    "# ######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass_or_size = []\n",
    "# passed_chains = []\n",
    "# for chain in all_cmm:\n",
    "#     if chain.linemeanmod > mod_thresh: # only chains that pass the mod threshold\n",
    "#         if chain.size > size_thresh: # only chains that pass the size threshold\n",
    "#             [passedargs, argfrac] = filter_args(chain.args, np.pi/3) # identify the left & right-pointing args\n",
    "#             if argfrac > arg_thresh: # only chains that pass the orientation threshold\n",
    "#                 if metric == 0:\n",
    "#                     mass_or_size.append(chain.mass)\n",
    "#                 elif metric == 1:\n",
    "#                     mass_or_size.append(chain.scaled_mass)\n",
    "#                 else:\n",
    "#                     mass_or_size.append(chain.size)\n",
    "#                 passed_chains.append(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_chains = sorted(zip(mass_or_size, passed_chains),reverse=True)[:5] # sort chains that passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize top chains:\n",
    "# colors = pl.cm.viridis(np.linspace(0,1,5)) # generate colors using a colormap\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.imshow(np.array(img), aspect='equal', cmap = 'gray')\n",
    "# plt.gca().set_aspect('equal'); plt.gca().invert_yaxis()\n",
    "# for k in range(0, len(top_chains)):\n",
    "#     plt.plot(top_chains[k][1].ix, top_chains[k][1].iy, 's-', color=colors[k],markersize=0.1)\n",
    "            \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.6"
=======
   "version": "3.10.2"
>>>>>>> 30967ad50b967a5858e89b8e379a91ecd6fe8021
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
