{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to calculate the auto and manual difference using an objective function\n",
    "\n",
    "Weighted least squares solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages, functions, manual and automated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "manual_path = '/media/jukes/jukes1/Manual/'; manual_filename = 'manual_tpos.csv'\n",
    "auto_path = '/home/jukes/Documents/Sample_glaciers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jukes/automated-glacier-terminus') #import necessary functions:\n",
    "from automated_terminus_functions import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoxID</th>\n",
       "      <th>datetimes</th>\n",
       "      <th>Scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>LC80320052013246LGN00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>LC80010152014160LGN00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>LC80350052015177LGN00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>LC82320182015213LGN00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001</td>\n",
       "      <td>2015-08-24</td>\n",
       "      <td>LC80320052015236LGN00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BoxID   datetimes                  Scene\n",
       "0   001  2013-09-03  LC80320052013246LGN00\n",
       "1   001  2014-06-09  LC80010152014160LGN00\n",
       "2   001  2015-06-26  LC80350052015177LGN00\n",
       "3   001  2015-08-01  LC82320182015213LGN00\n",
       "4   001  2015-08-24  LC80320052015236LGN00"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MANUAL info\n",
    "condition_df = pd.read_csv(manual_path+'LS8_manual_delineation_info.csv', dtype=str)\n",
    "\n",
    "# TEST images\n",
    "test_df = pd.read_csv(manual_path+'test.csv', dtype=str, header=None)\n",
    "test_df = test_df.rename(columns={0: 'BoxID', 1: 'datetimes', 2: 'Scene'})\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MANUAL TERMINUS POSITIONS\n",
    "manual_df = pd.read_csv(manual_path+manual_filename, dtype=str,sep=',')\n",
    "\n",
    "#SPLIT INTO 3 DATAFRAMES FOR 3 FLOWLINES:\n",
    "manual50 = manual_df[['BoxID','datetimes', 'intersect_x', 'intersect_y', \n",
    "                                      'tpos50']].copy().reset_index(drop=True).rename(columns={\"tpos50\": \"tpos\"})\n",
    "manual25 = manual_df[['BoxID','datetimes', 'intersect_x', 'intersect_y', \n",
    "                                      'tpos25']].copy().reset_index(drop=True).rename(columns={\"tpos25\": \"tpos\"})\n",
    "manual75 = manual_df[['BoxID','datetimes', 'intersect_x', 'intersect_y',\n",
    "                                      'tpos75']].copy().reset_index(drop=True).rename(columns={\"tpos75\": \"tpos\"})\n",
    "# manual_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BoxID</th>\n",
       "      <th>datetimes</th>\n",
       "      <th>Path</th>\n",
       "      <th>Row</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Not_exact_date</th>\n",
       "      <th>Jukes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>001</td>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80350052013123LGN01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jackie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>001</td>\n",
       "      <td>2013-05-05</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80330052013125LGN01</td>\n",
       "      <td>Sea ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delineation rate (2 ppl):</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>001</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80320052013134LGN03</td>\n",
       "      <td>Sea ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 - 2.5 hrs / 160 lines = ~1.9 min/line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>001</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80340052013148LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "      <td>2013-05-29</td>\n",
       "      <td>2 - 3.25 hrs / 168 lines = ~2.3 min/line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>001</td>\n",
       "      <td>2013-08-23</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80350052013235LGN00</td>\n",
       "      <td>Clear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120 -</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 BoxID   datetimes Path Row                  Scene Condition  \\\n",
       "0         21   001  2013-05-03   35   5  LC80350052013123LGN01       NaN   \n",
       "1         24   001  2013-05-05   33   5  LC80330052013125LGN01   Sea ice   \n",
       "2         27   001  2013-05-14   32   5  LC80320052013134LGN03   Sea ice   \n",
       "3         37   001  2013-05-28   34   5  LC80340052013148LGN00  Sea ice    \n",
       "4         61   001  2013-08-23   35   5  LC80350052013235LGN00     Clear   \n",
       "\n",
       "  Not_exact_date                                     Jukes  \n",
       "0            NaN                                    Jackie  \n",
       "1            NaN                 Delineation rate (2 ppl):  \n",
       "2            NaN   1 - 2.5 hrs / 160 lines = ~1.9 min/line  \n",
       "3     2013-05-29  2 - 3.25 hrs / 168 lines = ~2.3 min/line  \n",
       "4            NaN                                    120 -   "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newIDs = []\n",
    "for item in np.array(condition_df['BoxID']):\n",
    "    if type(item) != float:\n",
    "        newIDs.append(item.rjust(3, '0'))\n",
    "    else:\n",
    "        newIDs.append('NaN')\n",
    "condition_df['BoxID'] = newIDs \n",
    "condition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoxID</th>\n",
       "      <th>datetimes</th>\n",
       "      <th>intersect_x</th>\n",
       "      <th>intersect_y</th>\n",
       "      <th>tpos50</th>\n",
       "      <th>tpos25</th>\n",
       "      <th>tpos75</th>\n",
       "      <th>Path</th>\n",
       "      <th>Row</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>141</td>\n",
       "      <td>158</td>\n",
       "      <td>375.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80320052013246LGN00</td>\n",
       "      <td>Thin clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>142</td>\n",
       "      <td>159</td>\n",
       "      <td>390.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80350052015177LGN00</td>\n",
       "      <td>Dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>2015-08-24</td>\n",
       "      <td>141</td>\n",
       "      <td>158</td>\n",
       "      <td>375.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80320052015236LGN00</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>141</td>\n",
       "      <td>159</td>\n",
       "      <td>375.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80340052016125LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>142</td>\n",
       "      <td>159</td>\n",
       "      <td>390.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80330052016150LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>135</td>\n",
       "      <td>158</td>\n",
       "      <td>285.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80330052017072LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001</td>\n",
       "      <td>2017-03-18</td>\n",
       "      <td>136</td>\n",
       "      <td>158</td>\n",
       "      <td>300.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>LC80360042017077LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>001</td>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>136</td>\n",
       "      <td>158</td>\n",
       "      <td>300.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80340052017095LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-06-25</td>\n",
       "      <td>664</td>\n",
       "      <td>575</td>\n",
       "      <td>2932.5</td>\n",
       "      <td>2561.25</td>\n",
       "      <td>3093.75</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80330052014176LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-07-04</td>\n",
       "      <td>655</td>\n",
       "      <td>576</td>\n",
       "      <td>2797.5</td>\n",
       "      <td>2516.25</td>\n",
       "      <td>3093.75</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80320052014185LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-07-09</td>\n",
       "      <td>657</td>\n",
       "      <td>576</td>\n",
       "      <td>2827.5</td>\n",
       "      <td>2531.25</td>\n",
       "      <td>3093.75</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80350052014190LGN00</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-09-13</td>\n",
       "      <td>652</td>\n",
       "      <td>576</td>\n",
       "      <td>2752.5</td>\n",
       "      <td>2261.25</td>\n",
       "      <td>2808.75</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80330052014256LGN00</td>\n",
       "      <td>Shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-08-13</td>\n",
       "      <td>651</td>\n",
       "      <td>576</td>\n",
       "      <td>2737.5</td>\n",
       "      <td>2396.25</td>\n",
       "      <td>3108.75</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80350052015225LGN00</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>002</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>674</td>\n",
       "      <td>574</td>\n",
       "      <td>3082.5</td>\n",
       "      <td>2531.25</td>\n",
       "      <td>3078.75</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80350052016084LGN00</td>\n",
       "      <td>Shadow, sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>002</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>674</td>\n",
       "      <td>574</td>\n",
       "      <td>3082.5</td>\n",
       "      <td>2606.25</td>\n",
       "      <td>3153.75</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80300052016161LGN00</td>\n",
       "      <td>Shadow, sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>002</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>664</td>\n",
       "      <td>575</td>\n",
       "      <td>2932.5</td>\n",
       "      <td>2531.25</td>\n",
       "      <td>2898.75</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>LC80350052017102LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120</td>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>585.0</td>\n",
       "      <td>502.5</td>\n",
       "      <td>517.5</td>\n",
       "      <td>233</td>\n",
       "      <td>17</td>\n",
       "      <td>LC82330172014345LGN00</td>\n",
       "      <td>Dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>120</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>570.0</td>\n",
       "      <td>517.5</td>\n",
       "      <td>502.5</td>\n",
       "      <td>233</td>\n",
       "      <td>17</td>\n",
       "      <td>LC82330172015300LGN00</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>120</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>585.0</td>\n",
       "      <td>547.5</td>\n",
       "      <td>502.5</td>\n",
       "      <td>233</td>\n",
       "      <td>17</td>\n",
       "      <td>LC82330172015300LGN00</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>174</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>306</td>\n",
       "      <td>327</td>\n",
       "      <td>697.5</td>\n",
       "      <td>491.25</td>\n",
       "      <td>618.75</td>\n",
       "      <td>232</td>\n",
       "      <td>17</td>\n",
       "      <td>LC82320172016104LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>174</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>300</td>\n",
       "      <td>328</td>\n",
       "      <td>607.5</td>\n",
       "      <td>461.25</td>\n",
       "      <td>558.75</td>\n",
       "      <td>233</td>\n",
       "      <td>17</td>\n",
       "      <td>LC82330172016271LGN00</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>174</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>295</td>\n",
       "      <td>329</td>\n",
       "      <td>532.5</td>\n",
       "      <td>461.25</td>\n",
       "      <td>513.75</td>\n",
       "      <td>233</td>\n",
       "      <td>17</td>\n",
       "      <td>LC82330172017097LGN00</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>174</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>296</td>\n",
       "      <td>329</td>\n",
       "      <td>547.5</td>\n",
       "      <td>491.25</td>\n",
       "      <td>528.75</td>\n",
       "      <td>233</td>\n",
       "      <td>17</td>\n",
       "      <td>LC82330172017097LGN00</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>259</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>299</td>\n",
       "      <td>497</td>\n",
       "      <td>960.0</td>\n",
       "      <td>1042.5</td>\n",
       "      <td>952.5</td>\n",
       "      <td>232</td>\n",
       "      <td>15</td>\n",
       "      <td>LC82320152016136LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>259</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>291</td>\n",
       "      <td>496</td>\n",
       "      <td>840.0</td>\n",
       "      <td>982.5</td>\n",
       "      <td>742.5</td>\n",
       "      <td>233</td>\n",
       "      <td>15</td>\n",
       "      <td>LC82330152016255LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>259</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>291</td>\n",
       "      <td>496</td>\n",
       "      <td>840.0</td>\n",
       "      <td>982.5</td>\n",
       "      <td>757.5</td>\n",
       "      <td>233</td>\n",
       "      <td>15</td>\n",
       "      <td>LC82330152016255LGN00</td>\n",
       "      <td>Sea ice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BoxID   datetimes intersect_x intersect_y  tpos50   tpos25   tpos75 Path  \\\n",
       "0    001  2013-09-03         141         158   375.0    270.0    465.0   32   \n",
       "1    001  2015-06-26         142         159   390.0    300.0    435.0   35   \n",
       "2    001  2015-08-24         141         158   375.0    120.0    405.0   32   \n",
       "3    001  2016-05-04         141         159   375.0    120.0    435.0   34   \n",
       "4    001  2016-05-29         142         159   390.0    120.0    435.0   33   \n",
       "5    001  2017-03-13         135         158   285.0    120.0    345.0   33   \n",
       "6    001  2017-03-18         136         158   300.0    105.0    360.0   36   \n",
       "7    001  2017-04-05         136         158   300.0    120.0    360.0   34   \n",
       "8    002  2014-06-25         664         575  2932.5  2561.25  3093.75   33   \n",
       "9    002  2014-07-04         655         576  2797.5  2516.25  3093.75   32   \n",
       "10   002  2014-07-09         657         576  2827.5  2531.25  3093.75   35   \n",
       "11   002  2014-09-13         652         576  2752.5  2261.25  2808.75   33   \n",
       "12   002  2015-08-13         651         576  2737.5  2396.25  3108.75   35   \n",
       "13   002  2016-03-24         674         574  3082.5  2531.25  3078.75   35   \n",
       "14   002  2016-06-09         674         574  3082.5  2606.25  3153.75   30   \n",
       "15   002  2017-04-12         664         575  2932.5  2531.25  2898.75   35   \n",
       "16   120  2014-12-11         150         150   585.0    502.5    517.5  233   \n",
       "17   120  2015-10-27         149         150   570.0    517.5    502.5  233   \n",
       "18   120  2015-10-27         150         150   585.0    547.5    502.5  233   \n",
       "19   174  2016-04-13         306         327   697.5   491.25   618.75  232   \n",
       "20   174  2016-09-27         300         328   607.5   461.25   558.75  233   \n",
       "21   174  2017-04-07         295         329   532.5   461.25   513.75  233   \n",
       "22   174  2017-04-07         296         329   547.5   491.25   528.75  233   \n",
       "23   259  2016-05-15         299         497   960.0   1042.5    952.5  232   \n",
       "24   259  2016-09-11         291         496   840.0    982.5    742.5  233   \n",
       "25   259  2016-09-11         291         496   840.0    982.5    757.5  233   \n",
       "\n",
       "   Row                  Scene        Condition  \n",
       "0    5  LC80320052013246LGN00      Thin clouds  \n",
       "1    5  LC80350052015177LGN00              Dim  \n",
       "2    5  LC80320052015236LGN00            Clear  \n",
       "3    5  LC80340052016125LGN00         Sea ice   \n",
       "4    5  LC80330052016150LGN00         Sea ice   \n",
       "5    5  LC80330052017072LGN00         Sea ice   \n",
       "6    4  LC80360042017077LGN00         Sea ice   \n",
       "7    5  LC80340052017095LGN00         Sea ice   \n",
       "8    5  LC80330052014176LGN00         Sea ice   \n",
       "9    5  LC80320052014185LGN00         Sea ice   \n",
       "10   5  LC80350052014190LGN00            Clear  \n",
       "11   5  LC80330052014256LGN00           Shadow  \n",
       "12   5  LC80350052015225LGN00            Clear  \n",
       "13   5  LC80350052016084LGN00  Shadow, sea ice  \n",
       "14   5  LC80300052016161LGN00  Shadow, sea ice  \n",
       "15   5  LC80350052017102LGN00          Sea ice  \n",
       "16  17  LC82330172014345LGN00              Dim  \n",
       "17  17  LC82330172015300LGN00            Clear  \n",
       "18  17  LC82330172015300LGN00            Clear  \n",
       "19  17  LC82320172016104LGN00          Sea ice  \n",
       "20  17  LC82330172016271LGN00            Clear  \n",
       "21  17  LC82330172017097LGN00            Clear  \n",
       "22  17  LC82330172017097LGN00            Clear  \n",
       "23  15  LC82320152016136LGN00          Sea ice  \n",
       "24  15  LC82330152016255LGN00          Sea ice  \n",
       "25  15  LC82330152016255LGN00          Sea ice  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST image conditions by condition - manual\n",
    "merge1 = manual_df.merge(condition_df, how='inner', on=['datetimes', 'BoxID']).drop(['Unnamed: 0_x', \n",
    "                                                                 'Unnamed: 0_y',\n",
    "                                                                 'Line_x', 'Line_y', \n",
    "                                                                 'Jukes', 'Not_exact_date'], axis=1)\n",
    "merge2 = merge1.merge(test_df, how='inner', on=['datetimes', 'BoxID', 'Scene'])\n",
    "merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoxID</th>\n",
       "      <th>datetimes</th>\n",
       "      <th>Scene</th>\n",
       "      <th>tpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>LC80340052013148LGN00</td>\n",
       "      <td>3738.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>LC80300052014107LGN00</td>\n",
       "      <td>3123.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-06-27</td>\n",
       "      <td>LC80310052014178LGN00</td>\n",
       "      <td>3228.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-08-12</td>\n",
       "      <td>LC80330052014224LGN00</td>\n",
       "      <td>3123.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>LC80340052014263LGN00</td>\n",
       "      <td>2733.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>LC80320052014265LGN00</td>\n",
       "      <td>2733.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>LC80300052014267LGN00</td>\n",
       "      <td>2718.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>LC80330052014272LGN00</td>\n",
       "      <td>2733.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>002</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>LC80310052014274LGN00</td>\n",
       "      <td>2733.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-03-06</td>\n",
       "      <td>LC80350052015065LGN00</td>\n",
       "      <td>2418.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-05-20</td>\n",
       "      <td>LC80320052015140LGN00</td>\n",
       "      <td>3543.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>LC80330052015179LGN00</td>\n",
       "      <td>3078.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>LC80310052015181LGN00</td>\n",
       "      <td>3093.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>LC80340052015186LGN00</td>\n",
       "      <td>3108.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-07-12</td>\n",
       "      <td>LC80350052015193LGN00</td>\n",
       "      <td>3183.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-07-25</td>\n",
       "      <td>LC80300052015206LGN00</td>\n",
       "      <td>3243.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-07-28</td>\n",
       "      <td>LC80350052015209LGN00</td>\n",
       "      <td>3183.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-09-18</td>\n",
       "      <td>LC80310052015261LGN00</td>\n",
       "      <td>3123.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>002</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>LC80320052015284LGN00</td>\n",
       "      <td>2928.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>002</td>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>LC80330052016150LGN00</td>\n",
       "      <td>3543.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>002</td>\n",
       "      <td>2016-07-07</td>\n",
       "      <td>LC80340052016189LGN00</td>\n",
       "      <td>3123.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>002</td>\n",
       "      <td>2016-07-14</td>\n",
       "      <td>LC80350052016196LGN00</td>\n",
       "      <td>3123.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>002</td>\n",
       "      <td>2016-09-29</td>\n",
       "      <td>LC80300052016273LGN00</td>\n",
       "      <td>2838.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>002</td>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>LC80310052016280LGN00</td>\n",
       "      <td>2778.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>002</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>LC80330052017072LGN00</td>\n",
       "      <td>1683.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BoxID   datetimes                  Scene     tpos\n",
       "0    002  2013-05-28  LC80340052013148LGN00  3738.75\n",
       "1    002  2014-04-17  LC80300052014107LGN00  3123.75\n",
       "2    002  2014-06-27  LC80310052014178LGN00  3228.75\n",
       "3    002  2014-08-12  LC80330052014224LGN00  3123.75\n",
       "4    002  2014-09-20  LC80340052014263LGN00  2733.75\n",
       "5    002  2014-09-22  LC80320052014265LGN00  2733.75\n",
       "6    002  2014-09-24  LC80300052014267LGN00  2718.75\n",
       "7    002  2014-09-29  LC80330052014272LGN00  2733.75\n",
       "8    002  2014-10-01  LC80310052014274LGN00  2733.75\n",
       "9    002  2015-03-06  LC80350052015065LGN00  2418.75\n",
       "10   002  2015-05-20  LC80320052015140LGN00  3543.75\n",
       "11   002  2015-06-28  LC80330052015179LGN00  3078.75\n",
       "12   002  2015-06-30  LC80310052015181LGN00  3093.75\n",
       "13   002  2015-07-05  LC80340052015186LGN00  3108.75\n",
       "14   002  2015-07-12  LC80350052015193LGN00  3183.75\n",
       "15   002  2015-07-25  LC80300052015206LGN00  3243.75\n",
       "16   002  2015-07-28  LC80350052015209LGN00  3183.75\n",
       "17   002  2015-09-18  LC80310052015261LGN00  3123.75\n",
       "18   002  2015-10-11  LC80320052015284LGN00  2928.75\n",
       "19   002  2016-05-29  LC80330052016150LGN00  3543.75\n",
       "20   002  2016-07-07  LC80340052016189LGN00  3123.75\n",
       "21   002  2016-07-14  LC80350052016196LGN00  3123.75\n",
       "22   002  2016-09-29  LC80300052016273LGN00  2838.75\n",
       "23   002  2016-10-06  LC80310052016280LGN00  2778.75\n",
       "24   002  2017-03-13  LC80330052017072LGN00  1683.75"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.0"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average([abs(2002.5-2932.5), abs(2921.25-2531.25), abs(3037.5-3082.5), abs(2501.25-2606.25), abs(3123.75-3153.75)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoxIDs = ['001', '002', '120', '174', '259']\n",
    "BoxIDs = ['002']\n",
    "dfs = []\n",
    "\n",
    "for BoxID in BoxIDs:\n",
    "    auto50 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline50_filtered.csv', dtype=str,sep=',')\n",
    "    auto50 = auto50[['BoxID','datetimes', 'Scene', 'tpos']].copy()\n",
    "    auto25 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline25_filtered.csv', dtype=str,sep=',')\n",
    "    auto25 = auto25[['BoxID','datetimes', 'Scene', 'tpos']].copy()\n",
    "    auto75 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline75_filtered.csv', dtype=str,sep=',')\n",
    "    auto75 = auto75[['BoxID','datetimes', 'Scene', 'tpos']].copy()\n",
    "#     autodfs = [auto50, auto25, auto75]\n",
    "\n",
    "#     manual = merge2[merge2.BoxID == BoxID].copy()\n",
    "#     manual50 = manual[['BoxID','datetimes', 'Scene', 'tpos50', 'Condition']].copy().rename(columns={\"tpos50\": \"tpos\"})\n",
    "#     manual25 = manual[['BoxID','datetimes', 'Scene', 'tpos25', 'Condition']].copy().rename(columns={\"tpos25\": \"tpos\"})\n",
    "#     manual75 = manual[['BoxID','datetimes', 'Scene', 'tpos75', 'Condition']].copy().rename(columns={\"tpos75\": \"tpos\"})\n",
    "#     manualdfs = [manual50, manual25, manual75]\n",
    "\n",
    "#     cdfs = []\n",
    "#     for i in range(0, len(manualdfs)):\n",
    "#         adf = autodfs[i]; mdf = manualdfs[i]\n",
    "#         cdf = mdf.merge(adf, how='inner', on='datetimes')\n",
    "#         cdf = cdf.astype({'tpos_x': 'float', 'tpos_y': 'float'})\n",
    "#         cdf['diff'] = abs(np.array(cdf.tpos_x) - np.array(cdf.tpos_y))\n",
    "#         cdfs.append(cdf)\n",
    "#     dfs.append(pd.concat(cdfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Clear', 'Dim', 'Sea ice', 'Sea ice ', 'Thin clouds'}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_cdf = pd.concat(dfs)\n",
    "set(compare_cdf.Condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "240.0"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_df = compare_cdf[compare_cdf['Condition'] == 'Clear']\n",
    "print(len(cond_df))\n",
    "np.average(list(cond_df['diff']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.99666666666667"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7*55.71 + 14*182.14)/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.5"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "75/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theta calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.040000000000003\n"
     ]
    }
   ],
   "source": [
    "#SIGMAS (DATA ERRORS) ALONG EACH FLOWLINE (FROM INTERANALYST DIFFERENCES)\n",
    "sigmas = [35.02, 27.65, 30.45]\n",
    "sigma_avg = np.average(sigmas); print(sigma_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box174\n",
      "Theta values: 16.2436864750265 14.980670103092782\n",
      "Box120\n",
      "Theta values: 5.468603853588577 5.315721649484535\n",
      "Box001\n",
      "Theta values: 4.611837997139841 4.4642857142857135\n",
      "Box259\n",
      "Theta values: 1.8672395877956394 1.7949189985272458\n",
      "Box002\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-dce84f4856e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#CALCULATE THETA:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtheta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalizeddiff_all\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sum of normalized differences along flowlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mtheta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msigma_avg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sum of differences normalized by average sigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtheta1s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtheta2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "theta1s = []; theta2s = []; compare_dfs = []\n",
    "#FOR EACH GLACIER BOXID:\n",
    "BoxIDs = list(set(manual_df.BoxID))\n",
    "for BoxID in BoxIDs:\n",
    "    print(\"Box\"+BoxID)\n",
    "    #grab automated tpos\n",
    "    auto50 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline50_filtered.csv', dtype=str,sep=',')\n",
    "    auto25 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline25_filtered.csv', dtype=str,sep=',')\n",
    "    auto75 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline75_filtered.csv', dtype=str,sep=',')\n",
    "    autodfs = [auto50, auto25, auto75]\n",
    "    #grab manual tpos that corresponds to just boxID\n",
    "    manual50_df = manual50[manual50.BoxID == BoxID].copy()\n",
    "    manual25_df = manual25[manual25.BoxID == BoxID].copy()\n",
    "    manual75_df = manual75[manual75.BoxID == BoxID].copy()\n",
    "    manualdfs = [manual50_df, manual25_df, manual75_df]\n",
    "    #calculate difference in terminus positions along the three flowlines\n",
    "    lists3 = []; lists3_norm = []\n",
    "    for i in range(0, len(manualdfs)):\n",
    "        man = manualdfs[i]; auto = autodfs[i]; sigma = sigmas[i]\n",
    "        compare_df = man.merge(auto, how='inner', on=['datetimes'])\n",
    "        #cast terminus positions into float values\n",
    "        compare_df = compare_df.astype({'tpos_x': 'float', 'tpos_y': 'float'})\n",
    "        #subtract the absolute value of the difference and put into df as a column named \"diff\"\n",
    "        compare_df['diff'] = abs(np.array(compare_df.tpos_x) - np.array(compare_df.tpos_y))  \n",
    "        compare_df['diff/sigma'] = abs(np.array(compare_df.tpos_x) - np.array(compare_df.tpos_y))/sigma\n",
    "        lists3.append(list(compare_df['diff']))  \n",
    "        lists3_norm.append(list(compare_df['diff/sigma']))\n",
    "    diff_all = lists3[0]+lists3[1]+lists3[2] #list of all the differences between manual and auto\n",
    "    normalizeddiff_all = lists3_norm[0]+lists3_norm[1]+lists3_norm[2] #list of all the normalized differences\n",
    "    N = len(diff_all) #number of total intersections\n",
    "    \n",
    "    #CALCULATE THETA:\n",
    "    theta1 = (1.0/N)*np.sum(normalizeddiff_all) #sum of normalized differences along flowlines\n",
    "    theta2 = (1.0/N)*(np.sum(diff_all)/sigma_avg) #sum of differences normalized by average sigma\n",
    "    theta1s.append(theta1); theta2s.append(theta2)\n",
    "    print(\"Theta values:\",theta1, theta2)\n",
    "    \n",
    "    compare_dfs.append(compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'manual_dfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-39bf0f515dab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmanual_dfs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'manual_dfs' is not defined"
     ]
    }
   ],
   "source": [
    "manual_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Theta_avg', nan, nan),\n",
       " ('174', 15.250678739646302, 15.153724923376984),\n",
       " ('002', 43.19720044648473, 43.18432633252906),\n",
       " ('001', 32.47436749614078, 32.26716320559405),\n",
       " ('120', 13.919454254169144, 13.744797471440512),\n",
       " ('259', 26.457638700697967, 26.416362722840447)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(columns, theta1_for_df, theta2_for_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATE OVERALL THETA and write results to csv\n",
    "theta1_all = np.average(theta1s)\n",
    "theta2_all = np.average(theta2s)\n",
    "\n",
    "#organize data\n",
    "columns = ['Theta_avg']+BoxIDs\n",
    "theta1_for_df = [theta1_all]+theta1s\n",
    "theta2_for_df = [theta2_all]+theta2s\n",
    "#write to csv\n",
    "pd.DataFrame(list(zip(columns, theta1_for_df, theta2_for_df)), \n",
    "             columns=['ID', 'theta1', 'theta2']).to_csv(manual_path+'thetas.csv', sep=',') \n",
    "\n",
    "#ADJUST FILENAME TO INCLUDE PARAMETERS OR SOMETHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(manual_df):\n",
    "    #SPLIT INTO 3 DATAFRAMES FOR 3 FLOWLINES:\n",
    "    manual50 = manual_df[['BoxID','datetimes', 'intersect_x', 'intersect_y', \n",
    "                                          'tpos50']].copy().reset_index(drop=True).rename(columns={\"tpos50\": \"tpos\"})\n",
    "    manual25 = manual_df[['BoxID','datetimes', 'intersect_x', 'intersect_y', \n",
    "                                          'tpos25']].copy().reset_index(drop=True).rename(columns={\"tpos25\": \"tpos\"})\n",
    "    manual75 = manual_df[['BoxID','datetimes', 'intersect_x', 'intersect_y',\n",
    "                                          'tpos75']].copy().reset_index(drop=True).rename(columns={\"tpos75\": \"tpos\"})\n",
    "    #SIGMAS (DATA ERRORS) ALONG EACH FLOWLINE (FROM INTERANALYST DIFFERENCES)\n",
    "    sigmas = [35.02, 27.65, 30.45]; sigma_avg = np.average(sigmas);\n",
    "    \n",
    "    theta1s = []; theta2s = []\n",
    "    #FOR EACH GLACIER BOXID:\n",
    "    BoxIDs = list(set(manual_df.BoxID))\n",
    "    for BoxID in BoxIDs:\n",
    "        print(\"Box\"+BoxID)\n",
    "        #grab automated tpos\n",
    "        auto50 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline50_filtered.csv', dtype=str,sep=',')\n",
    "        auto25 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline25_filtered.csv', dtype=str,sep=',')\n",
    "        auto75 = pd.read_csv(auto_path+'Tpos_Box'+BoxID+'_flowline75_filtered.csv', dtype=str,sep=',')\n",
    "        autodfs = [auto50, auto25, auto75]\n",
    "        #grab manual tpos that corresponds to just boxID\n",
    "        manual50_df = manual50[manual50.BoxID == BoxID].copy()\n",
    "        manual25_df = manual25[manual25.BoxID == BoxID].copy()\n",
    "        manual75_df = manual75[manual75.BoxID == BoxID].copy()\n",
    "        manualdfs = [manual50, manual25, manual75]\n",
    "        #calculate difference in terminus positions along the three flowlines\n",
    "        lists3 = []; lists3_norm = []\n",
    "        for i in range(0, len(manualdfs)):\n",
    "            man = manualdfs[i]; auto = autodfs[i]; sigma = sigmas[i]\n",
    "            compare_df = man.merge(auto, how='inner', on=['datetimes'])\n",
    "            #cast terminus positions into float values\n",
    "            compare_df = compare_df.astype({'tpos_x': 'float', 'tpos_y': 'float'})\n",
    "            #subtract the absolute value of the difference and put into df as a column named \"diff\"\n",
    "            compare_df['diff'] = abs(np.array(compare_df.tpos_x) - np.array(compare_df.tpos_y))  \n",
    "            compare_df['diff/sigma'] = abs(np.array(compare_df.tpos_x) - np.array(compare_df.tpos_y))/sigma\n",
    "            lists3.append(list(compare_df['diff']))  \n",
    "            lists3_norm.append(list(compare_df['diff/sigma']))\n",
    "        diff_all = lists3[0]+lists3[1]+lists3[2] #list of all the differences between manual and auto\n",
    "        normalizeddiff_all = lists3_norm[0]+lists3_norm[1]+lists3_norm[2] #list of all the normalized differences\n",
    "        N = len(diff_all) #number of total intersections\n",
    "\n",
    "        #CALCULATE THETA:\n",
    "        theta1 = (1.0/N)*np.sum(normalizeddiff_all) #sum of normalized differences along flowlines\n",
    "        theta2 = (1.0/N)*(np.sum(diff_all)/sigma_avg) #sum of differences normalized by average sigma\n",
    "        theta1s.append(theta1); theta2s.append(theta2)\n",
    "        #print(\"Theta values:\",theta1, theta2)   \n",
    "        \n",
    "    #CALCULATE OVERALL THETA\n",
    "    theta1_all = np.average(theta1s); theta2_all = np.average(theta2s)\n",
    "    #organize data in dataframe\n",
    "    column_titles = ['Theta_avg']+BoxIDs\n",
    "    theta1_for_df = [theta1_all]+theta1s; theta2_for_df = [theta2_all]+theta2s\n",
    "    #write to csv\n",
    "    theta_df = pd.DataFrame(list(zip(column_titles, theta1_for_df, theta2_for_df)), \n",
    "                 columns=['ID', 'theta1', 'theta2'])\n",
    "    return theta_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective_func(manual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
