{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greenland peripherial glacier pre-image download processing\n",
    "\n",
    "#### Jukes Liu\n",
    "__Last modified 10-15-2019.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import packages, set base path, set glaciers of interest by BoxID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import fiona\n",
    "from shapely.geometry import Polygon, Point\n",
    "import shapely\n",
    "import math\n",
    "\n",
    "#SET basepath to your own folder\n",
    "basepath='/home/jukes/Documents/Sample_glaciers/'\n",
    "\n",
    "#ENTER list of glaciers of interest by BoxID\n",
    "#make this into a widget where you can enter them in?\n",
    "# BOXIDS = ['001', '002', '004', '033', '120', '174', '235', '259', '277', '531'];\n",
    "# BOXIDS = ['Alison', 'Helheim']\n",
    "BOXIDS = ['147', '148', '149', '150', '152', '190', '191', '192', '193', '194', '195', '195', '196', '213', '214', '215']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, y1, x2, y2):\n",
    "    dist = math.sqrt(((x2-x1)**2) + ((y2-y1)**2))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create buffer zone around terminus boxes and rasterize/subset terminus boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code pulls the buffer distances around the terminus boxes from an existing .csv file with the exported attributes tables for the peripheral glacier terminus boxes. These buffer distances will be used to create a buffer zone to subset the Landsat scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box147_UTM_23.shp\n",
      "Box147_UTM_24.shp\n",
      "Box148_UTM_23.shp\n",
      "Box148_UTM_24.shp\n",
      "Box149_UTM_24.shp\n",
      "Box149_UTM_23.shp\n",
      "Box150_UTM_24.shp\n",
      "Box150_UTM_23.shp\n",
      "Box152_UTM_23.shp\n",
      "Box152_UTM_24.shp\n",
      "Box190_UTM_24.shp\n",
      "Box190_UTM_23.shp\n",
      "Box191_UTM_24.shp\n",
      "Box191_UTM_23.shp\n",
      "Box192_UTM_23.shp\n",
      "Box192_UTM_24.shp\n",
      "Box193_UTM_23.shp\n",
      "Box193_UTM_24.shp\n",
      "Box194_UTM_23.shp\n",
      "Box194_UTM_24.shp\n",
      "Box195_UTM_24.shp\n",
      "Box195_UTM_23.shp\n",
      "Box195_UTM_24.shp\n",
      "Box195_UTM_23.shp\n",
      "Box196_UTM_23.shp\n",
      "Box196_UTM_24.shp\n",
      "Box213_UTM_24.shp\n",
      "Box213_UTM_23.shp\n",
      "Box214_UTM_24.shp\n",
      "Box214_UTM_23.shp\n",
      "Box215_UTM_24.shp\n",
      "Box215_UTM_23.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jukes/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: FionaDeprecationWarning: Collection.__next__() is buggy and will be removed in Fiona 2.0. Switch to `next(iter(collection))`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoxID</th>\n",
       "      <th>Buff_dist_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>190</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>191</td>\n",
       "      <td>1685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>193</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>194</td>\n",
       "      <td>1723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>195</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>195</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>196</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>213</td>\n",
       "      <td>2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>214</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>215</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BoxID  Buff_dist_m\n",
       "0    147         1083\n",
       "1    148          861\n",
       "2    149          662\n",
       "3    150          676\n",
       "4    152          934\n",
       "5    190         1946\n",
       "6    191         1685\n",
       "7    192          653\n",
       "8    193         1509\n",
       "9    194         1723\n",
       "10   195         1201\n",
       "11   195         1201\n",
       "12   196          673\n",
       "13   213         2478\n",
       "14   214         2777\n",
       "15   215         2574"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffers = []\n",
    "\n",
    "#Calculate a buffer distance around the terminus box using the UTM projected boxes\n",
    "for BoxID in BOXIDS:\n",
    "    buff_distances = []\n",
    "\n",
    "    for file in os.listdir(basepath+'Box'+BoxID+'/'):\n",
    "        if 'UTM' in file and '.shp' in file:\n",
    "            print(file)\n",
    "            boxpath = basepath+\"Box\"+BoxID+\"/\"+file\n",
    "#             print(boxpath)\n",
    "            \n",
    "            termbox = fiona.open(boxpath)\n",
    "            #grab the box feature:\n",
    "            box = termbox.next()\n",
    "            box_geom= box.get('geometry')\n",
    "            box_coords = box_geom.get('coordinates')[0]\n",
    "#             print(box_geom)\n",
    "            \n",
    "            points = []\n",
    "            for coord_pair in box_coords:\n",
    "                lat = coord_pair[0]\n",
    "                lon = coord_pair[1]\n",
    "                \n",
    "                points.append([lat, lon])\n",
    "            \n",
    "            #Calculate distance between 1 and 2 and distance between 2 and 3\n",
    "            #pick the longer one (length)\n",
    "            coord1 = points[0]\n",
    "            coord2 = points[1]\n",
    "            coord3 = points[2]\n",
    "            \n",
    "            #1 and 2\n",
    "            dist1 = distance(coord1[0], coord1[1], coord2[0], coord2[1])       \n",
    "            #2 and 3\n",
    "            dist2 = distance(coord2[0], coord2[1], coord3[0], coord3[1])\n",
    "            \n",
    "            buff_dist = int(np.max([dist1, dist2]))\n",
    "#             print(buff_dist)\n",
    "            buff_distances.append(buff_dist)\n",
    "    \n",
    "    buffer = buff_distances[0]\n",
    "    buffers.append(buffer)\n",
    "\n",
    "buff_df = pd.DataFrame(list(zip(BOXIDS, buffers)), columns=['BoxID', 'Buff_dist_m'])\n",
    "buff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section creates a buffer zone using GDAL command **ogr2ogr** with the following syntax:\n",
    "\n",
    "    ogr2ogr Buffer###.shp path_to_terminusbox###.shp  -dialect sqlite -sql \"SELECT ST_Buffer(geometry, buffer_distance) AS geometry,*FROM 'Box###'\" -f \"ESRI Shapefile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box147/Buffer147.shp /home/jukes/Documents/Sample_glaciers/Box147/Box147.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1083) AS geometry,*FROM 'Box147'\" -f \"ESRI Shapefile\"\n",
      "Box147\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box148/Buffer148.shp /home/jukes/Documents/Sample_glaciers/Box148/Box148.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 861) AS geometry,*FROM 'Box148'\" -f \"ESRI Shapefile\"\n",
      "Box148\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box149/Buffer149.shp /home/jukes/Documents/Sample_glaciers/Box149/Box149.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 662) AS geometry,*FROM 'Box149'\" -f \"ESRI Shapefile\"\n",
      "Box149\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box150/Buffer150.shp /home/jukes/Documents/Sample_glaciers/Box150/Box150.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 676) AS geometry,*FROM 'Box150'\" -f \"ESRI Shapefile\"\n",
      "Box150\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box152/Buffer152.shp /home/jukes/Documents/Sample_glaciers/Box152/Box152.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 934) AS geometry,*FROM 'Box152'\" -f \"ESRI Shapefile\"\n",
      "Box152\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box190/Buffer190.shp /home/jukes/Documents/Sample_glaciers/Box190/Box190.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1946) AS geometry,*FROM 'Box190'\" -f \"ESRI Shapefile\"\n",
      "Box190\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box191/Buffer191.shp /home/jukes/Documents/Sample_glaciers/Box191/Box191.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1685) AS geometry,*FROM 'Box191'\" -f \"ESRI Shapefile\"\n",
      "Box191\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box192/Buffer192.shp /home/jukes/Documents/Sample_glaciers/Box192/Box192.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 653) AS geometry,*FROM 'Box192'\" -f \"ESRI Shapefile\"\n",
      "Box192\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box193/Buffer193.shp /home/jukes/Documents/Sample_glaciers/Box193/Box193.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1509) AS geometry,*FROM 'Box193'\" -f \"ESRI Shapefile\"\n",
      "Box193\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box194/Buffer194.shp /home/jukes/Documents/Sample_glaciers/Box194/Box194.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1723) AS geometry,*FROM 'Box194'\" -f \"ESRI Shapefile\"\n",
      "Box194\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box195/Buffer195.shp /home/jukes/Documents/Sample_glaciers/Box195/Box195.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1201) AS geometry,*FROM 'Box195'\" -f \"ESRI Shapefile\"\n",
      "Box195\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box195/Buffer195.shp /home/jukes/Documents/Sample_glaciers/Box195/Box195.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 1201) AS geometry,*FROM 'Box195'\" -f \"ESRI Shapefile\"\n",
      "Box195\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box196/Buffer196.shp /home/jukes/Documents/Sample_glaciers/Box196/Box196.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 673) AS geometry,*FROM 'Box196'\" -f \"ESRI Shapefile\"\n",
      "Box196\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box213/Buffer213.shp /home/jukes/Documents/Sample_glaciers/Box213/Box213.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 2478) AS geometry,*FROM 'Box213'\" -f \"ESRI Shapefile\"\n",
      "Box213\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box214/Buffer214.shp /home/jukes/Documents/Sample_glaciers/Box214/Box214.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 2777) AS geometry,*FROM 'Box214'\" -f \"ESRI Shapefile\"\n",
      "Box214\n",
      "ogr2ogr /home/jukes/Documents/Sample_glaciers/Box215/Buffer215.shp /home/jukes/Documents/Sample_glaciers/Box215/Box215.shp -dialect sqlite -sql \"SELECT ST_Buffer(geometry, 2574) AS geometry,*FROM 'Box215'\" -f \"ESRI Shapefile\"\n",
      "Box215\n"
     ]
    }
   ],
   "source": [
    "for index, row in buff_df.iterrows():\n",
    "    BoxID = row['BoxID']\n",
    "    buff_dist = str(row['Buff_dist_m'])\n",
    "    \n",
    "    #SET path to the terminus box shapefiles\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    outputbuffer_path = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+\".shp\"\n",
    "    \n",
    "    #SET buffer command and print to check it\n",
    "    buffer_cmd = 'ogr2ogr '+outputbuffer_path+\" \"+terminusbox_path+' -dialect sqlite -sql \"SELECT ST_Buffer(geometry, '+buff_dist+\") AS geometry,*FROM 'Box\"+BoxID+\"'\"+'\" -f \"ESRI Shapefile\"'\n",
    "    print(buffer_cmd)\n",
    "    \n",
    "    subprocess.call(buffer_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terminus box shapefiles are then rasterized (to be used as a mask during the WTMM filering) using the GDAL **gdal_rasterize** command and subset to the buffer zone using the GDAL **gdalwarp** command using the following syntax:\n",
    "\n",
    "1) Rasterize\n",
    "\n",
    "    gdal_rasterize -burn 1.0 -tr x_resolution y_resolution -a_nodata 0.0 path_to_terminusbox.shp path_to_terminusbox_raster.TIF\n",
    "\n",
    "The x_resolution and y_resolution are set to be 15.0 (meters) to match the Landsat B8 resolution.\n",
    "    \n",
    "2) Subset\n",
    "\n",
    "    gdalwarp -cutline path_to_Buffer###.shp -crop_to_cutline path_to_terminusbox_raster.TIF path_to_subset_raster_cut.TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box147\n",
      "Box148\n",
      "Box149\n",
      "Box150\n",
      "Box152\n",
      "Box190\n",
      "Box191\n",
      "Box192\n",
      "Box193\n",
      "Box194\n",
      "Box195\n",
      "Box195\n",
      "Box196\n",
      "Box213\n",
      "Box214\n",
      "Box215\n"
     ]
    }
   ],
   "source": [
    "for index, row in buff_df.iterrows():\n",
    "    BoxID = row['BoxID']\n",
    "    #SET path to the terminus box shapefiles\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    buffer_path = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+\".shp\"\n",
    "    \n",
    "    #output raster path:\n",
    "    terminusraster_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".TIF\"\n",
    "    cutraster_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\"_cut.TIF\"\n",
    "    \n",
    "    #SET commands and print to check\n",
    "    rasterize_cmd = 'gdal_rasterize -burn 1.0 -tr 15.0 15.0 -a_nodata 0.0 '+terminusbox_path+' '+terminusraster_path\n",
    "    subsetbuffer_cmd = 'gdalwarp -cutline '+buffer_path+' -crop_to_cutline '+terminusraster_path+\" \"+cutraster_path\n",
    "    #print(export_GDALpath+rasterize_cmd)\n",
    "    #print(export_GDALpath+subsetbuffer_cmd)\n",
    "    \n",
    "    #RASTERIZE & SUBSET\n",
    "    subprocess.call(rasterize_cmd, shell=True)\n",
    "    subprocess.call(subsetbuffer_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Calculate average flow direction (weighted by magnitude) for each glacier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code processes 2016-2017 ice velocity data from the ESA Cryoportal to determine each glacier of interest's weighted average flow direction. The ice velocity direction (calculated from yx velocity) and the velocity magnitude at each glacier's terminus  is subset using the terminus box shapefile using a GDAL command (**gdalwarp**) with the following syntax:\n",
    "\n",
    "    gdalwarp -cutline path_to_terminusbox.shp -crop_to_cutline path_to_input_velocity.TIF path_to_output_velocity_at_term###.TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box147\n",
      "Box148\n",
      "Box149\n",
      "Box150\n",
      "Box152\n",
      "Box190\n",
      "Box191\n",
      "Box192\n",
      "Box193\n",
      "Box194\n",
      "Box195\n",
      "Box195\n",
      "Box196\n",
      "Box213\n",
      "Box214\n",
      "Box215\n"
     ]
    }
   ],
   "source": [
    "for BoxID in BOXIDS:\n",
    "    #SET paths to the terminus box shapefiles and velocity data\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    v_dir_path = basepath+'dir_degree_yx_velocity.tif'\n",
    "    v_mag_path = basepath+'magnitude_velocity.tif'  \n",
    "    \n",
    "    #SET output paths\n",
    "    v_dir_output = basepath+\"Box\"+BoxID+\"/dir_degree_yx_velocity_at_term\"+BoxID+\".tif\"\n",
    "    v_mag_output = basepath+\"Box\"+BoxID+\"/magnitude_velocity_at_term\"+BoxID+\".tif\"\n",
    "    \n",
    "    #SET velocity subset commands and print to check it\n",
    "    v_subset_dir_cmd = 'gdalwarp -cutline '+terminusbox_path+' -crop_to_cutline '+v_dir_path+\" \"+v_dir_output\n",
    "    v_subset_mag_cmd = 'gdalwarp -cutline '+terminusbox_path+' -crop_to_cutline '+v_mag_path+\" \"+v_mag_output\n",
    "    #print(export_GDALpath+v_subset_dir_cmd)\n",
    "    #print(export_GDALpath+v_subset_mag_cmd)\n",
    "    \n",
    "    #SUBSET velocity rasters\n",
    "    subprocess.call(v_subset_dir_cmd, shell=True)\n",
    "    subprocess.call(v_subset_mag_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, these subset velocity rasters are opened using the **rasterio** package and read into arrays. They are filtered for anomalous values and the velocity magnitudes are converted into weights. Then the **numpy.average()** function is used to calculated the weighted average flow directions where the flow directions of the pixels where the highest velocities are found are weighted more. \n",
    "\n",
    "The resulting average flow direction will be representative of the glacier's main flow. These directions will be used to rotate the images of the glaciers so that their flow is due right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jukes/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/jukes/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoxID</th>\n",
       "      <th>Flow_dir</th>\n",
       "      <th>Max_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "      <td>-67.982811</td>\n",
       "      <td>0.041723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148</td>\n",
       "      <td>-45.127583</td>\n",
       "      <td>0.015676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149</td>\n",
       "      <td>50.042461</td>\n",
       "      <td>0.048149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>83.907120</td>\n",
       "      <td>0.025399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152</td>\n",
       "      <td>89.427757</td>\n",
       "      <td>0.047727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>190</td>\n",
       "      <td>35.368717</td>\n",
       "      <td>0.591658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>191</td>\n",
       "      <td>58.450203</td>\n",
       "      <td>0.303347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>-95.570595</td>\n",
       "      <td>0.035823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>193</td>\n",
       "      <td>-110.582809</td>\n",
       "      <td>0.069529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>194</td>\n",
       "      <td>-98.556999</td>\n",
       "      <td>0.406422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>195</td>\n",
       "      <td>-127.023148</td>\n",
       "      <td>0.218372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>195</td>\n",
       "      <td>-127.023148</td>\n",
       "      <td>0.218372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>196</td>\n",
       "      <td>87.082054</td>\n",
       "      <td>0.044461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>213</td>\n",
       "      <td>67.288185</td>\n",
       "      <td>0.057947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>214</td>\n",
       "      <td>-17.691584</td>\n",
       "      <td>0.364651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>215</td>\n",
       "      <td>-35.681389</td>\n",
       "      <td>0.127903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BoxID    Flow_dir  Max_speed\n",
       "0    147  -67.982811   0.041723\n",
       "1    148  -45.127583   0.015676\n",
       "2    149   50.042461   0.048149\n",
       "3    150   83.907120   0.025399\n",
       "4    152   89.427757   0.047727\n",
       "5    190   35.368717   0.591658\n",
       "6    191   58.450203   0.303347\n",
       "7    192  -95.570595   0.035823\n",
       "8    193 -110.582809   0.069529\n",
       "9    194  -98.556999   0.406422\n",
       "10   195 -127.023148   0.218372\n",
       "11   195 -127.023148   0.218372\n",
       "12   196   87.082054   0.044461\n",
       "13   213   67.288185   0.057947\n",
       "14   214  -17.691584   0.364651\n",
       "15   215  -35.681389   0.127903"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATE list of glacier average flow directions:\n",
    "boxes = []\n",
    "rot_angles = []\n",
    "max_magnitudes = []\n",
    "\n",
    "\n",
    "for BoxID in BOXIDS :    \n",
    "        #READ velocity direction and magnitude data at terminus for each glacier into an array\n",
    "        direction = rasterio.open(basepath+'Box'+BoxID+'/dir_degree_yx_velocity_at_term'+BoxID+'.tif', \"r\")\n",
    "        dir_array = direction.read()\n",
    "        #print(dir_array.shape)\n",
    "        magnitude = rasterio.open(basepath+'Box'+BoxID+'/magnitude_velocity_at_term'+BoxID+'.tif', \"r\")\n",
    "        mag_array = magnitude.read()\n",
    "        #print(mag_array.shape)\n",
    "        \n",
    "        \n",
    "        #RESHAPE direction array and remove anomalous values\n",
    "        dir2 = dir_array.reshape(dir_array.shape[1] * dir_array.shape[2])\n",
    "        #direction must be between 180 and -180 degrees\n",
    "        mask_dir2 = (dir2 < 180) & (dir2 > -180)\n",
    "        masked_dir = dir2[mask_dir2]\n",
    "#         print(masked_dir.min(), masked_dir.max())\n",
    "\n",
    "        #RESHAPE magnitude array and remove anomalous values\n",
    "        mag2 = mag_array.reshape(mag_array.shape[1] * mag_array.shape[2])\n",
    "        #magnitude must be between 0 and 10 m/d\n",
    "        mask_mag2 = (mag2 < 100) & (mag2 > 0)\n",
    "        masked_mag = mag2[mask_mag2]\n",
    "#         print(masked_mag.min(), masked_mag.max())\n",
    "        \n",
    "    \n",
    "        #CALCULATE weights (0 - 1) from magnitudes\n",
    "        mag_range = masked_mag.max() - masked_mag.min()\n",
    "        stretch = 1/mag_range\n",
    "        weights = stretch*(masked_mag - masked_mag.min())\n",
    "        #print(weights.min(), weights.max()) #should be between 0 and 1\n",
    "        #print(weights.shape, masked_dir.shape)\n",
    "        \n",
    "        \n",
    "        #CALCULATE the weighted average rotation angle\n",
    "        avg_dir = np.average(masked_dir, weights=weights)\n",
    "#         print(avg_dir)\n",
    "        \n",
    "        #APPEND the rotation angles to the dictionary\n",
    "        if masked_dir.min() == masked_dir.max():\n",
    "            rot_angles.append(masked_dir.min())\n",
    "        else:\n",
    "            rot_angles.append(avg_dir)\n",
    "        \n",
    "        #APPEND the maximum flow magnitude\n",
    "        max_magnitudes.append(masked_mag.max())\n",
    "        \n",
    "        #APPEND the BoxID\n",
    "        boxes.append(BoxID)\n",
    "\n",
    "#create dataframe with the calculations\n",
    "velocities_df = pd.DataFrame(list(zip(boxes, rot_angles, max_magnitudes)), columns=['BoxID','Flow_dir', 'Max_speed'])\n",
    "velocities_df = velocities_df.sort_values(by='BoxID')\n",
    "velocities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT MAX VELOCITY AND AVERAGE FLOW DIRECTION TO A .CSV FILE\n",
    "#write the data frame to csv file\n",
    "velocities_df.to_csv(path_or_buf = basepath+'Glacier_velocities_SE.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-67.9828109741211, -45.12758255004883, 50.04246139526367, 83.90711975097656, 89.4277572631836, 35.368717193603516, 58.45020294189453, -95.57059478759766, -110.58280944824219, -98.55699920654297, -127.02314758300781, -127.02314758300781, 87.0820541381836, 67.2881851196289, -17.69158363342285, -35.68138885498047]\n"
     ]
    }
   ],
   "source": [
    "print(list(velocities_df.Flow_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
