{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greenland peripherial glacier terminus image processing\n",
    "\n",
    "### Jukes Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import packages, set base path, set glaciers of interest by BoxID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-947da1442f25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "\n",
    "#SET basepath to your own folder\n",
    "basepath='/Users/julialiu/Documents/M_Thesis/Data/Sample_glaciers/'\n",
    "\n",
    "#ENTER list of glaciers of interest by BoxID\n",
    "#make this into a widget where you can enter them in?\n",
    "BOXIDS = ['001', '002', '004', '033', '120', '174', '235', '259', '277', '531'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create buffer zone around terminus boxes and rasterize/subset terminus boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code pulls the buffer distances around the terminus boxes from an existing .csv file with the exported attributes tables for the peripheral glacier terminus boxes. These buffer distances will be used to create a buffer zone to subset the Landsat scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001: 1766 meters\n",
      "Box002: 6741 meters\n",
      "Box004: 7112 meters\n",
      "Box033: 5424 meters\n",
      "Box120: 1720 meters\n",
      "Box174: 3729 meters\n",
      "Box235: 2620 meters\n",
      "Box259: 6974 meters\n",
      "Box277: 2273 meters\n",
      "Box531: 2657 meters\n"
     ]
    }
   ],
   "source": [
    "#PULL buffer distances around terminus boxes from a csv file of attributes\n",
    "df=pd.read_csv(basepath+'Boxes_attributes.csv', sep=','); #reads in csv file \n",
    "df_buffdist = df[\"Buff_dist\"].copy(); #creates a dataframe of the buffer distances\n",
    "\n",
    "df_boxid = df[\"BoxID\"].copy(); #creates a data frame of the BoxIDs\n",
    "df_b = pd.concat([df_buffdist, df_boxid], axis=1); #concatenates the two columns\n",
    "\n",
    "#CREATE dictionary of buffer distances with BoxID as the key\n",
    "bd = df_b.set_index('BoxID').T.to_dict('list'); #turns the concatenated df into a dictionary\n",
    "\n",
    "#PRINT buffer distances for the glaciers of interest\n",
    "for BoxID in BOXIDS: \n",
    "    bd_key = int(BoxID)\n",
    "    buff_dist = str(int(bd[bd_key][0]))\n",
    "    print(\"Box\"+BoxID+\":\", buff_dist, \"meters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section creates a buffer zone using GDAL command **ogr2ogr** with the following syntax:\n",
    "\n",
    "    ogr2ogr Buffer###.shp path_to_terminusbox###.shp  -dialect sqlite -sql \"SELECT ST_Buffer(geometry, buffer_distance) AS geometry,*FROM 'Box###'\" -f \"ESRI Shapefile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001\n",
      "Box002\n",
      "Box004\n",
      "Box033\n",
      "Box120\n",
      "Box174\n",
      "Box235\n",
      "Box259\n",
      "Box277\n",
      "Box531\n"
     ]
    }
   ],
   "source": [
    "#export GDAL path command:\n",
    "export_GDALpath = 'export PATH=/Library/Frameworks/GDAL.framework/Programs:$PATH ; '\n",
    "\n",
    "for BoxID in BOXIDS:\n",
    "    #SET path to the terminus box shapefiles\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    outputbuffer_path = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+\".shp\"\n",
    "    \n",
    "    #PULL the buffer distances as strings from the bd dictionary using the BoxID keys\n",
    "    bd_key = int(BoxID)\n",
    "    buff_dist = str(int(bd[bd_key][0]))\n",
    "    \n",
    "    #SET buffer command and print to check it\n",
    "    buffer_cmd = 'ogr2ogr '+outputbuffer_path+\" \"+terminusbox_path+' -dialect sqlite -sql \"SELECT ST_Buffer(geometry, '+buff_dist+\") AS geometry,*FROM 'Box\"+BoxID+\"'\"+'\" -f \"ESRI Shapefile\"'\n",
    "    #print(export_GDALpath, buffer_cmd)\n",
    "    \n",
    "    subprocess.call(export_GDALpath+buffer_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terminus box shapefiles are then rasterized (to be used as a mask during the WTMM filering) using the GDAL **gdal_rasterize** command and subset to the buffer zone using the GDAL **gdalwarp** command using the following syntax:\n",
    "\n",
    "1) Rasterize\n",
    "\n",
    "    gdal_rasterize -burn 1.0 -tr x_resolution y_resolution -a_nodata 0.0 path_to_terminusbox.shp path_to_terminusbox_raster.TIF\n",
    "\n",
    "The x_resolution and y_resolution are set to be 15.0 (meters) to match the Landsat B8 resolution.\n",
    "    \n",
    "2) Subset\n",
    "\n",
    "    gdalwarp -cutline path_to_Buffer###.shp -crop_to_cutline path_to_terminusbox_raster.TIF path_to_subset_raster_cut.TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001\n",
      "Box002\n",
      "Box004\n",
      "Box033\n",
      "Box120\n",
      "Box174\n",
      "Box235\n",
      "Box259\n",
      "Box277\n",
      "Box531\n"
     ]
    }
   ],
   "source": [
    "#export GDAL path command:\n",
    "export_GDALpath = 'export PATH=/Library/Frameworks/GDAL.framework/Programs:$PATH ; '\n",
    "\n",
    "for BoxID in BOXIDS:\n",
    "    #SET path to the terminus box shapefiles\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    buffer_path = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+\".shp\"\n",
    "    \n",
    "    #output raster path:\n",
    "    terminusraster_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".TIF\"\n",
    "    cutraster_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\"_cut.TIF\"\n",
    "    \n",
    "    #SET commands and print to check\n",
    "    rasterize_cmd = 'gdal_rasterize -burn 1.0 -tr 15.0 15.0 -a_nodata 0.0 '+terminusbox_path+' '+terminusraster_path\n",
    "    subsetbuffer_cmd = 'gdalwarp -cutline '+buffer_path+' -crop_to_cutline '+terminusraster_path+\" \"+cutraster_path\n",
    "    #print(export_GDALpath+rasterize_cmd)\n",
    "    #print(export_GDALpath+subsetbuffer_cmd)\n",
    "    \n",
    "    #RASTERIZE & SUBSET\n",
    "    subprocess.call(export_GDALpath+rasterize_cmd, shell=True)\n",
    "    subprocess.call(export_GDALpath+subsetbuffer_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Subset downloaded Landsat scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Row</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoxID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001</th>\n",
       "      <td>034</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002</th>\n",
       "      <td>031</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004</th>\n",
       "      <td>031</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>033</th>\n",
       "      <td>008</td>\n",
       "      <td>014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>232</td>\n",
       "      <td>017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Path  Row\n",
       "BoxID          \n",
       "001    034  005\n",
       "002    031  005\n",
       "004    031  005\n",
       "033    008  014\n",
       "120    232  017"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#READ in the Landsat path and row information for the glaciers\n",
    "pathrows_df = pd.read_csv('/Users/julialiu/Documents/M_Thesis/Data/LS_pathrows.csv', sep=',', usecols =[0,1,2], dtype=str, nrows =10)\n",
    "pathrows_df = pathrows_df.set_index('BoxID')\n",
    "pathrows_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section of code accesses the Landsat 8 scenes downloaded and stored in Path###_Row### folders to 1) reproject them into Greenland Polar Stereographic Coordinates and 2) subset them using the buffer zone shapefiles created from the previous step. The two GDAL commands (**gdalwarp**) use the following syntax:\n",
    "\n",
    "1) Reproject\n",
    "\n",
    "    gdalwarp -t_srs ‘+proj=stere +lat_ts=70 +lat_0=90 +lon_0=-45 +y=0 +x=0 +k=1 +datum=WGS84 +units=m’ path_to_input_image.TIF path_to_renamed_output.TIF\n",
    "\n",
    "2) Subset\n",
    "\n",
    "    gdalwarp -cutline _path_to_Buffer###.shp -crop_to_cutline path_to_input_image.TIF path_to_renamed_output.TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001\n",
      "Box002\n",
      "Box004\n",
      "Box033\n",
      "Box120\n",
      "Box174\n",
      "Box235\n",
      "Box259\n",
      "Box277\n",
      "Box531\n"
     ]
    }
   ],
   "source": [
    "#set path to LS8 scenes\n",
    "path_toscenedirectory = '/Users/julialiu/Documents/M_Thesis/Data/LS8aws/'\n",
    "\n",
    "#export GDAL path command:\n",
    "export_GDALpath = 'export PATH=/Library/Frameworks/GDAL.framework/Programs:$PATH ; '\n",
    "\n",
    "for BoxID in BOXIDS:\n",
    "    \n",
    "    #SELECT folder with LS8 scenes for each glacier by Path and Row folder name\n",
    "    path = pathrows_df.loc[BoxID, 'Path']\n",
    "    row = pathrows_df.loc[BoxID, 'Row']\n",
    "    foldername = \"Path\"+path+\"_Row\"+row\n",
    "    path_toscenes = path_toscenedirectory+foldername+\"/\"\n",
    "    #print(path_toscenes)\n",
    "    \n",
    "    #set path to buffer zone\n",
    "    buffer_path = basepath+\"Box\"+BoxID+\"/Buffer\"+BoxID+\".shp\"\n",
    "    \n",
    "    #STEPS for each image:\n",
    "    for image in os.listdir(path_toscenes):\n",
    "        #REPROJECT into Greenland Polar Stereographic\n",
    "        reproject_cmd = \"gdalwarp -t_srs +proj=stere +lat_ts=70 +lat_0=90 +lon_0=-45 +y=0 +x=0 +k=1 +datum=WGS84 +units=m \"+path_toscenes+image+\"/\"+image+\"_B8.TIF \"+path_toscenes+image+\"/\"+image+\"_B8_PS.TIF\"\n",
    "        #print(export_GDALpath+reproject_cmd)\n",
    "        #subprocess.call(export_GDALpath+reproject_cmd, shell=True)\n",
    "\n",
    "        #SUBSET LS8 scenes to buffer zones around the terminus box\n",
    "        #save subsetted scenes as PGM files\n",
    "        subsetbuffer_cmd = 'gdalwarp -cutline '+buffer_path+' -crop_to_cutline '+path_toscenes+image+\"/\"+image+\"_B8_PS.TIF \"+path_toscenes+image+\"/\"+image+\"_B8_PS_Buffer\"+BoxID+\".pgm\"\n",
    "        #print(export_GDALpath+subsetbuffer_cmd)\n",
    "        #subprocess.call(export_GDALpath+subsetbuffer_cmd)\n",
    "        \n",
    "    print(\"Box\"+BoxID)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Calculate average flow direction (weighted by magnitude) for each glacier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code processes 2016-2017 ice velocity data from the ESA Cryoportal to determine each glacier of interest's weighted average flow direction. The ice velocity direction (calculated from yx velocity) and the velocity magnitude at each glacier's terminus  is subset using the terminus box shapefile using a GDAL command (**gdalwarp**) with the following syntax:\n",
    "\n",
    "    gdalwarp -cutline path_to_terminusbox.shp -crop_to_cutline path_to_input_velocity.TIF path_to_output_velocity_at_term###.TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box001\n",
      "Box002\n",
      "Box004\n",
      "Box033\n",
      "Box120\n",
      "Box174\n",
      "Box235\n",
      "Box259\n",
      "Box277\n",
      "Box531\n"
     ]
    }
   ],
   "source": [
    "#export GDAL path command:\n",
    "export_GDALpath = 'export PATH=/Library/Frameworks/GDAL.framework/Programs:$PATH ; '\n",
    "\n",
    "for BoxID in BOXIDS:\n",
    "    #SET paths to the terminus box shapefiles and velocity data\n",
    "    terminusbox_path = basepath+\"Box\"+BoxID+\"/Box\"+BoxID+\".shp\"\n",
    "    v_dir_path = basepath+'dir_degree_yx_velocity.tif'\n",
    "    v_mag_path = basepath+'magnitude_velocity.tif'  \n",
    "    \n",
    "    #SET output paths\n",
    "    v_dir_output = basepath+\"Box\"+BoxID+\"/dir_degree_yx_velocity_at_term\"+BoxID+\".tif\"\n",
    "    v_mag_output = basepath+\"Box\"+BoxID+\"/magnitude_velocity_at_term\"+BoxID+\".tif\"\n",
    "    \n",
    "    #SET velocity subset commands and print to check it\n",
    "    v_subset_dir_cmd = 'gdalwarp -cutline '+terminusbox_path+' -crop_to_cutline '+v_dir_path+\" \"+v_dir_output\n",
    "    v_subset_mag_cmd = 'gdalwarp -cutline '+terminusbox_path+' -crop_to_cutline '+v_mag_path+\" \"+v_mag_output\n",
    "    #print(export_GDALpath+v_subset_dir_cmd)\n",
    "    #print(export_GDALpath+v_subset_mag_cmd)\n",
    "    \n",
    "    #SUBSET velocity rasters\n",
    "    subprocess.call(export_GDALpath+v_subset_dir_cmd, shell=True)\n",
    "    subprocess.call(export_GDALpath+v_subset_mag_cmd, shell=True)\n",
    "    \n",
    "    print(\"Box\"+BoxID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, these subset velocity rasters are opened using the **rasterio** package and read into arrays. They are filtered for anomalous values and the velocity magnitudes are converted into weights. Then the **numpy.average()** function is used to calculated the weighted average flow directions where the flow directions of the pixels where the highest velocities are found are weighted more. \n",
    "\n",
    "The resulting average flow direction will be representative of the glacier's main flow. These directions will be used to rotate the images of the glaciers so that their flow is due right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'001': 56.284283, '002': 155.98723, '004': -3.4834337, '033': 142.11816, '120': -77.3864, '174': 12.677643, '235': -145.85077, '259': 98.999275, '277': -65.120186, '531': 78.83521}\n",
      "{'001': 0.04377438, '002': 3.5832264, '004': 0.62308246, '033': 0.77165776, '120': 0.27788857, '174': 0.91450316, '235': 0.15709679, '259': 3.0749009, '277': 0.2860196, '531': 0.040784776}\n"
     ]
    }
   ],
   "source": [
    "#CREATE list of glacier average flow directions:\n",
    "rot_angles = {}\n",
    "max_magnitudes = {}\n",
    "\n",
    "for BoxID in BOXIDS :    \n",
    "        #READ velocity direction and magnitude data at terminus for each glacier into an array\n",
    "        direction = rasterio.open(basepath+'Box'+BoxID+'/dir_degree_yx_velocity_at_term'+BoxID+'.tif', \"r\")\n",
    "        dir_array = direction.read()\n",
    "        #print(dir_array.shape)\n",
    "        magnitude = rasterio.open(basepath+'Box'+BoxID+'/magnitude_velocity_at_term'+BoxID+'.tif', \"r\")\n",
    "        mag_array = magnitude.read()\n",
    "        #print(mag_array.shape)\n",
    "        \n",
    "        \n",
    "        #RESHAPE direction array and remove anomalous values\n",
    "        dir2 = dir_array.reshape(dir_array.shape[1] * dir_array.shape[2])\n",
    "        #direction must be between 180 and -180 degrees\n",
    "        mask_dir2 = (dir2 < 180) & (dir2 > -180)\n",
    "        masked_dir = dir2[mask_dir2]\n",
    "        #print(masked_dir.min(), masked_dir.max())\n",
    "\n",
    "        #RESHAPE magnitude array and remove anomalous values\n",
    "        mag2 = mag_array.reshape(mag_array.shape[1] * mag_array.shape[2])\n",
    "        #magnitude must be between 0 and 10 m/d\n",
    "        mask_mag2 = (mag2 < 25) & (mag2 > 0)\n",
    "        masked_mag = mag2[mask_mag2]\n",
    "        #print(masked_mag.min(), masked_mag.max())\n",
    "        \n",
    "    \n",
    "        #CALCULATE weights (0 - 1) from magnitudes\n",
    "        mag_range = masked_mag.max() - masked_mag.min()\n",
    "        stretch = 1/mag_range\n",
    "        weights = stretch*(masked_mag - masked_mag.min())\n",
    "        #print(weights.min(), weights.max()) #should be between 0 and 1\n",
    "        #print(weights.shape, masked_dir.shape)\n",
    "        \n",
    "        \n",
    "        #CALCULATE the weighted average rotation angle\n",
    "        avg_dir = np.average(masked_dir, weights=weights)\n",
    "        #print(avg_dir)\n",
    "        \n",
    "        #APPEND the rotation angles to the dictionary\n",
    "        rot_angles.update( {BoxID: avg_dir})\n",
    "        \n",
    "        #APPEND the maximum flow magnitude\n",
    "        max_magnitudes.update( {BoxID: masked_mag.max()} )\n",
    "\n",
    "\n",
    "print(rot_angles)\n",
    "print(max_magnitudes)\n",
    "\n",
    "#EXPORT TO CSV for rotations???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Call FIJI scripts to perform rotations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEXT, USE FIJI/IMAGEJ TO PERFORM THE ROTATIONS, use iPython line or cell magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Call Tcl scripts to perform 2D WTMM and filter for terminus line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Call post-processing scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
